{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "a-yT195BU-84",
        "ctBIjt6MVKOg",
        "62THNzXM7ojU",
        "H-R1HEG54I7p",
        "xjUYnTETmf-f",
        "1gJraykxXisk",
        "wzv5X_llXxMW",
        "sLVETKc0Srl-",
        "joJFPtLETmlk",
        "7DW7wUN2UT8s"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f907b80691c74b518ea9a3f7e0ac7d61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_449a1e68a8e64e3ca2567fd8c5ccfa21",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2beaa6c5a00644e3a90fdbb5dfb99f04",
              "IPY_MODEL_c83930462699457e8dde7abcfa4a2796",
              "IPY_MODEL_1f61d1ceb8cc49d69a9090b6110571f1"
            ]
          }
        },
        "449a1e68a8e64e3ca2567fd8c5ccfa21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2beaa6c5a00644e3a90fdbb5dfb99f04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_705fcc4b70154bdd8ff19923a0654343",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8a3e2883eab4436d99aac38386b61914"
          }
        },
        "c83930462699457e8dde7abcfa4a2796": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_561e8bed18c846b6b20e196dc8934988",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 9464212,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 9464212,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_76548f5459ae40528914a315031a95ee"
          }
        },
        "1f61d1ceb8cc49d69a9090b6110571f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e4d43f3ef3c54d0b8fa203c424dffd2b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9464832/? [00:00&lt;00:00, 26037987.95it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b30bdb84fe394bd9872f742e4b141195"
          }
        },
        "705fcc4b70154bdd8ff19923a0654343": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8a3e2883eab4436d99aac38386b61914": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "561e8bed18c846b6b20e196dc8934988": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "76548f5459ae40528914a315031a95ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e4d43f3ef3c54d0b8fa203c424dffd2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b30bdb84fe394bd9872f742e4b141195": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "80fe0f490d174e658c857b3c602612e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6f57a61114ae45a7a428915e437b3ea1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e241ea9a8cb34ac79035692ce5b93eab",
              "IPY_MODEL_7f41134525624762824ab81d5fad5823",
              "IPY_MODEL_85fb670ef2804ef78286cc7fef15d401"
            ]
          }
        },
        "6f57a61114ae45a7a428915e437b3ea1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e241ea9a8cb34ac79035692ce5b93eab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9dcc7fe9e11e4bc8a9b28618d9d9e3a9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_936cbdbce44749f0b7a256e642c5ff16"
          }
        },
        "7f41134525624762824ab81d5fad5823": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_42b17376fc354e5eba847ec7d3572750",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 6462886,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 6462886,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d27a53423e164b42b32bb12f101d6784"
          }
        },
        "85fb670ef2804ef78286cc7fef15d401": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_edcca8011f714d19a46788a9def374e7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 6463488/? [00:00&lt;00:00, 13060191.59it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f01e903b4f4b4590b0e2496b7ee60200"
          }
        },
        "9dcc7fe9e11e4bc8a9b28618d9d9e3a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "936cbdbce44749f0b7a256e642c5ff16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "42b17376fc354e5eba847ec7d3572750": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d27a53423e164b42b32bb12f101d6784": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "edcca8011f714d19a46788a9def374e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f01e903b4f4b4590b0e2496b7ee60200": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-yT195BU-84"
      },
      "source": [
        "**The following code cells contains our experiments code details** \n",
        "---- \n",
        " **Please start from Experiment 1 and go up**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nxHQjoSgYxn",
        "outputId": "ab74fc46-4d7a-4a45-b270-63796ccc82bd"
      },
      "source": [
        "# algorithm \n",
        "\n",
        "!pip install learn2learn\n",
        "!pip install flow-torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from flow.flow import Sequential, inv_flow\n",
        "from flow.conditioner import MADE ,CouplingLayers\n",
        "from flow.transformer import DSF , NonAffine\n",
        "from flow.transformer import Affine as AffineTransformer\n",
        "from flow.modules import BatchNorm, Affine, Sigmoid, Shuffle,ActNorm\n",
        "from flow.training import get_device, train, plot_losses, test_nll\n",
        "\n",
        "import learn2learn as l2l\n",
        "from torch import nn, optim"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting learn2learn\n",
            "  Downloading learn2learn-0.1.6.tar.gz (604 kB)\n",
            "\u001b[K     |████████████████████████████████| 604 kB 5.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from learn2learn) (1.19.5)\n",
            "Requirement already satisfied: gym>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from learn2learn) (0.17.3)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from learn2learn) (1.9.0+cu111)\n",
            "Requirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from learn2learn) (0.10.0+cu111)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from learn2learn) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from learn2learn) (2.23.0)\n",
            "Collecting gsutil\n",
            "  Downloading gsutil-5.4.tar.gz (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 34.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from learn2learn) (4.62.3)\n",
            "Collecting qpth>=0.0.15\n",
            "  Downloading qpth-0.0.15.tar.gz (11 kB)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.14.0->learn2learn) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.14.0->learn2learn) (1.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.14.0->learn2learn) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.1.0->learn2learn) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.3.0->learn2learn) (7.1.2)\n",
            "Requirement already satisfied: argcomplete>=1.9.4 in /usr/local/lib/python3.7/dist-packages (from gsutil->learn2learn) (1.12.3)\n",
            "Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python3.7/dist-packages (from gsutil->learn2learn) (1.7)\n",
            "Collecting fasteners>=0.14.1\n",
            "  Downloading fasteners-0.16.3-py2.py3-none-any.whl (28 kB)\n",
            "Collecting gcs-oauth2-boto-plugin>=3.0\n",
            "  Downloading gcs-oauth2-boto-plugin-3.0.tar.gz (20 kB)\n",
            "Collecting google-apitools>=0.5.32\n",
            "  Downloading google_apitools-0.5.32-py3-none-any.whl (135 kB)\n",
            "\u001b[K     |████████████████████████████████| 135 kB 48.5 MB/s \n",
            "\u001b[?25hCollecting httplib2>=0.18\n",
            "  Downloading httplib2-0.20.1-py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 5.5 MB/s \n",
            "\u001b[?25hCollecting google-reauth>=0.1.0\n",
            "  Downloading google_reauth-0.1.1-py2.py3-none-any.whl (17 kB)\n",
            "Collecting monotonic>=1.4\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting pyOpenSSL>=0.13\n",
            "  Downloading pyOpenSSL-21.0.0-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.3 MB/s \n",
            "\u001b[?25hCollecting retry_decorator>=1.0.0\n",
            "  Downloading retry_decorator-1.1.1.tar.gz (3.9 kB)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from gsutil->learn2learn) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata<5,>=0.23 in /usr/local/lib/python3.7/dist-packages (from argcomplete>=1.9.4->gsutil->learn2learn) (4.8.1)\n",
            "Requirement already satisfied: rsa==4.7.2 in /usr/local/lib/python3.7/dist-packages (from gcs-oauth2-boto-plugin>=3.0->gsutil->learn2learn) (4.7.2)\n",
            "Collecting boto>=2.29.1\n",
            "  Downloading boto-2.49.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 30.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: oauth2client>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from gcs-oauth2-boto-plugin>=3.0->gsutil->learn2learn) (4.1.3)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa==4.7.2->gcs-oauth2-boto-plugin>=3.0->gsutil->learn2learn) (0.4.8)\n",
            "Collecting pyu2f\n",
            "  Downloading pyu2f-0.1.5.tar.gz (27 kB)\n",
            "Requirement already satisfied: pyparsing<3,>=2.4.2 in /usr/local/lib/python3.7/dist-packages (from httplib2>=0.18->gsutil->learn2learn) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5,>=0.23->argcomplete>=1.9.4->gsutil->learn2learn) (3.6.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=2.2.0->gcs-oauth2-boto-plugin>=3.0->gsutil->learn2learn) (0.2.8)\n",
            "Collecting cryptography>=3.3\n",
            "  Downloading cryptography-35.0.0-cp36-abi3-manylinux_2_24_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 33.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=3.3->pyOpenSSL>=0.13->gsutil->learn2learn) (1.14.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=3.3->pyOpenSSL>=0.13->gsutil->learn2learn) (2.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->learn2learn) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->learn2learn) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->learn2learn) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->learn2learn) (2.10)\n",
            "Building wheels for collected packages: learn2learn, qpth, gsutil, gcs-oauth2-boto-plugin, retry-decorator, pyu2f\n",
            "  Building wheel for learn2learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for learn2learn: filename=learn2learn-0.1.6-cp37-cp37m-linux_x86_64.whl size=945733 sha256=f1eb4f56fc27d6eaf0d1cd05e77c80d5aff1435639f5a88caf71423cc2bc527d\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/d0/99/d65b01d3a6bda35325b9b2e964c7c17169951c915484029b74\n",
            "  Building wheel for qpth (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for qpth: filename=qpth-0.0.15-py3-none-any.whl size=15379 sha256=61e216c0d7310561f4a8faaf88f8e9dfa8e811683b11aa58b90740c7f2728d4a\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/bb/0f/3af358159c8cfc56654d85ba5069b53ab351dee72f5a57c2ff\n",
            "  Building wheel for gsutil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gsutil: filename=gsutil-5.4-py3-none-any.whl size=3715191 sha256=0fffe121db01ba5820a4ba46f0ddfef2fc32054d4e5b7a8502a69ec00046d968\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/d0/fb/d3706aec16bd9e26711966fe39858244ff750985a6a76f0e84\n",
            "  Building wheel for gcs-oauth2-boto-plugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gcs-oauth2-boto-plugin: filename=gcs_oauth2_boto_plugin-3.0-py3-none-any.whl size=23220 sha256=75cc44ed9cb971d12a4404c5d3eb1bf5806a2d1fcdac274f027fdab960068950\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/93/86/cb2140365b10150dbdba338da385c7c18c7cbd9e592e3421db\n",
            "  Building wheel for retry-decorator (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for retry-decorator: filename=retry_decorator-1.1.1-py2.py3-none-any.whl size=3656 sha256=cb42172b0a4af0165047efde04b11eea143b5579be282bc8703d6c56fea67e80\n",
            "  Stored in directory: /root/.cache/pip/wheels/91/39/dc/7359c639e34d9c388a1b3e1dc444363905194afc70f57eb9a5\n",
            "  Building wheel for pyu2f (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyu2f: filename=pyu2f-0.1.5-py3-none-any.whl size=39402 sha256=cb6cd701df779cc566d318c5c0afa2c56286a8aaa6ecd83f591cc11b46e7f906\n",
            "  Stored in directory: /root/.cache/pip/wheels/b3/84/c6/ee8093bf96e2224aca3a9bfa074aa3c86c39208f91055fd60f\n",
            "Successfully built learn2learn qpth gsutil gcs-oauth2-boto-plugin retry-decorator pyu2f\n",
            "Installing collected packages: pyu2f, httplib2, cryptography, retry-decorator, pyOpenSSL, google-reauth, fasteners, boto, monotonic, google-apitools, gcs-oauth2-boto-plugin, qpth, gsutil, learn2learn\n",
            "  Attempting uninstall: httplib2\n",
            "    Found existing installation: httplib2 0.17.4\n",
            "    Uninstalling httplib2-0.17.4:\n",
            "      Successfully uninstalled httplib2-0.17.4\n",
            "Successfully installed boto-2.49.0 cryptography-35.0.0 fasteners-0.16.3 gcs-oauth2-boto-plugin-3.0 google-apitools-0.5.32 google-reauth-0.1.1 gsutil-5.4 httplib2-0.20.1 learn2learn-0.1.6 monotonic-1.6 pyOpenSSL-21.0.0 pyu2f-0.1.5 qpth-0.0.15 retry-decorator-1.1.1\n",
            "Collecting flow-torch\n",
            "  Downloading flow-torch-0.1.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from flow-torch) (1.19.5)\n",
            "Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from flow-torch) (1.9.0+cu111)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.7/dist-packages (from flow-torch) (3.2.2)\n",
            "Requirement already satisfied: tqdm>=4.32.1 in /usr/local/lib/python3.7/dist-packages (from flow-torch) (4.62.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->flow-torch) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->flow-torch) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->flow-torch) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->flow-torch) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=3.2.2->flow-torch) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.1->flow-torch) (3.7.4.3)\n",
            "Building wheels for collected packages: flow-torch\n",
            "  Building wheel for flow-torch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flow-torch: filename=flow_torch-0.1.2-py3-none-any.whl size=22476 sha256=2258d0dc63dd040000b6431344ad5d687dc3c07e424e8c0820cdef3571828b43\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/87/52/051461d341ce95b45ce920ad585f3e95c5b932215af500b196\n",
            "Successfully built flow-torch\n",
            "Installing collected packages: flow-torch\n",
            "Successfully installed flow-torch-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctBIjt6MVKOg"
      },
      "source": [
        "**SUMMARY OF EXP9**\n",
        "---\n",
        "\n",
        "With meta_lr=0.010 fast_lr=0.3 meta_batch_size=32 adaptation_steps=1 num_iterations=3\n",
        "\n",
        "* **Standard MAML** \n",
        "\n",
        "  * Mean accuracy/loss, stddev, and confidence intervals\n",
        "  * (0.5694479288843771, 0.04151392751219393, 0.0033218060277096046)\n",
        "\n",
        "---\n",
        "\n",
        "* **with the following flows [same as Exp8 + 39 batchnorm layers]**\n",
        "\n",
        "  * Mean accuracy/loss, stddev, and confidence intervals\n",
        "  * (0.5921354288343961, 0.04329447271298972, 0.0034642793164360343)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGIkQjZLVCc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "9f399954-5f0c-4eef-9beb-c503a4afa5a4"
      },
      "source": [
        "#@title COMPARE WITH EXP9 standard maml with meta_lr=0.010 fast_lr=0.3 meta_batch_size=32 adaptation_steps=1 num_iterations=3 \n",
        "\n",
        "#@markdown Mean accuracy/loss, stddev, and confidence intervals\n",
        "\n",
        "#@markdown (0.5694479288843771, 0.04151392751219393, 0.0033218060277096046)\n",
        "\n",
        "#@markdown min accuracy: 0.4250000105239451\n",
        "\n",
        "#@markdown max accuracy: 0.6937500145286322\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "  Demonstrates how to:\n",
        "    * use the MAML wrapper for fast-adaptation,\n",
        "    * use the benchmark interface to load Omniglot, and\n",
        "    * sample tasks and split them in adaptation and evaluation sets.\n",
        "\"\"\"\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import learn2learn as l2l\n",
        "\n",
        "from torch import nn, optim\n",
        "\n",
        "\n",
        "\n",
        "def accuracy(predictions, targets):\n",
        "    predictions = predictions.argmax(dim=1).view(targets.shape)\n",
        "    return (predictions == targets).sum().float() / targets.size(0)\n",
        "\n",
        "\n",
        "def fast_adapt(batch, learner, loss, adaptation_steps, shots, ways, device):\n",
        "    data, labels = batch\n",
        "    data, labels = data.to(device), labels.to(device)\n",
        "\n",
        "    # Separate data into adaptation/evalutation sets\n",
        "    adaptation_indices = np.zeros(data.size(0), dtype=bool)\n",
        "    adaptation_indices[np.arange(shots*ways) * 2] = True\n",
        "    evaluation_indices = torch.from_numpy(~adaptation_indices)\n",
        "    adaptation_indices = torch.from_numpy(adaptation_indices)\n",
        "    adaptation_data, adaptation_labels = data[adaptation_indices], labels[adaptation_indices]\n",
        "    evaluation_data, evaluation_labels = data[evaluation_indices], labels[evaluation_indices]\n",
        "\n",
        "    # Adapt the model\n",
        "    for step in range(adaptation_steps):\n",
        "        train_error = loss(learner(adaptation_data), adaptation_labels)\n",
        "        learner.adapt(train_error)\n",
        "\n",
        "    # Evaluate the adapted model\n",
        "    predictions = learner(evaluation_data)\n",
        "    valid_error = loss(predictions, evaluation_labels)\n",
        "    valid_accuracy = accuracy(predictions, evaluation_labels)\n",
        "    return valid_error, valid_accuracy\n",
        "\n",
        "\n",
        "ways=5\n",
        "shots=1\n",
        "meta_lr=0.01\n",
        "fast_lr=0.3\n",
        "meta_batch_size=32\n",
        "adaptation_steps=1\n",
        "num_iterations=3\n",
        "cuda=True\n",
        "# seed=42,\n",
        "\n",
        "# random.seed(seed)\n",
        "# np.random.seed(seed)\n",
        "# torch.manual_seed(seed)\n",
        "device = torch.device('cpu')\n",
        "if cuda:\n",
        "    # torch.cuda.manual_seed(seed)\n",
        "    device = torch.device('cuda')\n",
        "\n",
        "# Load train/validation/test tasksets using the benchmark interface\n",
        "tasksets = l2l.vision.benchmarks.get_tasksets('omniglot',\n",
        "                                              train_ways=ways,\n",
        "                                              train_samples=2*shots,\n",
        "                                              test_ways=ways,\n",
        "                                              test_samples=2*shots,\n",
        "                                              num_tasks=20000,\n",
        "                                              root='~/data',\n",
        ")\n",
        "\n",
        "# Create model\n",
        "model =  l2l.vision.models.OmniglotCNN(ways)\n",
        "#model =  l2l.vision.models.OmniglotFC(28 ** 2, ways)\n",
        "model.to(device)\n",
        "maml = l2l.algorithms.MAML(model, lr=fast_lr, first_order=False)\n",
        "opt = optim.Adam(maml.parameters(), meta_lr)\n",
        "loss = nn.CrossEntropyLoss(reduction='mean')\n",
        "\n",
        "for iteration in range(num_iterations):\n",
        "    opt.zero_grad()\n",
        "    meta_train_error = 0.0\n",
        "    meta_train_accuracy = 0.0\n",
        "    meta_valid_error = 0.0\n",
        "    meta_valid_accuracy = 0.0\n",
        "    for task in range(meta_batch_size):\n",
        "        # Compute meta-training loss\n",
        "        learner = maml.clone()\n",
        "        batch = tasksets.train.sample()\n",
        "        evaluation_error, evaluation_accuracy = fast_adapt(batch,\n",
        "                                                            learner,\n",
        "                                                            loss,\n",
        "                                                            adaptation_steps,\n",
        "                                                            shots,\n",
        "                                                            ways,\n",
        "                                                            device)\n",
        "        evaluation_error.backward()\n",
        "        meta_train_error += evaluation_error.item()\n",
        "        meta_train_accuracy += evaluation_accuracy.item()\n",
        "\n",
        "        # Compute meta-validation loss\n",
        "        # learner = maml.clone()\n",
        "        # batch = tasksets.validation.sample()\n",
        "        # evaluation_error, evaluation_accuracy = fast_adapt(batch,\n",
        "        #                                                     learner,\n",
        "        #                                                     loss,\n",
        "        #                                                     adaptation_steps,\n",
        "        #                                                     shots,\n",
        "        #                                                     ways,\n",
        "        #                                                     device)\n",
        "        # meta_valid_error += evaluation_error.item()\n",
        "        # meta_valid_accuracy += evaluation_accuracy.item()\n",
        "\n",
        "    # Print some metrics\n",
        "    print('\\n')\n",
        "    print('Iteration', iteration)\n",
        "    print('Meta Train Error', meta_train_error / meta_batch_size)\n",
        "    print('Meta Train Accuracy', meta_train_accuracy / meta_batch_size)\n",
        "    # print('Meta Valid Error', meta_valid_error / meta_batch_size)\n",
        "    # print('Meta Valid Accuracy', meta_valid_accuracy / meta_batch_size)\n",
        "\n",
        "    # Average the accumulated gradients and optimize\n",
        "    for p in maml.parameters():\n",
        "        p.grad.data.mul_(1.0 / meta_batch_size)\n",
        "    opt.step()\n",
        "\n",
        "\n",
        "\n",
        "acc_acuracy=[]\n",
        "iterations=600\n",
        "\n",
        "for _ in range(iterations):\n",
        "  meta_test_error = 0.0\n",
        "  meta_test_accuracy = 0.0\n",
        "\n",
        "  for task in range(meta_batch_size):\n",
        "\n",
        "      # Compute meta-testing loss\n",
        "      learner = maml.clone()\n",
        "      batch = tasksets.test.sample()\n",
        "      evaluation_error, evaluation_accuracy = fast_adapt(batch,\n",
        "                                                          learner,\n",
        "                                                          loss,\n",
        "                                                          3,\n",
        "                                                          shots,\n",
        "                                                          ways,\n",
        "                                                          device)\n",
        "      meta_test_error += evaluation_error.item()\n",
        "      meta_test_accuracy += evaluation_accuracy.item()\n",
        "\n",
        "  # print('Meta Test Error', meta_test_error / meta_batch_size)\n",
        "  # print('Meta Test Accuracy', meta_test_accuracy / meta_batch_size)\n",
        "  acc_acuracy.append(meta_test_accuracy/meta_batch_size)\n",
        "\n",
        "\n",
        "acc_acuracy = np.array(acc_acuracy)\n",
        "means = np.mean(acc_acuracy, 0)\n",
        "stds = np.std(acc_acuracy, 0)\n",
        "ci95 = 1.96*stds/np.sqrt(iterations)\n",
        "\n",
        "print('Mean accuracy/loss, stddev, and confidence intervals')\n",
        "print((means, stds, ci95))\n",
        "\n",
        "print(acc_acuracy[acc_acuracy.argmin()])\n",
        "print(acc_acuracy[acc_acuracy.argmax()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:281: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "\n",
            "\n",
            "Iteration 0\n",
            "Meta Train Error 2.0319694709032774\n",
            "Meta Train Accuracy 0.2875000066123903\n",
            "\n",
            "\n",
            "Iteration 1\n",
            "Meta Train Error 1.6078584901988506\n",
            "Meta Train Accuracy 0.4562500095926225\n",
            "\n",
            "\n",
            "Iteration 2\n",
            "Meta Train Error 1.3360285721719265\n",
            "Meta Train Accuracy 0.475000012665987\n",
            "Mean accuracy/loss, stddev, and confidence intervals\n",
            "(0.5694479288843771, 0.04151392751219393, 0.0033218060277096046)\n",
            "0.4250000105239451\n",
            "0.6937500145286322\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-aP248JVBsj",
        "cellView": "form",
        "outputId": "07dd64a2-5744-411e-c79c-4a3b222d31b8"
      },
      "source": [
        "#@title EXP9 meta_lr=0.010 fast_lr=0.3  meta_batch_size=32 num_iterations=3 \n",
        "\n",
        "#@markdown 400 generated images instead of 1 shot per class \n",
        "\n",
        "#@markdown Foud that adding more layers of folws specifically batch normalization flow layer achives higher accuracy \n",
        "\n",
        "#@markdown Flow details: \n",
        "\n",
        "#@markdown    BatchNorm(dim=dim),ActNorm(dim=dim).warm_start(x=trainX),BatchNorm(dim=dim),ActNorm(dim=dim).warm_start(x=trainX),\n",
        "\n",
        "#@markdown    BatchNorm(dim=dim), 6 times \n",
        "\n",
        "#@markdown    Affine(dim=dim),Affine(dim=dim),\n",
        "\n",
        "\n",
        "#@markdown BatchNorm(dim=dim), 39 times \n",
        "\n",
        "#@markdown -------- \n",
        "#@markdown Mean accuracy/loss, stddev, and confidence intervals\n",
        "\n",
        "\n",
        "#@markdown (0.5921354288343961, 0.04329447271298972, 0.0034642793164360343)\n",
        "\n",
        "#@markdown min accuracy: 0.4750000089406967\n",
        "\n",
        "#@markdown max accuracy: 0.7312500113621354\n",
        "\n",
        "\n",
        "\n",
        "def accuracy(predictions, targets):\n",
        "    predictions = predictions.argmax(dim=1).view(targets.shape)\n",
        "    return (predictions == targets).sum().float() / targets.size(0)\n",
        "\n",
        "\n",
        "def fast_adapt(batch, learner, loss, adaptation_steps, shots, ways, device):\n",
        "    data, labels = batch\n",
        "    # print(\"data:  \",data.shape)\n",
        "    data, labels = data.to(device), labels.to(device, dtype=torch.int64)\n",
        "    # Separate data into adaptation/evalutation sets\n",
        "    adaptation_indices = np.zeros(data.size(0), dtype=bool)\n",
        "    adaptation_indices[np.arange(shots*ways) * 2] = True\n",
        "    evaluation_indices = torch.from_numpy(~adaptation_indices)\n",
        "    adaptation_indices = torch.from_numpy(adaptation_indices)\n",
        "    adaptation_data, adaptation_labels = data[adaptation_indices], labels[adaptation_indices]\n",
        "    evaluation_data, evaluation_labels = data[evaluation_indices], labels[evaluation_indices]\n",
        "\n",
        "    # Adapt the model\n",
        "    for step in range(adaptation_steps):\n",
        "        train_error = loss(learner(adaptation_data), adaptation_labels)\n",
        "        learner.adapt(train_error)\n",
        "\n",
        "\n",
        "    # Evaluate the adapted model\n",
        "    predictions = learner(evaluation_data)\n",
        "    valid_error = loss(predictions, evaluation_labels)\n",
        "    valid_accuracy = accuracy(predictions, evaluation_labels)\n",
        "    return valid_error, valid_accuracy\n",
        "\n",
        "\n",
        "def fast_adapt_train(batch, learner, loss, adaptation_steps, shots, ways, device):\n",
        "\n",
        "    data, labels = batch\n",
        "    data, labels = data.to(device), labels.to(device, dtype=torch.int64)\n",
        "    # Separate data into adaptation/evalutation sets\n",
        "    indices = np.random.permutation(data.shape[0])\n",
        "    \n",
        "    adaptation_indices = indices[:360]\n",
        "    evaluation_indices = indices[360:]\n",
        "    adaptation_data, adaptation_labels = data[adaptation_indices], labels[adaptation_indices]\n",
        "    evaluation_data, evaluation_labels = data[evaluation_indices], labels[evaluation_indices]\n",
        "    # print(adaptation_data.shape)\n",
        "    # print(\"modified version\")\n",
        "    # Adapt the model\n",
        "    for step in range(adaptation_steps):\n",
        "        train_error = loss(learner(adaptation_data), adaptation_labels)\n",
        "        learner.adapt(train_error)\n",
        "\n",
        "\n",
        "    # Evaluate the adapted model\n",
        "    predictions = learner(evaluation_data)\n",
        "    valid_error = loss(predictions, evaluation_labels)\n",
        "    valid_accuracy = accuracy(predictions, evaluation_labels)\n",
        "    return valid_error, valid_accuracy\n",
        "\n",
        "def train_flow (trainX ,cond_train , device):\n",
        "\n",
        "  \n",
        "  # trainX has a shape of (count , channel , pixles,pixles)\n",
        "  \n",
        "\n",
        "  trainX = torch.flatten(trainX,1,-1)\n",
        "  # valX = torch.flatten(valX , 1,-1)\n",
        "  dim=trainX.shape[1]\n",
        "  \n",
        "  # print(cond_train)\n",
        "  cond_train = torch.nn.functional.one_hot(cond_train)\n",
        "  # cond_val   = torch.nn.functional.one_hot(cond_val) \n",
        "  # print(cond_train)\n",
        "  cond_dim = cond_train.size(1)\n",
        "  \n",
        "  flow = Sequential(      \n",
        "\n",
        "      # MADE(AffineTransformer(dim=dim) , cond_dim=cond_dim),\n",
        "      # MADE(AffineTransformer(dim=dim) , cond_dim=cond_dim),\n",
        "\n",
        "  # very slow in sampling \n",
        "    # inv_flow(Sigmoid)(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    ActNorm(dim=dim).warm_start(x=trainX),\n",
        "    BatchNorm(dim=dim),\n",
        "    ActNorm(dim=dim).warm_start(x=trainX),\n",
        "    # BatchNorm(dim=dim),\n",
        "    # ActNorm(dim=dim).warm_start(x=trainX),\n",
        "# //////////////////\n",
        "    #     BatchNorm(dim=dim),\n",
        "    # ActNorm(dim=dim).warm_start(x=trainX),\n",
        "    # BatchNorm(dim=dim),\n",
        "    # ActNorm(dim=dim).warm_start(x=trainX),\n",
        "    # BatchNorm(dim=dim),\n",
        "    # ActNorm(dim=dim).warm_start(x=trainX),\n",
        "    # BatchNorm(dim=dim),\n",
        "    # ActNorm(dim=dim).warm_start(x=trainX),\n",
        "    # BatchNorm(dim=dim),\n",
        "    # ActNorm(dim=dim).warm_start(x=trainX),\n",
        "# ////////\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    # MADE(DSF(dim=dim), cond_dim=cond_dim),\n",
        "    Affine(dim=dim),  \n",
        "    Affine(dim=dim),  \n",
        "BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "        BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "        BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "      # BatchNorm(dim=dim),\n",
        "      # Shuffle(dim=dim),\n",
        "      # CouplingLayers(AffineTransformer(dim=dim//2 ) ,dim=dim),\n",
        "\n",
        "  ).to(device)\n",
        "  train_losses, val_losses = train(flow, trainX, trainX ,cond_train=cond_train, cond_val=cond_train , patience=100 ,batch_size=8,n_epochs=1000)\n",
        " \n",
        "  test_labels = np.random.choice(5, size=(400))\n",
        "  test_labels = torch.from_numpy(test_labels)\n",
        "  test_cond = torch.nn.functional.one_hot(test_labels)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    train_data = flow.sample(400,cond=test_cond.to(device)).cpu()\n",
        "\n",
        "  # return train_data, train_losses , val_losses , mean , var\n",
        "  return torch.reshape(train_data , (400,1,28,28)) , test_labels\n",
        "\n",
        "\n",
        "\n",
        "ways=5\n",
        "shots=1\n",
        "meta_lr=0.01\n",
        "fast_lr=0.3\n",
        "meta_batch_size=32\n",
        "adaptation_steps=1\n",
        "num_iterations=3\n",
        "cuda=True\n",
        "# seed=42\n",
        "# Load train/validation/test tasksets using the benchmark interface\n",
        "tasksets = l2l.vision.benchmarks.get_tasksets('omniglot',\n",
        "                                                  train_ways=ways,\n",
        "                                                  train_samples=2*shots,\n",
        "                                                  test_ways=ways,\n",
        "                                                  test_samples=2*shots,\n",
        "                                                  num_tasks=20000,\n",
        "                                                  root='~/data',\n",
        "    )\n",
        "\n",
        "# dim = 28*28\n",
        "\n",
        "device = torch.device('cpu')\n",
        "if cuda:\n",
        "  # torch.cuda.manual_seed(seed)\n",
        "  device = torch.device('cuda')\n",
        "\n",
        "# Create model\n",
        "model = l2l.vision.models.OmniglotCNN(ways)\n",
        "# model = l2l.vision.models.OmniglotFC(28 ** 2, ways)\n",
        "model.to(device)\n",
        "maml = l2l.algorithms.MAML(model, lr=fast_lr, first_order=False)\n",
        "opt = optim.Adam(maml.parameters(), meta_lr)\n",
        "loss = nn.CrossEntropyLoss(reduction='mean')\n",
        "\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "for iteration in tqdm(range(num_iterations)):\n",
        "    opt.zero_grad()\n",
        "    meta_train_error = 0.0\n",
        "    meta_train_accuracy = 0.0\n",
        "    meta_valid_error = 0.0\n",
        "    meta_valid_accuracy = 0.0\n",
        "\n",
        "    for task in range(meta_batch_size):\n",
        "        # Compute meta-training loss\n",
        "        # learner = maml.clone()\n",
        "\n",
        "        # generate batch the batch contains # ways*shots , channels , img size  and labels \n",
        "        train_batch = tasksets.train.sample()\n",
        "        val_batch = tasksets.validation.sample()\n",
        "\n",
        "        # split batch based on classes in labels then   labels.split(int(data.shape[0]/ways))\n",
        "        train_data, train_labels = train_batch\n",
        "        val_data , val_labels= val_batch\n",
        "\n",
        "        \n",
        "        train_data_generator ,train_lable_generator  = train_flow (train_data ,train_labels  , device)\n",
        "\n",
        "        # train_data_generator = torch.cat(train_data_generator)\n",
        "        # train_lable_generator = torch.cat(train_lable_generator)\n",
        "        \n",
        "        batch = [train_data_generator ,train_lable_generator]\n",
        "\n",
        "        learner = maml.clone()            \n",
        "        \n",
        "        evaluation_error, evaluation_accuracy = fast_adapt_train(batch,\n",
        "                                                            learner,\n",
        "                                                            loss,\n",
        "                                                            adaptation_steps,\n",
        "                                                            shots,\n",
        "                                                            ways,\n",
        "                                                            device)\n",
        "        evaluation_error.backward()\n",
        "        meta_train_error += evaluation_error.item()\n",
        "        meta_train_accuracy += evaluation_accuracy.item()\n",
        "\n",
        "# ''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
        "\n",
        "        # # Compute meta-validation loss\n",
        "        # batch = tasksets.validation.sample()\n",
        "        \n",
        "        # learner = maml.clone()\n",
        "        # evaluation_error, evaluation_accuracy = fast_adapt(batch,learner,loss,adaptation_steps,shots,ways,\n",
        "        #                                                     device)\n",
        "        # meta_valid_error += evaluation_error.item()\n",
        "        # meta_valid_accuracy += evaluation_accuracy.item()\n",
        "\n",
        "    # Print some metrics\n",
        "    print('\\n')\n",
        "    print('Iteration', iteration)\n",
        "    print('Meta Train Error', meta_train_error / meta_batch_size)\n",
        "    print('Meta Train Accuracy', meta_train_accuracy / meta_batch_size)\n",
        "    # print('Meta Valid Error', meta_valid_error / meta_batch_size)\n",
        "    # print('Meta Valid Accuracy', meta_valid_accuracy / meta_batch_size)\n",
        "\n",
        "    # Average the accumulated gradients and optimize\n",
        "    for p in maml.parameters():\n",
        "        p.grad.data.mul_(1.0 / meta_batch_size)\n",
        "    opt.step()\n",
        "\n",
        "\n",
        "acc_acuracy=[]\n",
        "iterations= 600\n",
        "for _ in range(iterations):\n",
        "  meta_test_error = 0.0\n",
        "  meta_test_accuracy = 0.0\n",
        "\n",
        "  for task in range(meta_batch_size):\n",
        "\n",
        "      # Compute meta-testing loss\n",
        "      learner = maml.clone()\n",
        "      batch = tasksets.test.sample()\n",
        "      evaluation_error, evaluation_accuracy = fast_adapt(batch,\n",
        "                                                          learner,\n",
        "                                                          loss,\n",
        "                                                          3,\n",
        "                                                          shots,\n",
        "                                                          ways,\n",
        "                                                          device)\n",
        "      meta_test_error += evaluation_error.item()\n",
        "      meta_test_accuracy += evaluation_accuracy.item()\n",
        "\n",
        "  # print('Meta Test Error', meta_test_error / meta_batch_size)\n",
        "  # print('Meta Test Accuracy', meta_test_accuracy / meta_batch_size)\n",
        "  acc_acuracy.append(meta_test_accuracy/meta_batch_size)\n",
        "\n",
        "\n",
        "acc_acuracy = np.array(acc_acuracy)\n",
        "means = np.mean(acc_acuracy, 0)\n",
        "stds = np.std(acc_acuracy, 0)\n",
        "ci95 = 1.96*stds/np.sqrt(iterations)\n",
        "\n",
        "print('Mean accuracy/loss, stddev, and confidence intervals')\n",
        "print((means, stds, ci95))\n",
        "\n",
        "print(acc_acuracy[acc_acuracy.argmin()])\n",
        "print(acc_acuracy[acc_acuracy.argmax()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:281: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "125it [00:26,  4.69it/s, epoch_progress=100%, train_loss=-2.663e+05, last_val_loss=+4.908e+32, best_epoch=25, best_loss=+8.297e+31]\n",
            "139it [00:29,  4.69it/s, epoch_progress=100%, train_loss=-3.339e+05, last_val_loss=+2.364e+32, best_epoch=39, best_loss=+7.515e+31]\n",
            "121it [00:26,  4.65it/s, epoch_progress=100%, train_loss=-3.160e+05, last_val_loss=+7.654e+32, best_epoch=21, best_loss=+1.500e+32]\n",
            "120it [00:26,  4.48it/s, epoch_progress=100%, train_loss=-2.746e+05, last_val_loss=+3.316e+32, best_epoch=20, best_loss=+9.277e+31]\n",
            "199it [00:45,  4.41it/s, epoch_progress=100%, train_loss=-2.786e+05, last_val_loss=+2.296e+32, best_epoch=99, best_loss=+7.046e+31]\n",
            "123it [00:27,  4.41it/s, epoch_progress=100%, train_loss=-3.067e+05, last_val_loss=+1.186e+32, best_epoch=23, best_loss=+4.757e+31]\n",
            "119it [00:27,  4.32it/s, epoch_progress=100%, train_loss=-3.181e+05, last_val_loss=+3.487e+32, best_epoch=19, best_loss=+3.454e+31]\n",
            "122it [00:27,  4.40it/s, epoch_progress=100%, train_loss=-2.813e+05, last_val_loss=+1.875e+32, best_epoch=22, best_loss=+7.898e+31]\n",
            "127it [00:29,  4.28it/s, epoch_progress=100%, train_loss=-3.606e+05, last_val_loss=+1.915e+32, best_epoch=27, best_loss=+6.399e+31]\n",
            "121it [00:27,  4.33it/s, epoch_progress=100%, train_loss=-2.570e+05, last_val_loss=+6.948e+32, best_epoch=21, best_loss=+6.824e+31]\n",
            "116it [00:26,  4.34it/s, epoch_progress=100%, train_loss=-3.072e+05, last_val_loss=+3.872e+32, best_epoch=16, best_loss=+5.011e+31]\n",
            "135it [00:31,  4.30it/s, epoch_progress=100%, train_loss=-3.356e+05, last_val_loss=+4.365e+32, best_epoch=35, best_loss=+9.354e+31]\n",
            "119it [00:27,  4.27it/s, epoch_progress=100%, train_loss=-3.145e+05, last_val_loss=+6.691e+32, best_epoch=19, best_loss=+5.541e+31]\n",
            "116it [00:25,  4.47it/s, epoch_progress=100%, train_loss=-2.942e+05, last_val_loss=+2.921e+32, best_epoch=16, best_loss=+2.711e+31]\n",
            "141it [00:32,  4.30it/s, epoch_progress=100%, train_loss=-2.888e+05, last_val_loss=+1.730e+32, best_epoch=41, best_loss=+9.042e+31]\n",
            "117it [00:27,  4.31it/s, epoch_progress=100%, train_loss=-3.267e+05, last_val_loss=+3.364e+32, best_epoch=17, best_loss=+4.756e+31]\n",
            "115it [00:25,  4.51it/s, epoch_progress=100%, train_loss=-2.980e+05, last_val_loss=+1.306e+32, best_epoch=15, best_loss=+3.696e+31]\n",
            "206it [00:45,  4.54it/s, epoch_progress=100%, train_loss=-3.155e+05, last_val_loss=+5.266e+32, best_epoch=106, best_loss=+6.579e+31]\n",
            "131it [00:29,  4.50it/s, epoch_progress=100%, train_loss=-3.267e+05, last_val_loss=+1.676e+32, best_epoch=31, best_loss=+1.027e+32]\n",
            "117it [00:25,  4.59it/s, epoch_progress=100%, train_loss=-3.104e+05, last_val_loss=+2.934e+32, best_epoch=17, best_loss=+2.988e+31]\n",
            "136it [00:29,  4.60it/s, epoch_progress=100%, train_loss=-2.099e+05, last_val_loss=+3.986e+32, best_epoch=36, best_loss=+9.155e+31]\n",
            "119it [00:25,  4.65it/s, epoch_progress=100%, train_loss=-3.704e+05, last_val_loss=+2.863e+32, best_epoch=19, best_loss=+6.904e+31]\n",
            "142it [00:31,  4.58it/s, epoch_progress=100%, train_loss=-3.465e+05, last_val_loss=+3.230e+32, best_epoch=42, best_loss=+1.227e+32]\n",
            "165it [00:36,  4.56it/s, epoch_progress=100%, train_loss=-3.285e+05, last_val_loss=+2.760e+32, best_epoch=65, best_loss=+8.091e+31]\n",
            "114it [00:24,  4.59it/s, epoch_progress=100%, train_loss=-3.067e+05, last_val_loss=+2.101e+32, best_epoch=14, best_loss=+2.071e+31]\n",
            "118it [00:27,  4.30it/s, epoch_progress=100%, train_loss=-3.666e+05, last_val_loss=+3.815e+32, best_epoch=18, best_loss=+6.584e+31]\n",
            "119it [00:27,  4.29it/s, epoch_progress=100%, train_loss=-3.121e+05, last_val_loss=+4.255e+32, best_epoch=19, best_loss=+3.988e+31]\n",
            "125it [00:28,  4.42it/s, epoch_progress=100%, train_loss=-2.803e+05, last_val_loss=+3.030e+32, best_epoch=25, best_loss=+8.550e+31]\n",
            "188it [00:40,  4.59it/s, epoch_progress=100%, train_loss=-2.866e+05, last_val_loss=+7.745e+32, best_epoch=88, best_loss=+8.514e+31]\n",
            "119it [00:26,  4.56it/s, epoch_progress=100%, train_loss=-3.070e+05, last_val_loss=+3.803e+32, best_epoch=19, best_loss=+1.068e+32]\n",
            "229it [00:49,  4.60it/s, epoch_progress=100%, train_loss=-3.251e+05, last_val_loss=+6.499e+32, best_epoch=129, best_loss=+8.295e+31]\n",
            "120it [00:26,  4.58it/s, epoch_progress=100%, train_loss=-2.978e+05, last_val_loss=+2.471e+32, best_epoch=20, best_loss=+5.956e+31]\n",
            " 33%|███▎      | 1/3 [16:15<32:30, 975.47s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Iteration 0\n",
            "Meta Train Error 1.9917625673115253\n",
            "Meta Train Accuracy 0.21328125381842256\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "186it [00:41,  4.54it/s, epoch_progress=100%, train_loss=-3.490e+05, last_val_loss=+3.170e+32, best_epoch=86, best_loss=+8.272e+31]\n",
            "117it [00:26,  4.42it/s, epoch_progress=100%, train_loss=-2.932e+05, last_val_loss=+1.173e+32, best_epoch=17, best_loss=+6.877e+30]\n",
            "128it [00:28,  4.45it/s, epoch_progress=100%, train_loss=-3.472e+05, last_val_loss=+3.435e+32, best_epoch=28, best_loss=+9.085e+31]\n",
            "120it [00:26,  4.53it/s, epoch_progress=100%, train_loss=-2.981e+05, last_val_loss=+2.853e+32, best_epoch=20, best_loss=+8.325e+31]\n",
            "120it [00:25,  4.64it/s, epoch_progress=100%, train_loss=-2.962e+05, last_val_loss=+2.420e+32, best_epoch=20, best_loss=+2.048e+31]\n",
            "181it [00:40,  4.48it/s, epoch_progress=100%, train_loss=-3.498e+05, last_val_loss=+6.757e+32, best_epoch=81, best_loss=+1.164e+32]\n",
            "173it [00:38,  4.49it/s, epoch_progress=100%, train_loss=-2.964e+05, last_val_loss=+3.793e+32, best_epoch=73, best_loss=+5.195e+31]\n",
            "148it [00:33,  4.41it/s, epoch_progress=100%, train_loss=-2.918e+05, last_val_loss=+4.748e+32, best_epoch=48, best_loss=+1.129e+32]\n",
            "119it [00:26,  4.42it/s, epoch_progress=100%, train_loss=-3.729e+05, last_val_loss=+2.890e+32, best_epoch=19, best_loss=+6.261e+31]\n",
            "151it [00:34,  4.38it/s, epoch_progress=100%, train_loss=-3.084e+05, last_val_loss=+4.733e+32, best_epoch=51, best_loss=+1.020e+32]\n",
            "137it [00:31,  4.41it/s, epoch_progress=100%, train_loss=-3.097e+05, last_val_loss=+2.144e+32, best_epoch=37, best_loss=+8.674e+31]\n",
            "141it [00:30,  4.65it/s, epoch_progress=100%, train_loss=-2.485e+05, last_val_loss=+2.029e+32, best_epoch=41, best_loss=+7.427e+31]\n",
            "126it [00:27,  4.60it/s, epoch_progress=100%, train_loss=-2.411e+05, last_val_loss=+1.476e+32, best_epoch=26, best_loss=+7.097e+31]\n",
            "122it [00:26,  4.61it/s, epoch_progress=100%, train_loss=-3.346e+05, last_val_loss=+2.705e+32, best_epoch=22, best_loss=+6.458e+31]\n",
            "218it [00:48,  4.53it/s, epoch_progress=100%, train_loss=-2.850e+05, last_val_loss=+2.908e+32, best_epoch=118, best_loss=+1.155e+32]\n",
            "141it [00:33,  4.25it/s, epoch_progress=100%, train_loss=-3.163e+05, last_val_loss=+3.851e+32, best_epoch=41, best_loss=+1.078e+32]\n",
            "127it [00:28,  4.42it/s, epoch_progress=100%, train_loss=-2.811e+05, last_val_loss=+3.780e+32, best_epoch=27, best_loss=+9.774e+31]\n",
            "119it [00:26,  4.44it/s, epoch_progress=100%, train_loss=-2.885e+05, last_val_loss=+1.952e+32, best_epoch=19, best_loss=+8.280e+31]\n",
            "179it [00:41,  4.32it/s, epoch_progress=100%, train_loss=-2.983e+05, last_val_loss=+6.001e+32, best_epoch=79, best_loss=+7.113e+31]\n",
            "169it [00:39,  4.32it/s, epoch_progress=100%, train_loss=-3.781e+05, last_val_loss=+7.762e+32, best_epoch=69, best_loss=+9.600e+31]\n",
            "119it [00:26,  4.58it/s, epoch_progress=100%, train_loss=-2.376e+05, last_val_loss=+2.244e+32, best_epoch=19, best_loss=+5.206e+31]\n",
            "118it [00:26,  4.53it/s, epoch_progress=100%, train_loss=-3.251e+05, last_val_loss=+4.343e+32, best_epoch=18, best_loss=+3.674e+31]\n",
            "119it [00:27,  4.37it/s, epoch_progress=100%, train_loss=-2.611e+05, last_val_loss=+2.346e+32, best_epoch=19, best_loss=+6.992e+31]\n",
            "135it [00:31,  4.28it/s, epoch_progress=100%, train_loss=-3.337e+05, last_val_loss=+4.097e+32, best_epoch=35, best_loss=+8.107e+31]\n",
            "121it [00:28,  4.30it/s, epoch_progress=100%, train_loss=-3.201e+05, last_val_loss=+1.085e+33, best_epoch=21, best_loss=+6.872e+31]\n",
            "120it [00:28,  4.28it/s, epoch_progress=100%, train_loss=-3.376e+05, last_val_loss=+4.044e+32, best_epoch=20, best_loss=+5.976e+31]\n",
            "121it [00:28,  4.25it/s, epoch_progress=100%, train_loss=-2.580e+05, last_val_loss=+2.229e+32, best_epoch=21, best_loss=+3.146e+31]\n",
            "140it [00:32,  4.30it/s, epoch_progress=100%, train_loss=-3.612e+05, last_val_loss=+4.200e+32, best_epoch=40, best_loss=+5.612e+31]\n",
            "120it [00:28,  4.24it/s, epoch_progress=100%, train_loss=-3.679e+05, last_val_loss=+2.322e+32, best_epoch=20, best_loss=+7.765e+31]\n",
            "127it [00:29,  4.25it/s, epoch_progress=100%, train_loss=-3.309e+05, last_val_loss=+3.357e+32, best_epoch=27, best_loss=+1.445e+32]\n",
            "181it [00:41,  4.34it/s, epoch_progress=100%, train_loss=-2.496e+05, last_val_loss=+4.566e+36, best_epoch=81, best_loss=+7.231e+31]\n",
            "116it [00:26,  4.32it/s, epoch_progress=100%, train_loss=-2.914e+05, last_val_loss=+1.934e+32, best_epoch=16, best_loss=+2.175e+31]\n",
            " 67%|██████▋   | 2/3 [33:14<16:41, 1001.35s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Iteration 1\n",
            "Meta Train Error 1.8223151452839375\n",
            "Meta Train Accuracy 0.20625000400468707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "128it [00:29,  4.28it/s, epoch_progress=100%, train_loss=-3.236e+05, last_val_loss=+4.414e+32, best_epoch=28, best_loss=+8.932e+31]\n",
            "131it [00:29,  4.42it/s, epoch_progress=100%, train_loss=-2.957e+05, last_val_loss=+2.301e+32, best_epoch=31, best_loss=+9.827e+31]\n",
            "136it [00:30,  4.45it/s, epoch_progress=100%, train_loss=-2.843e+05, last_val_loss=+1.814e+32, best_epoch=36, best_loss=+1.149e+32]\n",
            "252it [00:54,  4.58it/s, epoch_progress=100%, train_loss=-2.924e+05, last_val_loss=+5.221e+32, best_epoch=152, best_loss=+7.312e+31]\n",
            "132it [00:28,  4.58it/s, epoch_progress=100%, train_loss=-3.057e+05, last_val_loss=+2.534e+32, best_epoch=32, best_loss=+1.019e+32]\n",
            "136it [00:30,  4.48it/s, epoch_progress=100%, train_loss=-2.826e+05, last_val_loss=+2.463e+32, best_epoch=36, best_loss=+1.545e+32]\n",
            "116it [00:26,  4.38it/s, epoch_progress=100%, train_loss=-3.066e+05, last_val_loss=+4.743e+32, best_epoch=16, best_loss=+8.149e+31]\n",
            "143it [00:33,  4.25it/s, epoch_progress=100%, train_loss=-3.303e+05, last_val_loss=+6.125e+32, best_epoch=43, best_loss=+1.638e+32]\n",
            "133it [00:30,  4.29it/s, epoch_progress=100%, train_loss=-3.221e+05, last_val_loss=+4.583e+32, best_epoch=33, best_loss=+1.006e+32]\n",
            "118it [00:27,  4.34it/s, epoch_progress=100%, train_loss=-2.988e+05, last_val_loss=+1.137e+32, best_epoch=18, best_loss=+3.375e+31]\n",
            "137it [00:31,  4.29it/s, epoch_progress=100%, train_loss=-3.030e+05, last_val_loss=+6.260e+32, best_epoch=37, best_loss=+1.161e+32]\n",
            "120it [00:28,  4.28it/s, epoch_progress=100%, train_loss=-2.909e+05, last_val_loss=+8.510e+32, best_epoch=20, best_loss=+7.970e+31]\n",
            "131it [00:29,  4.51it/s, epoch_progress=100%, train_loss=-3.048e+05, last_val_loss=+3.408e+32, best_epoch=31, best_loss=+8.335e+31]\n",
            "101it [00:21,  4.65it/s, epoch_progress=100%, train_loss=-3.725e+05, last_val_loss=+2.133e+32, best_epoch=1, best_loss=+2.243e+06]\n",
            "120it [00:25,  4.64it/s, epoch_progress=100%, train_loss=-3.113e+05, last_val_loss=+3.334e+32, best_epoch=20, best_loss=+7.896e+31]\n",
            "205it [00:43,  4.66it/s, epoch_progress=100%, train_loss=-3.219e+05, last_val_loss=+1.060e+33, best_epoch=105, best_loss=+9.945e+31]\n",
            "119it [00:25,  4.60it/s, epoch_progress=100%, train_loss=-2.645e+05, last_val_loss=+4.985e+32, best_epoch=19, best_loss=+6.029e+31]\n",
            "134it [00:30,  4.45it/s, epoch_progress=100%, train_loss=-3.317e+05, last_val_loss=+2.795e+32, best_epoch=34, best_loss=+1.290e+32]\n",
            "133it [00:30,  4.31it/s, epoch_progress=100%, train_loss=-3.469e+05, last_val_loss=+5.461e+32, best_epoch=33, best_loss=+7.663e+31]\n",
            "131it [00:30,  4.36it/s, epoch_progress=100%, train_loss=-3.165e+05, last_val_loss=+3.155e+32, best_epoch=31, best_loss=+1.124e+32]\n",
            "158it [00:34,  4.54it/s, epoch_progress=100%, train_loss=-3.497e+05, last_val_loss=+3.198e+32, best_epoch=58, best_loss=+7.570e+31]\n",
            "101it [00:22,  4.57it/s, epoch_progress=100%, train_loss=-3.256e+05, last_val_loss=+6.510e+32, best_epoch=1, best_loss=+3.250e+06]\n",
            "229it [00:50,  4.49it/s, epoch_progress=100%, train_loss=-3.148e+05, last_val_loss=+1.102e+33, best_epoch=129, best_loss=+5.084e+31]\n",
            "177it [00:38,  4.58it/s, epoch_progress=100%, train_loss=-3.023e+05, last_val_loss=+6.250e+32, best_epoch=77, best_loss=+1.125e+32]\n",
            "121it [00:26,  4.63it/s, epoch_progress=100%, train_loss=-2.820e+05, last_val_loss=+3.937e+32, best_epoch=21, best_loss=+8.037e+31]\n",
            "123it [00:27,  4.48it/s, epoch_progress=100%, train_loss=-3.554e+05, last_val_loss=+4.574e+32, best_epoch=23, best_loss=+9.255e+31]\n",
            "128it [00:29,  4.41it/s, epoch_progress=100%, train_loss=-3.116e+05, last_val_loss=+2.036e+32, best_epoch=28, best_loss=+8.802e+31]\n",
            "117it [00:25,  4.54it/s, epoch_progress=100%, train_loss=-3.262e+05, last_val_loss=+6.226e+32, best_epoch=17, best_loss=+1.130e+32]\n",
            "149it [00:32,  4.54it/s, epoch_progress=100%, train_loss=-3.064e+05, last_val_loss=+4.135e+32, best_epoch=49, best_loss=+9.350e+31]\n",
            "116it [00:25,  4.52it/s, epoch_progress=100%, train_loss=-2.732e+05, last_val_loss=+6.417e+32, best_epoch=16, best_loss=+2.296e+31]\n",
            "178it [00:39,  4.50it/s, epoch_progress=100%, train_loss=-3.250e+05, last_val_loss=+4.374e+32, best_epoch=78, best_loss=+1.769e+32]\n",
            "118it [00:26,  4.47it/s, epoch_progress=100%, train_loss=-3.579e+05, last_val_loss=+4.289e+32, best_epoch=18, best_loss=+4.015e+31]\n",
            "100%|██████████| 3/3 [50:03<00:00, 1001.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 2\n",
            "Meta Train Error 1.8441716134548187\n",
            "Meta Train Accuracy 0.20781250426080078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean accuracy/loss, stddev, and confidence intervals\n",
            "(0.5921354288343961, 0.04329447271298972, 0.0034642793164360343)\n",
            "0.4750000089406967\n",
            "0.7312500113621354\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62THNzXM7ojU"
      },
      "source": [
        "\n",
        "**SUMMARY OF EXP8**\n",
        "---\n",
        "\n",
        "With meta_lr=0.010 fast_lr=0.30 meta_batch_size=16 adaptation_steps=1  num_iterations=3 \n",
        "\n",
        "* **Standard MAML**\n",
        "\n",
        "  * Mean accuracy/loss, stddev, and confidence intervals\n",
        "  * (0.5487500118821238, 0.057567895473163384, 0.004606391002854177)\n",
        "\n",
        "\n",
        "-----\n",
        "\n",
        "* **with the following flows [same as EXP8 + more 5 batchnorm layers]**\n",
        "\n",
        "  * Mean accuracy/loss, stddev, and confidence intervals\n",
        "  * (0.6348125119693577, 0.0569568206496079, 0.004557494833450018)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqFCh_zB7oDc",
        "cellView": "form",
        "outputId": "5262db7d-ccac-4bcd-c8a6-0f492007b096"
      },
      "source": [
        "#@title COMPARE WITH EXP8 standard maml with meta_lr=0.010 fast_lr=0.30 meta_batch_size=16 adaptation_steps=1 num_iterations=3\n",
        "\n",
        "#@markdown Mean accuracy/loss, stddev, and confidence intervals\n",
        "\n",
        "#@markdown (0.5487500118821238, 0.057567895473163384, 0.004606391002854177)\n",
        "\n",
        "#@markdown min accuracy: 0.40000000689178705\n",
        "\n",
        "#@markdown max accuracy: 0.7125000134110451 \n",
        "\n",
        "\"\"\"\n",
        "  Demonstrates how to:\n",
        "    * use the MAML wrapper for fast-adaptation,\n",
        "    * use the benchmark interface to load Omniglot, and\n",
        "    * sample tasks and split them in adaptation and evaluation sets.\n",
        "\"\"\"\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import learn2learn as l2l\n",
        "\n",
        "from torch import nn, optim\n",
        "\n",
        "\n",
        "\n",
        "def accuracy(predictions, targets):\n",
        "    predictions = predictions.argmax(dim=1).view(targets.shape)\n",
        "    return (predictions == targets).sum().float() / targets.size(0)\n",
        "\n",
        "\n",
        "def fast_adapt(batch, learner, loss, adaptation_steps, shots, ways, device):\n",
        "    data, labels = batch\n",
        "    data, labels = data.to(device), labels.to(device)\n",
        "\n",
        "    # Separate data into adaptation/evalutation sets\n",
        "    adaptation_indices = np.zeros(data.size(0), dtype=bool)\n",
        "    adaptation_indices[np.arange(shots*ways) * 2] = True\n",
        "    evaluation_indices = torch.from_numpy(~adaptation_indices)\n",
        "    adaptation_indices = torch.from_numpy(adaptation_indices)\n",
        "    adaptation_data, adaptation_labels = data[adaptation_indices], labels[adaptation_indices]\n",
        "    evaluation_data, evaluation_labels = data[evaluation_indices], labels[evaluation_indices]\n",
        "\n",
        "    # Adapt the model\n",
        "    for step in range(adaptation_steps):\n",
        "        train_error = loss(learner(adaptation_data), adaptation_labels)\n",
        "        learner.adapt(train_error)\n",
        "\n",
        "    # Evaluate the adapted model\n",
        "    predictions = learner(evaluation_data)\n",
        "    valid_error = loss(predictions, evaluation_labels)\n",
        "    valid_accuracy = accuracy(predictions, evaluation_labels)\n",
        "    return valid_error, valid_accuracy\n",
        "\n",
        "\n",
        "ways=5\n",
        "shots=1\n",
        "meta_lr=0.010\n",
        "fast_lr=0.30\n",
        "meta_batch_size=16\n",
        "adaptation_steps=1\n",
        "num_iterations=3\n",
        "cuda=True\n",
        "# seed=42,\n",
        "\n",
        "# random.seed(seed)\n",
        "# np.random.seed(seed)\n",
        "# torch.manual_seed(seed)\n",
        "device = torch.device('cpu')\n",
        "if cuda:\n",
        "    # torch.cuda.manual_seed(seed)\n",
        "    device = torch.device('cuda')\n",
        "\n",
        "# Load train/validation/test tasksets using the benchmark interface\n",
        "tasksets = l2l.vision.benchmarks.get_tasksets('omniglot',\n",
        "                                              train_ways=ways,\n",
        "                                              train_samples=2*shots,\n",
        "                                              test_ways=ways,\n",
        "                                              test_samples=2*shots,\n",
        "                                              num_tasks=20000,\n",
        "                                              root='~/data',\n",
        ")\n",
        "\n",
        "# Create model\n",
        "model =  l2l.vision.models.OmniglotCNN(ways)\n",
        "#model =  l2l.vision.models.OmniglotFC(28 ** 2, ways)\n",
        "model.to(device)\n",
        "maml = l2l.algorithms.MAML(model, lr=fast_lr, first_order=False)\n",
        "opt = optim.Adam(maml.parameters(), meta_lr)\n",
        "loss = nn.CrossEntropyLoss(reduction='mean')\n",
        "\n",
        "for iteration in range(num_iterations):\n",
        "    opt.zero_grad()\n",
        "    meta_train_error = 0.0\n",
        "    meta_train_accuracy = 0.0\n",
        "    meta_valid_error = 0.0\n",
        "    meta_valid_accuracy = 0.0\n",
        "    for task in range(meta_batch_size):\n",
        "        # Compute meta-training loss\n",
        "        learner = maml.clone()\n",
        "        batch = tasksets.train.sample()\n",
        "        evaluation_error, evaluation_accuracy = fast_adapt(batch,\n",
        "                                                            learner,\n",
        "                                                            loss,\n",
        "                                                            adaptation_steps,\n",
        "                                                            shots,\n",
        "                                                            ways,\n",
        "                                                            device)\n",
        "        evaluation_error.backward()\n",
        "        meta_train_error += evaluation_error.item()\n",
        "        meta_train_accuracy += evaluation_accuracy.item()\n",
        "\n",
        "        # Compute meta-validation loss\n",
        "        # learner = maml.clone()\n",
        "        # batch = tasksets.validation.sample()\n",
        "        # evaluation_error, evaluation_accuracy = fast_adapt(batch,\n",
        "        #                                                     learner,\n",
        "        #                                                     loss,\n",
        "        #                                                     adaptation_steps,\n",
        "        #                                                     shots,\n",
        "        #                                                     ways,\n",
        "        #                                                     device)\n",
        "        # meta_valid_error += evaluation_error.item()\n",
        "        # meta_valid_accuracy += evaluation_accuracy.item()\n",
        "\n",
        "    # Print some metrics\n",
        "    print('\\n')\n",
        "    print('Iteration', iteration)\n",
        "    print('Meta Train Error', meta_train_error / meta_batch_size)\n",
        "    print('Meta Train Accuracy', meta_train_accuracy / meta_batch_size)\n",
        "    # print('Meta Valid Error', meta_valid_error / meta_batch_size)\n",
        "    # print('Meta Valid Accuracy', meta_valid_accuracy / meta_batch_size)\n",
        "\n",
        "    # Average the accumulated gradients and optimize\n",
        "    for p in maml.parameters():\n",
        "        p.grad.data.mul_(1.0 / meta_batch_size)\n",
        "    opt.step()\n",
        "\n",
        "\n",
        "\n",
        "acc_acuracy=[]\n",
        "iterations=600\n",
        "\n",
        "for _ in range(iterations):\n",
        "  meta_test_error = 0.0\n",
        "  meta_test_accuracy = 0.0\n",
        "\n",
        "  for task in range(meta_batch_size):\n",
        "\n",
        "      # Compute meta-testing loss\n",
        "      learner = maml.clone()\n",
        "      batch = tasksets.test.sample()\n",
        "      evaluation_error, evaluation_accuracy = fast_adapt(batch,\n",
        "                                                          learner,\n",
        "                                                          loss,\n",
        "                                                          3,\n",
        "                                                          shots,\n",
        "                                                          ways,\n",
        "                                                          device)\n",
        "      meta_test_error += evaluation_error.item()\n",
        "      meta_test_accuracy += evaluation_accuracy.item()\n",
        "\n",
        "  # print('Meta Test Error', meta_test_error / meta_batch_size)\n",
        "  # print('Meta Test Accuracy', meta_test_accuracy / meta_batch_size)\n",
        "  acc_acuracy.append(meta_test_accuracy/meta_batch_size)\n",
        "\n",
        "\n",
        "acc_acuracy = np.array(acc_acuracy)\n",
        "means = np.mean(acc_acuracy, 0)\n",
        "stds = np.std(acc_acuracy, 0)\n",
        "ci95 = 1.96*stds/np.sqrt(iterations)\n",
        "\n",
        "print('Mean accuracy/loss, stddev, and confidence intervals')\n",
        "print((means, stds, ci95))\n",
        "\n",
        "print(acc_acuracy[acc_acuracy.argmin()])\n",
        "print(acc_acuracy[acc_acuracy.argmax()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:281: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "\n",
            "\n",
            "Iteration 0\n",
            "Meta Train Error 2.2285805493593216\n",
            "Meta Train Accuracy 0.32500000577419996\n",
            "\n",
            "\n",
            "Iteration 1\n",
            "Meta Train Error 1.5777313373982906\n",
            "Meta Train Accuracy 0.4875000137835741\n",
            "\n",
            "\n",
            "Iteration 2\n",
            "Meta Train Error 1.8515682071447372\n",
            "Meta Train Accuracy 0.37500000931322575\n",
            "Mean accuracy/loss, stddev, and confidence intervals\n",
            "(0.5487500118821238, 0.057567895473163384, 0.004606391002854177)\n",
            "0.40000000689178705\n",
            "0.7125000134110451\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1vGjV8O7nsa",
        "cellView": "form",
        "outputId": "b04d1895-f99b-42cc-8719-3c9914236d71"
      },
      "source": [
        "#@title EXP8 meta_lr=0.010 fast_lr=0.30  meta_batch_size=16 num_iterations=3 \n",
        "\n",
        "#@markdown 400 generated images instead of 1 shot per class \n",
        "\n",
        "#@markdown Foud that adding more layers of folws specifically batch normalization flow layer achives higher accuracy \n",
        "\n",
        "#@markdown Flow details:\n",
        "\n",
        "#@markdown    BatchNorm(dim=dim),ActNorm(dim=dim).warm_start(x=trainX),BatchNorm(dim=dim),ActNorm(dim=dim).warm_start(x=trainX),\n",
        "\n",
        "#@markdown    BatchNorm(dim=dim), 6 times \n",
        "\n",
        "#@markdown    Affine(dim=dim),Affine(dim=dim),\n",
        "\n",
        "\n",
        "#@markdown BatchNorm(dim=dim), 30 times \n",
        "\n",
        "#@markdown ----\n",
        "\n",
        "#@markdown Mean accuracy/loss, stddev, and confidence intervals\n",
        "\n",
        "#@markdown (0.6348125119693577, 0.0569568206496079, 0.004557494833450018)\n",
        "\n",
        "#@markdown min accuracy: 0.450000012293458\n",
        "\n",
        "#@markdown max accuracy: 0.8125000074505806\n",
        "\n",
        "def accuracy(predictions, targets):\n",
        "    predictions = predictions.argmax(dim=1).view(targets.shape)\n",
        "    return (predictions == targets).sum().float() / targets.size(0)\n",
        "\n",
        "\n",
        "def fast_adapt(batch, learner, loss, adaptation_steps, shots, ways, device):\n",
        "    data, labels = batch\n",
        "    # print(\"data:  \",data.shape)\n",
        "    data, labels = data.to(device), labels.to(device, dtype=torch.int64)\n",
        "    # Separate data into adaptation/evalutation sets\n",
        "    adaptation_indices = np.zeros(data.size(0), dtype=bool)\n",
        "    adaptation_indices[np.arange(shots*ways) * 2] = True\n",
        "    evaluation_indices = torch.from_numpy(~adaptation_indices)\n",
        "    adaptation_indices = torch.from_numpy(adaptation_indices)\n",
        "    adaptation_data, adaptation_labels = data[adaptation_indices], labels[adaptation_indices]\n",
        "    evaluation_data, evaluation_labels = data[evaluation_indices], labels[evaluation_indices]\n",
        "\n",
        "    # Adapt the model\n",
        "    for step in range(adaptation_steps):\n",
        "        train_error = loss(learner(adaptation_data), adaptation_labels)\n",
        "        learner.adapt(train_error)\n",
        "\n",
        "\n",
        "    # Evaluate the adapted model\n",
        "    predictions = learner(evaluation_data)\n",
        "    valid_error = loss(predictions, evaluation_labels)\n",
        "    valid_accuracy = accuracy(predictions, evaluation_labels)\n",
        "    return valid_error, valid_accuracy\n",
        "\n",
        "\n",
        "def fast_adapt_train(batch, learner, loss, adaptation_steps, shots, ways, device):\n",
        "\n",
        "    data, labels = batch\n",
        "    data, labels = data.to(device), labels.to(device, dtype=torch.int64)\n",
        "    # Separate data into adaptation/evalutation sets\n",
        "    indices = np.random.permutation(data.shape[0])\n",
        "    \n",
        "    adaptation_indices = indices[:360]\n",
        "    evaluation_indices = indices[360:]\n",
        "    adaptation_data, adaptation_labels = data[adaptation_indices], labels[adaptation_indices]\n",
        "    evaluation_data, evaluation_labels = data[evaluation_indices], labels[evaluation_indices]\n",
        "    # print(adaptation_data.shape)\n",
        "    # print(\"modified version\")\n",
        "    # Adapt the model\n",
        "    for step in range(adaptation_steps):\n",
        "        train_error = loss(learner(adaptation_data), adaptation_labels)\n",
        "        learner.adapt(train_error)\n",
        "\n",
        "\n",
        "    # Evaluate the adapted model\n",
        "    predictions = learner(evaluation_data)\n",
        "    valid_error = loss(predictions, evaluation_labels)\n",
        "    valid_accuracy = accuracy(predictions, evaluation_labels)\n",
        "    return valid_error, valid_accuracy\n",
        "\n",
        "def train_flow (trainX ,cond_train , device):\n",
        "\n",
        "  \n",
        "  # trainX has a shape of (count , channel , pixles,pixles)\n",
        "  \n",
        "\n",
        "  trainX = torch.flatten(trainX,1,-1)\n",
        "  # valX = torch.flatten(valX , 1,-1)\n",
        "  dim=trainX.shape[1]\n",
        "  \n",
        "  # print(cond_train)\n",
        "  cond_train = torch.nn.functional.one_hot(cond_train)\n",
        "  # cond_val   = torch.nn.functional.one_hot(cond_val) \n",
        "  # print(cond_train)\n",
        "  cond_dim = cond_train.size(1)\n",
        "  \n",
        "  flow = Sequential(      \n",
        "\n",
        "      # MADE(AffineTransformer(dim=dim) , cond_dim=cond_dim),\n",
        "      # MADE(AffineTransformer(dim=dim) , cond_dim=cond_dim),\n",
        "\n",
        "  # very slow in sampling \n",
        "    # inv_flow(Sigmoid)(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    ActNorm(dim=dim).warm_start(x=trainX),\n",
        "    BatchNorm(dim=dim),\n",
        "    ActNorm(dim=dim).warm_start(x=trainX),\n",
        "    # BatchNorm(dim=dim),\n",
        "    # ActNorm(dim=dim).warm_start(x=trainX),\n",
        "# //////////////////\n",
        "    #     BatchNorm(dim=dim),\n",
        "    # ActNorm(dim=dim).warm_start(x=trainX),\n",
        "    # BatchNorm(dim=dim),\n",
        "    # ActNorm(dim=dim).warm_start(x=trainX),\n",
        "    # BatchNorm(dim=dim),\n",
        "    # ActNorm(dim=dim).warm_start(x=trainX),\n",
        "    # BatchNorm(dim=dim),\n",
        "    # ActNorm(dim=dim).warm_start(x=trainX),\n",
        "    # BatchNorm(dim=dim),\n",
        "    # ActNorm(dim=dim).warm_start(x=trainX),\n",
        "# ////////\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    # MADE(DSF(dim=dim), cond_dim=cond_dim),\n",
        "    Affine(dim=dim),  \n",
        "    Affine(dim=dim),  \n",
        "BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "      # BatchNorm(dim=dim),\n",
        "      # Shuffle(dim=dim),\n",
        "      # CouplingLayers(AffineTransformer(dim=dim//2 ) ,dim=dim),\n",
        "\n",
        "  ).to(device)\n",
        "  train_losses, val_losses = train(flow, trainX, trainX ,cond_train=cond_train, cond_val=cond_train , patience=100 ,batch_size=8,n_epochs=1000)\n",
        " \n",
        "  test_labels = np.random.choice(5, size=(400))\n",
        "  test_labels = torch.from_numpy(test_labels)\n",
        "  test_cond = torch.nn.functional.one_hot(test_labels)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    train_data = flow.sample(400,cond=test_cond.to(device)).cpu()\n",
        "\n",
        "  # return train_data, train_losses , val_losses , mean , var\n",
        "  return torch.reshape(train_data , (400,1,28,28)) , test_labels\n",
        "\n",
        "\n",
        "\n",
        "ways=5\n",
        "shots=1\n",
        "meta_lr=0.010\n",
        "fast_lr=0.30\n",
        "meta_batch_size=16\n",
        "adaptation_steps=1\n",
        "num_iterations=3\n",
        "cuda=True\n",
        "# seed=42\n",
        "# Load train/validation/test tasksets using the benchmark interface\n",
        "tasksets = l2l.vision.benchmarks.get_tasksets('omniglot',\n",
        "                                                  train_ways=ways,\n",
        "                                                  train_samples=2*shots,\n",
        "                                                  test_ways=ways,\n",
        "                                                  test_samples=2*shots,\n",
        "                                                  num_tasks=20000,\n",
        "                                                  root='~/data',\n",
        "    )\n",
        "\n",
        "# dim = 28*28\n",
        "\n",
        "device = torch.device('cpu')\n",
        "if cuda:\n",
        "  # torch.cuda.manual_seed(seed)\n",
        "  device = torch.device('cuda')\n",
        "\n",
        "# Create model\n",
        "model = l2l.vision.models.OmniglotCNN(ways)\n",
        "# model = l2l.vision.models.OmniglotFC(28 ** 2, ways)\n",
        "model.to(device)\n",
        "maml = l2l.algorithms.MAML(model, lr=fast_lr, first_order=False)\n",
        "opt = optim.Adam(maml.parameters(), meta_lr)\n",
        "loss = nn.CrossEntropyLoss(reduction='mean')\n",
        "\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "for iteration in tqdm(range(num_iterations)):\n",
        "    opt.zero_grad()\n",
        "    meta_train_error = 0.0\n",
        "    meta_train_accuracy = 0.0\n",
        "    meta_valid_error = 0.0\n",
        "    meta_valid_accuracy = 0.0\n",
        "\n",
        "    for task in range(meta_batch_size):\n",
        "        # Compute meta-training loss\n",
        "        # learner = maml.clone()\n",
        "\n",
        "        # generate batch the batch contains # ways*shots , channels , img size  and labels \n",
        "        train_batch = tasksets.train.sample()\n",
        "        val_batch = tasksets.validation.sample()\n",
        "\n",
        "        # split batch based on classes in labels then   labels.split(int(data.shape[0]/ways))\n",
        "        train_data, train_labels = train_batch\n",
        "        val_data , val_labels= val_batch\n",
        "\n",
        "        \n",
        "        train_data_generator ,train_lable_generator  = train_flow (train_data ,train_labels  , device)\n",
        "\n",
        "        # train_data_generator = torch.cat(train_data_generator)\n",
        "        # train_lable_generator = torch.cat(train_lable_generator)\n",
        "        \n",
        "        batch = [train_data_generator ,train_lable_generator]\n",
        "\n",
        "        learner = maml.clone()            \n",
        "        \n",
        "        evaluation_error, evaluation_accuracy = fast_adapt_train(batch,\n",
        "                                                            learner,\n",
        "                                                            loss,\n",
        "                                                            adaptation_steps,\n",
        "                                                            shots,\n",
        "                                                            ways,\n",
        "                                                            device)\n",
        "        evaluation_error.backward()\n",
        "        meta_train_error += evaluation_error.item()\n",
        "        meta_train_accuracy += evaluation_accuracy.item()\n",
        "\n",
        "# ''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
        "\n",
        "        # # Compute meta-validation loss\n",
        "        # batch = tasksets.validation.sample()\n",
        "        \n",
        "        # learner = maml.clone()\n",
        "        # evaluation_error, evaluation_accuracy = fast_adapt(batch,learner,loss,adaptation_steps,shots,ways,\n",
        "        #                                                     device)\n",
        "        # meta_valid_error += evaluation_error.item()\n",
        "        # meta_valid_accuracy += evaluation_accuracy.item()\n",
        "\n",
        "    # Print some metrics\n",
        "    print('\\n')\n",
        "    print('Iteration', iteration)\n",
        "    print('Meta Train Error', meta_train_error / meta_batch_size)\n",
        "    print('Meta Train Accuracy', meta_train_accuracy / meta_batch_size)\n",
        "    # print('Meta Valid Error', meta_valid_error / meta_batch_size)\n",
        "    # print('Meta Valid Accuracy', meta_valid_accuracy / meta_batch_size)\n",
        "\n",
        "    # Average the accumulated gradients and optimize\n",
        "    for p in maml.parameters():\n",
        "        p.grad.data.mul_(1.0 / meta_batch_size)\n",
        "    opt.step()\n",
        "\n",
        "\n",
        "acc_acuracy=[]\n",
        "iterations= 600\n",
        "for _ in range(iterations):\n",
        "  meta_test_error = 0.0\n",
        "  meta_test_accuracy = 0.0\n",
        "\n",
        "  for task in range(meta_batch_size):\n",
        "\n",
        "      # Compute meta-testing loss\n",
        "      learner = maml.clone()\n",
        "      batch = tasksets.test.sample()\n",
        "      evaluation_error, evaluation_accuracy = fast_adapt(batch,\n",
        "                                                          learner,\n",
        "                                                          loss,\n",
        "                                                          3,\n",
        "                                                          shots,\n",
        "                                                          ways,\n",
        "                                                          device)\n",
        "      meta_test_error += evaluation_error.item()\n",
        "      meta_test_accuracy += evaluation_accuracy.item()\n",
        "\n",
        "  # print('Meta Test Error', meta_test_error / meta_batch_size)\n",
        "  # print('Meta Test Accuracy', meta_test_accuracy / meta_batch_size)\n",
        "  acc_acuracy.append(meta_test_accuracy/meta_batch_size)\n",
        "\n",
        "\n",
        "acc_acuracy = np.array(acc_acuracy)\n",
        "means = np.mean(acc_acuracy, 0)\n",
        "stds = np.std(acc_acuracy, 0)\n",
        "ci95 = 1.96*stds/np.sqrt(iterations)\n",
        "\n",
        "print('Mean accuracy/loss, stddev, and confidence intervals')\n",
        "print((means, stds, ci95))\n",
        "\n",
        "print(acc_acuracy[acc_acuracy.argmin()])\n",
        "print(acc_acuracy[acc_acuracy.argmax()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:281: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "215it [00:40,  5.25it/s, epoch_progress=100%, train_loss=-2.335e+05, last_val_loss=+1.560e+26, best_epoch=115, best_loss=+3.166e+25]\n",
            "117it [00:22,  5.27it/s, epoch_progress=100%, train_loss=-1.871e+05, last_val_loss=+1.141e+26, best_epoch=17, best_loss=+2.943e+25]\n",
            "166it [00:31,  5.23it/s, epoch_progress=100%, train_loss=-2.466e+05, last_val_loss=+1.752e+26, best_epoch=66, best_loss=+4.217e+25]\n",
            "120it [00:22,  5.26it/s, epoch_progress=100%, train_loss=-2.693e+05, last_val_loss=+1.556e+26, best_epoch=20, best_loss=+3.539e+25]\n",
            "174it [00:33,  5.25it/s, epoch_progress=100%, train_loss=-2.499e+05, last_val_loss=+1.242e+26, best_epoch=74, best_loss=+3.265e+25]\n",
            "149it [00:28,  5.20it/s, epoch_progress=100%, train_loss=-2.901e+05, last_val_loss=+8.526e+25, best_epoch=49, best_loss=+3.676e+25]\n",
            "101it [00:19,  5.29it/s, epoch_progress=100%, train_loss=-2.189e+05, last_val_loss=+1.919e+26, best_epoch=1, best_loss=+3.844e+05]\n",
            "115it [00:21,  5.27it/s, epoch_progress=100%, train_loss=-2.129e+05, last_val_loss=+6.223e+25, best_epoch=15, best_loss=+1.043e+25]\n",
            "121it [00:23,  5.22it/s, epoch_progress=100%, train_loss=-2.627e+05, last_val_loss=+1.819e+26, best_epoch=21, best_loss=+2.352e+25]\n",
            "121it [00:23,  5.20it/s, epoch_progress=100%, train_loss=-2.499e+05, last_val_loss=+1.016e+26, best_epoch=21, best_loss=+4.079e+25]\n",
            "120it [00:23,  5.15it/s, epoch_progress=100%, train_loss=-2.681e+05, last_val_loss=+1.247e+26, best_epoch=20, best_loss=+1.416e+25]\n",
            "129it [00:24,  5.30it/s, epoch_progress=100%, train_loss=-2.483e+05, last_val_loss=+1.595e+26, best_epoch=29, best_loss=+6.292e+25]\n",
            "119it [00:22,  5.24it/s, epoch_progress=100%, train_loss=-2.214e+05, last_val_loss=+3.590e+26, best_epoch=19, best_loss=+4.223e+25]\n",
            "119it [00:22,  5.21it/s, epoch_progress=100%, train_loss=-2.813e+05, last_val_loss=+5.413e+25, best_epoch=19, best_loss=+1.794e+25]\n",
            "117it [00:22,  5.23it/s, epoch_progress=100%, train_loss=-2.248e+05, last_val_loss=+9.163e+25, best_epoch=17, best_loss=+1.217e+25]\n",
            "101it [00:18,  5.37it/s, epoch_progress=100%, train_loss=-2.082e+05, last_val_loss=+5.185e+25, best_epoch=1, best_loss=+2.935e+05]\n",
            " 33%|███▎      | 1/3 [06:45<13:30, 405.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 0\n",
            "Meta Train Error 1.9390601515769958\n",
            "Meta Train Accuracy 0.18593750288709998\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "128it [00:24,  5.23it/s, epoch_progress=100%, train_loss=-2.293e+05, last_val_loss=+9.975e+25, best_epoch=28, best_loss=+4.189e+25]\n",
            "132it [00:25,  5.26it/s, epoch_progress=100%, train_loss=-2.469e+05, last_val_loss=+3.050e+26, best_epoch=32, best_loss=+4.441e+25]\n",
            "116it [00:21,  5.30it/s, epoch_progress=100%, train_loss=-2.674e+05, last_val_loss=+1.191e+26, best_epoch=16, best_loss=+4.734e+25]\n",
            "117it [00:22,  5.19it/s, epoch_progress=100%, train_loss=-2.516e+05, last_val_loss=+1.825e+26, best_epoch=17, best_loss=+2.827e+25]\n",
            "117it [00:22,  5.31it/s, epoch_progress=100%, train_loss=-2.810e+05, last_val_loss=+1.013e+26, best_epoch=17, best_loss=+4.942e+25]\n",
            "114it [00:21,  5.21it/s, epoch_progress=100%, train_loss=-2.257e+05, last_val_loss=+7.212e+25, best_epoch=14, best_loss=+2.162e+25]\n",
            "191it [00:36,  5.19it/s, epoch_progress=100%, train_loss=-2.508e+05, last_val_loss=+9.217e+25, best_epoch=91, best_loss=+2.987e+25]\n",
            "116it [00:21,  5.34it/s, epoch_progress=100%, train_loss=-2.461e+05, last_val_loss=+1.621e+26, best_epoch=16, best_loss=+1.447e+25]\n",
            "121it [00:22,  5.32it/s, epoch_progress=100%, train_loss=-2.255e+05, last_val_loss=+4.870e+25, best_epoch=21, best_loss=+2.826e+25]\n",
            "121it [00:22,  5.37it/s, epoch_progress=100%, train_loss=-2.455e+05, last_val_loss=+9.634e+25, best_epoch=21, best_loss=+3.547e+25]\n",
            "119it [00:22,  5.31it/s, epoch_progress=100%, train_loss=-2.865e+05, last_val_loss=+8.641e+25, best_epoch=19, best_loss=+2.379e+25]\n",
            "124it [00:23,  5.29it/s, epoch_progress=100%, train_loss=-2.280e+05, last_val_loss=+9.835e+25, best_epoch=24, best_loss=+3.890e+25]\n",
            "117it [00:21,  5.34it/s, epoch_progress=100%, train_loss=-2.266e+05, last_val_loss=+4.402e+25, best_epoch=17, best_loss=+1.716e+25]\n",
            "144it [00:27,  5.28it/s, epoch_progress=100%, train_loss=-2.119e+05, last_val_loss=+8.991e+25, best_epoch=44, best_loss=+3.750e+25]\n",
            "171it [00:31,  5.41it/s, epoch_progress=100%, train_loss=-2.266e+05, last_val_loss=+1.826e+26, best_epoch=71, best_loss=+4.097e+25]\n",
            "157it [00:29,  5.31it/s, epoch_progress=100%, train_loss=-2.719e+05, last_val_loss=+1.751e+26, best_epoch=57, best_loss=+3.438e+25]\n",
            " 67%|██████▋   | 2/3 [13:27<06:43, 403.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 1\n",
            "Meta Train Error 1.8743568360805511\n",
            "Meta Train Accuracy 0.19687500270083547\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "116it [00:21,  5.38it/s, epoch_progress=100%, train_loss=-2.749e+05, last_val_loss=+7.601e+25, best_epoch=16, best_loss=+1.639e+25]\n",
            "261it [00:48,  5.39it/s, epoch_progress=100%, train_loss=-2.158e+05, last_val_loss=+3.189e+26, best_epoch=161, best_loss=+4.252e+25]\n",
            "119it [00:21,  5.43it/s, epoch_progress=100%, train_loss=-2.528e+05, last_val_loss=+9.600e+25, best_epoch=19, best_loss=+2.988e+25]\n",
            "160it [00:29,  5.37it/s, epoch_progress=100%, train_loss=-2.794e+05, last_val_loss=+2.260e+26, best_epoch=60, best_loss=+3.039e+25]\n",
            "121it [00:22,  5.36it/s, epoch_progress=100%, train_loss=-2.357e+05, last_val_loss=+1.877e+26, best_epoch=21, best_loss=+4.627e+25]\n",
            "115it [00:21,  5.38it/s, epoch_progress=100%, train_loss=-2.641e+05, last_val_loss=+9.550e+25, best_epoch=15, best_loss=+2.526e+25]\n",
            "131it [00:24,  5.42it/s, epoch_progress=100%, train_loss=-2.314e+05, last_val_loss=+2.724e+26, best_epoch=31, best_loss=+3.582e+25]\n",
            "124it [00:22,  5.42it/s, epoch_progress=100%, train_loss=-2.167e+05, last_val_loss=+1.350e+26, best_epoch=24, best_loss=+4.405e+25]\n",
            "321it [00:59,  5.42it/s, epoch_progress=100%, train_loss=-2.737e+05, last_val_loss=+1.026e+26, best_epoch=221, best_loss=+2.463e+25]\n",
            "148it [00:27,  5.31it/s, epoch_progress=100%, train_loss=-2.782e+05, last_val_loss=+1.741e+26, best_epoch=48, best_loss=+4.505e+25]\n",
            "118it [00:21,  5.39it/s, epoch_progress=100%, train_loss=-2.818e+05, last_val_loss=+1.979e+26, best_epoch=18, best_loss=+4.494e+25]\n",
            "122it [00:22,  5.41it/s, epoch_progress=100%, train_loss=-2.107e+05, last_val_loss=+1.187e+26, best_epoch=22, best_loss=+4.323e+25]\n",
            "119it [00:21,  5.42it/s, epoch_progress=100%, train_loss=-2.063e+05, last_val_loss=+1.840e+26, best_epoch=19, best_loss=+1.810e+25]\n",
            "120it [00:21,  5.48it/s, epoch_progress=100%, train_loss=-2.829e+05, last_val_loss=+1.230e+26, best_epoch=20, best_loss=+2.832e+25]\n",
            "114it [00:20,  5.46it/s, epoch_progress=100%, train_loss=-2.491e+05, last_val_loss=+1.153e+26, best_epoch=14, best_loss=+4.005e+24]\n",
            "145it [00:26,  5.40it/s, epoch_progress=100%, train_loss=-2.368e+05, last_val_loss=+1.013e+26, best_epoch=45, best_loss=+3.265e+25]\n",
            "100%|██████████| 3/3 [20:47<00:00, 415.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 2\n",
            "Meta Train Error 1.736103892326355\n",
            "Meta Train Accuracy 0.19375000288709998\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean accuracy/loss, stddev, and confidence intervals\n",
            "(0.6348125119693577, 0.0569568206496079, 0.004557494833450018)\n",
            "0.450000012293458\n",
            "0.8125000074505806\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-R1HEG54I7p"
      },
      "source": [
        "**SUMMARY OF EXP7**\n",
        "---\n",
        "\n",
        "lower fast_learning rate 0.35  and 3 iterations \n",
        "\n",
        "* **Standard MAML**\n",
        "\n",
        "  * Mean accuracy/loss, stddev, and confidence intervals\n",
        "  * (0.5572500119513522, 0.08597201673500991, 0.00687919405652049)\n",
        "\n",
        "------\n",
        "* **with the following flows**\n",
        "\n",
        "  * Mean accuracy/loss, stddev, and confidence intervals\n",
        "  * (0.6215000123189142, 0.08055950191919135, 0.0064461026720695125)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMVGTtDZ4AaA",
        "cellView": "form",
        "outputId": "23eb503b-5f77-468d-8055-9ed54a674dc6"
      },
      "source": [
        "#@title COMPARE WITH EXP7 standard maml with fast_lr 0.35 and 3 iterations and rest of parameters as EXP4\n",
        "\n",
        "#@markdown Mean accuracy/loss, stddev, and confidence intervals\n",
        "\n",
        "#@markdown (0.5572500119513522, 0.08597201673500991, 0.00687919405652049)\n",
        "\n",
        "#@markdown min accuracy: 0.3000000063329935\n",
        "\n",
        "#@markdown max accuracy: 0.8500000089406967\n",
        "\"\"\"\n",
        "  Demonstrates how to:\n",
        "    * use the MAML wrapper for fast-adaptation,\n",
        "    * use the benchmark interface to load Omniglot, and\n",
        "    * sample tasks and split them in adaptation and evaluation sets.\n",
        "\"\"\"\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import learn2learn as l2l\n",
        "\n",
        "from torch import nn, optim\n",
        "\n",
        "\n",
        "\n",
        "def accuracy(predictions, targets):\n",
        "    predictions = predictions.argmax(dim=1).view(targets.shape)\n",
        "    return (predictions == targets).sum().float() / targets.size(0)\n",
        "\n",
        "\n",
        "def fast_adapt(batch, learner, loss, adaptation_steps, shots, ways, device):\n",
        "    data, labels = batch\n",
        "    data, labels = data.to(device), labels.to(device)\n",
        "\n",
        "    # Separate data into adaptation/evalutation sets\n",
        "    adaptation_indices = np.zeros(data.size(0), dtype=bool)\n",
        "    adaptation_indices[np.arange(shots*ways) * 2] = True\n",
        "    evaluation_indices = torch.from_numpy(~adaptation_indices)\n",
        "    adaptation_indices = torch.from_numpy(adaptation_indices)\n",
        "    adaptation_data, adaptation_labels = data[adaptation_indices], labels[adaptation_indices]\n",
        "    evaluation_data, evaluation_labels = data[evaluation_indices], labels[evaluation_indices]\n",
        "\n",
        "    # Adapt the model\n",
        "    for step in range(adaptation_steps):\n",
        "        train_error = loss(learner(adaptation_data), adaptation_labels)\n",
        "        learner.adapt(train_error)\n",
        "\n",
        "    # Evaluate the adapted model\n",
        "    predictions = learner(evaluation_data)\n",
        "    valid_error = loss(predictions, evaluation_labels)\n",
        "    valid_accuracy = accuracy(predictions, evaluation_labels)\n",
        "    return valid_error, valid_accuracy\n",
        "\n",
        "\n",
        "ways=5\n",
        "shots=1\n",
        "meta_lr=0.013\n",
        "fast_lr=0.35\n",
        "meta_batch_size=8\n",
        "adaptation_steps=1\n",
        "num_iterations=3\n",
        "cuda=True\n",
        "# seed=42,\n",
        "\n",
        "# random.seed(seed)\n",
        "# np.random.seed(seed)\n",
        "# torch.manual_seed(seed)\n",
        "device = torch.device('cpu')\n",
        "if cuda:\n",
        "    # torch.cuda.manual_seed(seed)\n",
        "    device = torch.device('cuda')\n",
        "\n",
        "# Load train/validation/test tasksets using the benchmark interface\n",
        "tasksets = l2l.vision.benchmarks.get_tasksets('omniglot',\n",
        "                                              train_ways=ways,\n",
        "                                              train_samples=2*shots,\n",
        "                                              test_ways=ways,\n",
        "                                              test_samples=2*shots,\n",
        "                                              num_tasks=20000,\n",
        "                                              root='~/data',\n",
        ")\n",
        "\n",
        "# Create model\n",
        "model =  l2l.vision.models.OmniglotCNN(ways)\n",
        "#model =  l2l.vision.models.OmniglotFC(28 ** 2, ways)\n",
        "model.to(device)\n",
        "maml = l2l.algorithms.MAML(model, lr=fast_lr, first_order=False)\n",
        "opt = optim.Adam(maml.parameters(), meta_lr)\n",
        "loss = nn.CrossEntropyLoss(reduction='mean')\n",
        "\n",
        "for iteration in range(num_iterations):\n",
        "    opt.zero_grad()\n",
        "    meta_train_error = 0.0\n",
        "    meta_train_accuracy = 0.0\n",
        "    meta_valid_error = 0.0\n",
        "    meta_valid_accuracy = 0.0\n",
        "    for task in range(meta_batch_size):\n",
        "        # Compute meta-training loss\n",
        "        learner = maml.clone()\n",
        "        batch = tasksets.train.sample()\n",
        "        evaluation_error, evaluation_accuracy = fast_adapt(batch,\n",
        "                                                            learner,\n",
        "                                                            loss,\n",
        "                                                            adaptation_steps,\n",
        "                                                            shots,\n",
        "                                                            ways,\n",
        "                                                            device)\n",
        "        evaluation_error.backward()\n",
        "        meta_train_error += evaluation_error.item()\n",
        "        meta_train_accuracy += evaluation_accuracy.item()\n",
        "\n",
        "        # Compute meta-validation loss\n",
        "        # learner = maml.clone()\n",
        "        # batch = tasksets.validation.sample()\n",
        "        # evaluation_error, evaluation_accuracy = fast_adapt(batch,\n",
        "        #                                                     learner,\n",
        "        #                                                     loss,\n",
        "        #                                                     adaptation_steps,\n",
        "        #                                                     shots,\n",
        "        #                                                     ways,\n",
        "        #                                                     device)\n",
        "        # meta_valid_error += evaluation_error.item()\n",
        "        # meta_valid_accuracy += evaluation_accuracy.item()\n",
        "\n",
        "    # Print some metrics\n",
        "    print('\\n')\n",
        "    print('Iteration', iteration)\n",
        "    print('Meta Train Error', meta_train_error / meta_batch_size)\n",
        "    print('Meta Train Accuracy', meta_train_accuracy / meta_batch_size)\n",
        "    # print('Meta Valid Error', meta_valid_error / meta_batch_size)\n",
        "    # print('Meta Valid Accuracy', meta_valid_accuracy / meta_batch_size)\n",
        "\n",
        "    # Average the accumulated gradients and optimize\n",
        "    for p in maml.parameters():\n",
        "        p.grad.data.mul_(1.0 / meta_batch_size)\n",
        "    opt.step()\n",
        "\n",
        "\n",
        "\n",
        "acc_acuracy=[]\n",
        "iterations=600\n",
        "\n",
        "for _ in range(iterations):\n",
        "  meta_test_error = 0.0\n",
        "  meta_test_accuracy = 0.0\n",
        "\n",
        "  for task in range(meta_batch_size):\n",
        "\n",
        "      # Compute meta-testing loss\n",
        "      learner = maml.clone()\n",
        "      batch = tasksets.test.sample()\n",
        "      evaluation_error, evaluation_accuracy = fast_adapt(batch,\n",
        "                                                          learner,\n",
        "                                                          loss,\n",
        "                                                          3,\n",
        "                                                          shots,\n",
        "                                                          ways,\n",
        "                                                          device)\n",
        "      meta_test_error += evaluation_error.item()\n",
        "      meta_test_accuracy += evaluation_accuracy.item()\n",
        "\n",
        "  # print('Meta Test Error', meta_test_error / meta_batch_size)\n",
        "  # print('Meta Test Accuracy', meta_test_accuracy / meta_batch_size)\n",
        "  acc_acuracy.append(meta_test_accuracy/meta_batch_size)\n",
        "\n",
        "\n",
        "acc_acuracy = np.array(acc_acuracy)\n",
        "means = np.mean(acc_acuracy, 0)\n",
        "stds = np.std(acc_acuracy, 0)\n",
        "ci95 = 1.96*stds/np.sqrt(iterations)\n",
        "\n",
        "print('Mean accuracy/loss, stddev, and confidence intervals')\n",
        "print((means, stds, ci95))\n",
        "\n",
        "print(acc_acuracy[acc_acuracy.argmin()])\n",
        "print(acc_acuracy[acc_acuracy.argmax()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:281: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "\n",
            "\n",
            "Iteration 0\n",
            "Meta Train Error 2.406614050269127\n",
            "Meta Train Accuracy 0.2500000074505806\n",
            "\n",
            "\n",
            "Iteration 1\n",
            "Meta Train Error 1.4657954163849354\n",
            "Meta Train Accuracy 0.42500000819563866\n",
            "\n",
            "\n",
            "Iteration 2\n",
            "Meta Train Error 1.4867252483963966\n",
            "Meta Train Accuracy 0.42500000819563866\n",
            "Mean accuracy/loss, stddev, and confidence intervals\n",
            "(0.5572500119513522, 0.08597201673500991, 0.00687919405652049)\n",
            "0.3000000063329935\n",
            "0.8500000089406967\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m811VjDl3_2o",
        "cellView": "form",
        "outputId": "259164d0-ec3f-4687-8bbf-bf970737bbef"
      },
      "source": [
        "#@title EXP7 lower fast_learning rate 0.35  and 3 iterations \n",
        "#@markdown meta_lr 0.013 \n",
        "\n",
        "#@markdown 400 generated images instead of 1 shot per class \n",
        "\n",
        "#@markdown Foud that adding more layers of folws specifically batch normalization flow layer achives higher accuracy \n",
        "\n",
        "#@markdown Flow details:\n",
        "\n",
        "#@markdown    BatchNorm(dim=dim),ActNorm(dim=dim).warm_start(x=trainX),BatchNorm(dim=dim),ActNorm(dim=dim).warm_start(x=trainX),\n",
        "\n",
        "#@markdown    BatchNorm(dim=dim), 6 times \n",
        "\n",
        "#@markdown    Affine(dim=dim),Affine(dim=dim),\n",
        "\n",
        "#@markdown BatchNorm(dim=dim), 25 times \n",
        "\n",
        "#@markdown ------\n",
        "\n",
        "#@markdown Mean accuracy/loss, stddev, and confidence intervals\n",
        "\n",
        "#@markdown (0.6215000123189142, 0.08055950191919135, 0.0064461026720695125)\n",
        "\n",
        "#@markdown min accuracy: 0.3750000074505806\n",
        "\n",
        "#@markdown max accuracy: 0.9000000059604645\n",
        "\n",
        "\n",
        "def accuracy(predictions, targets):\n",
        "    predictions = predictions.argmax(dim=1).view(targets.shape)\n",
        "    return (predictions == targets).sum().float() / targets.size(0)\n",
        "\n",
        "\n",
        "def fast_adapt(batch, learner, loss, adaptation_steps, shots, ways, device):\n",
        "    data, labels = batch\n",
        "    # print(\"data:  \",data.shape)\n",
        "    data, labels = data.to(device), labels.to(device, dtype=torch.int64)\n",
        "    # Separate data into adaptation/evalutation sets\n",
        "    adaptation_indices = np.zeros(data.size(0), dtype=bool)\n",
        "    adaptation_indices[np.arange(shots*ways) * 2] = True\n",
        "    evaluation_indices = torch.from_numpy(~adaptation_indices)\n",
        "    adaptation_indices = torch.from_numpy(adaptation_indices)\n",
        "    adaptation_data, adaptation_labels = data[adaptation_indices], labels[adaptation_indices]\n",
        "    evaluation_data, evaluation_labels = data[evaluation_indices], labels[evaluation_indices]\n",
        "\n",
        "    # Adapt the model\n",
        "    for step in range(adaptation_steps):\n",
        "        train_error = loss(learner(adaptation_data), adaptation_labels)\n",
        "        learner.adapt(train_error)\n",
        "\n",
        "\n",
        "    # Evaluate the adapted model\n",
        "    predictions = learner(evaluation_data)\n",
        "    valid_error = loss(predictions, evaluation_labels)\n",
        "    valid_accuracy = accuracy(predictions, evaluation_labels)\n",
        "    return valid_error, valid_accuracy\n",
        "\n",
        "\n",
        "def fast_adapt_train(batch, learner, loss, adaptation_steps, shots, ways, device):\n",
        "\n",
        "    data, labels = batch\n",
        "    data, labels = data.to(device), labels.to(device, dtype=torch.int64)\n",
        "    # Separate data into adaptation/evalutation sets\n",
        "    indices = np.random.permutation(data.shape[0])\n",
        "    \n",
        "    adaptation_indices = indices[:360]\n",
        "    evaluation_indices = indices[360:]\n",
        "    adaptation_data, adaptation_labels = data[adaptation_indices], labels[adaptation_indices]\n",
        "    evaluation_data, evaluation_labels = data[evaluation_indices], labels[evaluation_indices]\n",
        "    # print(adaptation_data.shape)\n",
        "    # print(\"modified version\")\n",
        "    # Adapt the model\n",
        "    for step in range(adaptation_steps):\n",
        "        train_error = loss(learner(adaptation_data), adaptation_labels)\n",
        "        learner.adapt(train_error)\n",
        "\n",
        "\n",
        "    # Evaluate the adapted model\n",
        "    predictions = learner(evaluation_data)\n",
        "    valid_error = loss(predictions, evaluation_labels)\n",
        "    valid_accuracy = accuracy(predictions, evaluation_labels)\n",
        "    return valid_error, valid_accuracy\n",
        "\n",
        "def train_flow (trainX ,cond_train , device):\n",
        "\n",
        "  \n",
        "  # trainX has a shape of (count , channel , pixles,pixles)\n",
        "  \n",
        "\n",
        "  trainX = torch.flatten(trainX,1,-1)\n",
        "  # valX = torch.flatten(valX , 1,-1)\n",
        "  dim=trainX.shape[1]\n",
        "  \n",
        "  # print(cond_train)\n",
        "  cond_train = torch.nn.functional.one_hot(cond_train)\n",
        "  # cond_val   = torch.nn.functional.one_hot(cond_val) \n",
        "  # print(cond_train)\n",
        "  cond_dim = cond_train.size(1)\n",
        "  \n",
        "  flow = Sequential(      \n",
        "\n",
        "      # MADE(AffineTransformer(dim=dim) , cond_dim=cond_dim),\n",
        "      # MADE(AffineTransformer(dim=dim) , cond_dim=cond_dim),\n",
        "\n",
        "  # very slow in sampling \n",
        "    # inv_flow(Sigmoid)(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    ActNorm(dim=dim).warm_start(x=trainX),\n",
        "    BatchNorm(dim=dim),\n",
        "    ActNorm(dim=dim).warm_start(x=trainX),\n",
        "    # BatchNorm(dim=dim),\n",
        "    # ActNorm(dim=dim).warm_start(x=trainX),\n",
        "# //////////////////\n",
        "    #     BatchNorm(dim=dim),\n",
        "    # ActNorm(dim=dim).warm_start(x=trainX),\n",
        "    # BatchNorm(dim=dim),\n",
        "    # ActNorm(dim=dim).warm_start(x=trainX),\n",
        "    # BatchNorm(dim=dim),\n",
        "    # ActNorm(dim=dim).warm_start(x=trainX),\n",
        "    # BatchNorm(dim=dim),\n",
        "    # ActNorm(dim=dim).warm_start(x=trainX),\n",
        "    # BatchNorm(dim=dim),\n",
        "    # ActNorm(dim=dim).warm_start(x=trainX),\n",
        "# ////////\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    # MADE(DSF(dim=dim), cond_dim=cond_dim),\n",
        "    Affine(dim=dim),  \n",
        "    Affine(dim=dim),  \n",
        "BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "\n",
        "      # BatchNorm(dim=dim),\n",
        "      # Shuffle(dim=dim),\n",
        "      # CouplingLayers(AffineTransformer(dim=dim//2 ) ,dim=dim),\n",
        "\n",
        "  ).to(device)\n",
        "  train_losses, val_losses = train(flow, trainX, trainX ,cond_train=cond_train, cond_val=cond_train , patience=100 ,batch_size=8,n_epochs=1000)\n",
        " \n",
        "  test_labels = np.random.choice(5, size=(400))\n",
        "  test_labels = torch.from_numpy(test_labels)\n",
        "  test_cond = torch.nn.functional.one_hot(test_labels)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    train_data = flow.sample(400,cond=test_cond.to(device)).cpu()\n",
        "\n",
        "  # return train_data, train_losses , val_losses , mean , var\n",
        "  return torch.reshape(train_data , (400,1,28,28)) , test_labels\n",
        "\n",
        "\n",
        "\n",
        "ways=5\n",
        "shots=1\n",
        "meta_lr=0.013\n",
        "fast_lr=0.35\n",
        "meta_batch_size=8\n",
        "adaptation_steps=1\n",
        "num_iterations=3\n",
        "cuda=True\n",
        "# seed=42\n",
        "# Load train/validation/test tasksets using the benchmark interface\n",
        "tasksets = l2l.vision.benchmarks.get_tasksets('omniglot',\n",
        "                                                  train_ways=ways,\n",
        "                                                  train_samples=2*shots,\n",
        "                                                  test_ways=ways,\n",
        "                                                  test_samples=2*shots,\n",
        "                                                  num_tasks=20000,\n",
        "                                                  root='~/data',\n",
        "    )\n",
        "\n",
        "# dim = 28*28\n",
        "\n",
        "device = torch.device('cpu')\n",
        "if cuda:\n",
        "  # torch.cuda.manual_seed(seed)\n",
        "  device = torch.device('cuda')\n",
        "\n",
        "# Create model\n",
        "model = l2l.vision.models.OmniglotCNN(ways)\n",
        "# model = l2l.vision.models.OmniglotFC(28 ** 2, ways)\n",
        "model.to(device)\n",
        "maml = l2l.algorithms.MAML(model, lr=fast_lr, first_order=False)\n",
        "opt = optim.Adam(maml.parameters(), meta_lr)\n",
        "loss = nn.CrossEntropyLoss(reduction='mean')\n",
        "\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "for iteration in tqdm(range(num_iterations)):\n",
        "    opt.zero_grad()\n",
        "    meta_train_error = 0.0\n",
        "    meta_train_accuracy = 0.0\n",
        "    meta_valid_error = 0.0\n",
        "    meta_valid_accuracy = 0.0\n",
        "\n",
        "    for task in range(meta_batch_size):\n",
        "        # Compute meta-training loss\n",
        "        # learner = maml.clone()\n",
        "\n",
        "        # generate batch the batch contains # ways*shots , channels , img size  and labels \n",
        "        train_batch = tasksets.train.sample()\n",
        "        val_batch = tasksets.validation.sample()\n",
        "\n",
        "        # split batch based on classes in labels then   labels.split(int(data.shape[0]/ways))\n",
        "        train_data, train_labels = train_batch\n",
        "        val_data , val_labels= val_batch\n",
        "\n",
        "        \n",
        "        train_data_generator ,train_lable_generator  = train_flow (train_data ,train_labels  , device)\n",
        "\n",
        "        # train_data_generator = torch.cat(train_data_generator)\n",
        "        # train_lable_generator = torch.cat(train_lable_generator)\n",
        "        \n",
        "        batch = [train_data_generator ,train_lable_generator]\n",
        "\n",
        "        learner = maml.clone()            \n",
        "        \n",
        "        evaluation_error, evaluation_accuracy = fast_adapt_train(batch,\n",
        "                                                            learner,\n",
        "                                                            loss,\n",
        "                                                            adaptation_steps,\n",
        "                                                            shots,\n",
        "                                                            ways,\n",
        "                                                            device)\n",
        "        evaluation_error.backward()\n",
        "        meta_train_error += evaluation_error.item()\n",
        "        meta_train_accuracy += evaluation_accuracy.item()\n",
        "\n",
        "# ''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
        "\n",
        "        # # Compute meta-validation loss\n",
        "        # batch = tasksets.validation.sample()\n",
        "        \n",
        "        # learner = maml.clone()\n",
        "        # evaluation_error, evaluation_accuracy = fast_adapt(batch,learner,loss,adaptation_steps,shots,ways,\n",
        "        #                                                     device)\n",
        "        # meta_valid_error += evaluation_error.item()\n",
        "        # meta_valid_accuracy += evaluation_accuracy.item()\n",
        "\n",
        "    # Print some metrics\n",
        "    print('\\n')\n",
        "    print('Iteration', iteration)\n",
        "    print('Meta Train Error', meta_train_error / meta_batch_size)\n",
        "    print('Meta Train Accuracy', meta_train_accuracy / meta_batch_size)\n",
        "    # print('Meta Valid Error', meta_valid_error / meta_batch_size)\n",
        "    # print('Meta Valid Accuracy', meta_valid_accuracy / meta_batch_size)\n",
        "\n",
        "    # Average the accumulated gradients and optimize\n",
        "    for p in maml.parameters():\n",
        "        p.grad.data.mul_(1.0 / meta_batch_size)\n",
        "    opt.step()\n",
        "\n",
        "\n",
        "acc_acuracy=[]\n",
        "iterations= 600\n",
        "for _ in range(iterations):\n",
        "  meta_test_error = 0.0\n",
        "  meta_test_accuracy = 0.0\n",
        "\n",
        "  for task in range(meta_batch_size):\n",
        "\n",
        "      # Compute meta-testing loss\n",
        "      learner = maml.clone()\n",
        "      batch = tasksets.test.sample()\n",
        "      evaluation_error, evaluation_accuracy = fast_adapt(batch,\n",
        "                                                          learner,\n",
        "                                                          loss,\n",
        "                                                          3,\n",
        "                                                          shots,\n",
        "                                                          ways,\n",
        "                                                          device)\n",
        "      meta_test_error += evaluation_error.item()\n",
        "      meta_test_accuracy += evaluation_accuracy.item()\n",
        "\n",
        "  # print('Meta Test Error', meta_test_error / meta_batch_size)\n",
        "  # print('Meta Test Accuracy', meta_test_accuracy / meta_batch_size)\n",
        "  acc_acuracy.append(meta_test_accuracy/meta_batch_size)\n",
        "\n",
        "\n",
        "acc_acuracy = np.array(acc_acuracy)\n",
        "means = np.mean(acc_acuracy, 0)\n",
        "stds = np.std(acc_acuracy, 0)\n",
        "ci95 = 1.96*stds/np.sqrt(iterations)\n",
        "\n",
        "print('Mean accuracy/loss, stddev, and confidence intervals')\n",
        "print((means, stds, ci95))\n",
        "\n",
        "print(acc_acuracy[acc_acuracy.argmin()])\n",
        "print(acc_acuracy[acc_acuracy.argmax()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:281: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "121it [00:19,  6.22it/s, epoch_progress=100%, train_loss=-2.157e+05, last_val_loss=+1.871e+22, best_epoch=21, best_loss=+7.114e+21]\n",
            "116it [00:18,  6.20it/s, epoch_progress=100%, train_loss=-2.377e+05, last_val_loss=+2.909e+22, best_epoch=16, best_loss=+3.492e+21]\n",
            "120it [00:19,  6.14it/s, epoch_progress=100%, train_loss=-2.272e+05, last_val_loss=+1.630e+22, best_epoch=20, best_loss=+7.546e+21]\n",
            "152it [00:25,  6.08it/s, epoch_progress=100%, train_loss=-2.214e+05, last_val_loss=+4.263e+22, best_epoch=52, best_loss=+9.875e+21]\n",
            "116it [00:19,  6.09it/s, epoch_progress=100%, train_loss=-1.822e+05, last_val_loss=+1.264e+22, best_epoch=16, best_loss=+5.174e+21]\n",
            "120it [00:19,  6.09it/s, epoch_progress=100%, train_loss=-2.026e+05, last_val_loss=+1.741e+22, best_epoch=20, best_loss=+5.378e+21]\n",
            "117it [00:18,  6.17it/s, epoch_progress=100%, train_loss=-2.104e+05, last_val_loss=+1.119e+22, best_epoch=17, best_loss=+4.739e+21]\n",
            "118it [00:19,  6.07it/s, epoch_progress=100%, train_loss=-1.799e+05, last_val_loss=+1.333e+22, best_epoch=18, best_loss=+4.560e+21]\n",
            " 33%|███▎      | 1/3 [02:41<05:23, 161.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 0\n",
            "Meta Train Error 2.0482741594314575\n",
            "Meta Train Accuracy 0.14375000214204192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "169it [00:27,  6.22it/s, epoch_progress=100%, train_loss=-2.071e+05, last_val_loss=+1.371e+22, best_epoch=69, best_loss=+6.994e+21]\n",
            "118it [00:18,  6.30it/s, epoch_progress=100%, train_loss=-1.911e+05, last_val_loss=+1.831e+22, best_epoch=18, best_loss=+4.323e+21]\n",
            "119it [00:18,  6.33it/s, epoch_progress=100%, train_loss=-2.164e+05, last_val_loss=+1.394e+22, best_epoch=19, best_loss=+2.955e+21]\n",
            "120it [00:19,  6.28it/s, epoch_progress=100%, train_loss=-1.819e+05, last_val_loss=+1.407e+22, best_epoch=20, best_loss=+4.070e+21]\n",
            "119it [00:18,  6.32it/s, epoch_progress=100%, train_loss=-1.760e+05, last_val_loss=+9.325e+21, best_epoch=19, best_loss=+7.412e+21]\n",
            "145it [00:23,  6.28it/s, epoch_progress=100%, train_loss=-2.408e+05, last_val_loss=+1.512e+22, best_epoch=45, best_loss=+5.344e+21]\n",
            "117it [00:18,  6.45it/s, epoch_progress=100%, train_loss=-1.854e+05, last_val_loss=+1.674e+22, best_epoch=17, best_loss=+4.872e+21]\n",
            "124it [00:19,  6.25it/s, epoch_progress=100%, train_loss=-2.105e+05, last_val_loss=+1.590e+22, best_epoch=24, best_loss=+5.379e+21]\n",
            " 67%|██████▋   | 2/3 [05:27<02:44, 164.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 1\n",
            "Meta Train Error 1.7234332263469696\n",
            "Meta Train Accuracy 0.23750000353902578\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "119it [00:18,  6.34it/s, epoch_progress=100%, train_loss=-1.963e+05, last_val_loss=+1.669e+22, best_epoch=19, best_loss=+6.158e+21]\n",
            "122it [00:19,  6.18it/s, epoch_progress=100%, train_loss=-2.350e+05, last_val_loss=+1.627e+22, best_epoch=22, best_loss=+7.052e+21]\n",
            "136it [00:21,  6.35it/s, epoch_progress=100%, train_loss=-1.865e+05, last_val_loss=+1.091e+22, best_epoch=36, best_loss=+5.672e+21]\n",
            "121it [00:19,  6.29it/s, epoch_progress=100%, train_loss=-2.377e+05, last_val_loss=+9.967e+21, best_epoch=21, best_loss=+5.124e+21]\n",
            "130it [00:21,  6.16it/s, epoch_progress=100%, train_loss=-2.071e+05, last_val_loss=+1.660e+22, best_epoch=30, best_loss=+5.688e+21]\n",
            "118it [00:18,  6.23it/s, epoch_progress=100%, train_loss=-2.019e+05, last_val_loss=+6.038e+23, best_epoch=18, best_loss=+6.320e+21]\n",
            "116it [00:18,  6.19it/s, epoch_progress=100%, train_loss=-1.871e+05, last_val_loss=+1.160e+22, best_epoch=16, best_loss=+9.125e+21]\n",
            "120it [00:19,  6.13it/s, epoch_progress=100%, train_loss=-2.024e+05, last_val_loss=+8.126e+21, best_epoch=20, best_loss=+5.214e+21]\n",
            "100%|██████████| 3/3 [08:06<00:00, 162.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 2\n",
            "Meta Train Error 2.1149842590093613\n",
            "Meta Train Accuracy 0.2187500037252903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean accuracy/loss, stddev, and confidence intervals\n",
            "(0.6215000123189142, 0.08055950191919135, 0.0064461026720695125)\n",
            "0.3750000074505806\n",
            "0.9000000059604645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjUYnTETmf-f"
      },
      "source": [
        "\n",
        "**SUMMARY OF EXP6**\n",
        "---\n",
        "\n",
        "lower fast_learning rate 0.3  and 3 iterations \n",
        "\n",
        "* **Standard MAML** \n",
        "\n",
        "  * Mean accuracy/loss, stddev, and confidence intervals\n",
        "  * (0.5623750121705234, 0.08327905596336382, 0.006663712316783581)\n",
        "\n",
        "----\n",
        "* **with the following flows**\n",
        "\n",
        "  * Mean accuracy/loss, stddev, and confidence intervals\n",
        "  * (0.6194583455100655, 0.08578994689481148, 0.006864625435123306)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKQQykdnme2A",
        "cellView": "form",
        "outputId": "6504d238-c931-493e-fd15-b1d6d18e4536"
      },
      "source": [
        "#@title COMPARE WITH EXP6 standard maml with fast_lr 0.3 and 3 iterations and rest of parameters as EXP4\n",
        "\n",
        "#@markdown Mean accuracy/loss, stddev, and confidence intervals\n",
        "\n",
        "#@markdown (0.5623750121705234, 0.08327905596336382, 0.006663712316783581)\n",
        "\n",
        "#@markdown min accuracy: 0.35000000335276127\n",
        "\n",
        "#@markdown max accuracy: 0.8250000067055225\n",
        "\n",
        "\"\"\"\n",
        "  Demonstrates how to:\n",
        "    * use the MAML wrapper for fast-adaptation,\n",
        "    * use the benchmark interface to load Omniglot, and\n",
        "    * sample tasks and split them in adaptation and evaluation sets.\n",
        "\"\"\"\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import learn2learn as l2l\n",
        "\n",
        "from torch import nn, optim\n",
        "\n",
        "\n",
        "\n",
        "def accuracy(predictions, targets):\n",
        "    predictions = predictions.argmax(dim=1).view(targets.shape)\n",
        "    return (predictions == targets).sum().float() / targets.size(0)\n",
        "\n",
        "\n",
        "def fast_adapt(batch, learner, loss, adaptation_steps, shots, ways, device):\n",
        "    data, labels = batch\n",
        "    data, labels = data.to(device), labels.to(device)\n",
        "\n",
        "    # Separate data into adaptation/evalutation sets\n",
        "    adaptation_indices = np.zeros(data.size(0), dtype=bool)\n",
        "    adaptation_indices[np.arange(shots*ways) * 2] = True\n",
        "    evaluation_indices = torch.from_numpy(~adaptation_indices)\n",
        "    adaptation_indices = torch.from_numpy(adaptation_indices)\n",
        "    adaptation_data, adaptation_labels = data[adaptation_indices], labels[adaptation_indices]\n",
        "    evaluation_data, evaluation_labels = data[evaluation_indices], labels[evaluation_indices]\n",
        "\n",
        "    # Adapt the model\n",
        "    for step in range(adaptation_steps):\n",
        "        train_error = loss(learner(adaptation_data), adaptation_labels)\n",
        "        learner.adapt(train_error)\n",
        "\n",
        "    # Evaluate the adapted model\n",
        "    predictions = learner(evaluation_data)\n",
        "    valid_error = loss(predictions, evaluation_labels)\n",
        "    valid_accuracy = accuracy(predictions, evaluation_labels)\n",
        "    return valid_error, valid_accuracy\n",
        "\n",
        "\n",
        "ways=5\n",
        "shots=1\n",
        "meta_lr=0.013\n",
        "fast_lr=0.3\n",
        "meta_batch_size=8\n",
        "adaptation_steps=1\n",
        "num_iterations=3\n",
        "cuda=True\n",
        "# seed=42,\n",
        "\n",
        "# random.seed(seed)\n",
        "# np.random.seed(seed)\n",
        "# torch.manual_seed(seed)\n",
        "device = torch.device('cpu')\n",
        "if cuda:\n",
        "    # torch.cuda.manual_seed(seed)\n",
        "    device = torch.device('cuda')\n",
        "\n",
        "# Load train/validation/test tasksets using the benchmark interface\n",
        "tasksets = l2l.vision.benchmarks.get_tasksets('omniglot',\n",
        "                                              train_ways=ways,\n",
        "                                              train_samples=2*shots,\n",
        "                                              test_ways=ways,\n",
        "                                              test_samples=2*shots,\n",
        "                                              num_tasks=20000,\n",
        "                                              root='~/data',\n",
        ")\n",
        "\n",
        "# Create model\n",
        "model =  l2l.vision.models.OmniglotCNN(ways)\n",
        "#model =  l2l.vision.models.OmniglotFC(28 ** 2, ways)\n",
        "model.to(device)\n",
        "maml = l2l.algorithms.MAML(model, lr=fast_lr, first_order=False)\n",
        "opt = optim.Adam(maml.parameters(), meta_lr)\n",
        "loss = nn.CrossEntropyLoss(reduction='mean')\n",
        "\n",
        "for iteration in range(num_iterations):\n",
        "    opt.zero_grad()\n",
        "    meta_train_error = 0.0\n",
        "    meta_train_accuracy = 0.0\n",
        "    meta_valid_error = 0.0\n",
        "    meta_valid_accuracy = 0.0\n",
        "    for task in range(meta_batch_size):\n",
        "        # Compute meta-training loss\n",
        "        learner = maml.clone()\n",
        "        batch = tasksets.train.sample()\n",
        "        evaluation_error, evaluation_accuracy = fast_adapt(batch,\n",
        "                                                            learner,\n",
        "                                                            loss,\n",
        "                                                            adaptation_steps,\n",
        "                                                            shots,\n",
        "                                                            ways,\n",
        "                                                            device)\n",
        "        evaluation_error.backward()\n",
        "        meta_train_error += evaluation_error.item()\n",
        "        meta_train_accuracy += evaluation_accuracy.item()\n",
        "\n",
        "        # Compute meta-validation loss\n",
        "        # learner = maml.clone()\n",
        "        # batch = tasksets.validation.sample()\n",
        "        # evaluation_error, evaluation_accuracy = fast_adapt(batch,\n",
        "        #                                                     learner,\n",
        "        #                                                     loss,\n",
        "        #                                                     adaptation_steps,\n",
        "        #                                                     shots,\n",
        "        #                                                     ways,\n",
        "        #                                                     device)\n",
        "        # meta_valid_error += evaluation_error.item()\n",
        "        # meta_valid_accuracy += evaluation_accuracy.item()\n",
        "\n",
        "    # Print some metrics\n",
        "    print('\\n')\n",
        "    print('Iteration', iteration)\n",
        "    print('Meta Train Error', meta_train_error / meta_batch_size)\n",
        "    print('Meta Train Accuracy', meta_train_accuracy / meta_batch_size)\n",
        "    # print('Meta Valid Error', meta_valid_error / meta_batch_size)\n",
        "    # print('Meta Valid Accuracy', meta_valid_accuracy / meta_batch_size)\n",
        "\n",
        "    # Average the accumulated gradients and optimize\n",
        "    for p in maml.parameters():\n",
        "        p.grad.data.mul_(1.0 / meta_batch_size)\n",
        "    opt.step()\n",
        "\n",
        "\n",
        "\n",
        "acc_acuracy=[]\n",
        "iterations=600\n",
        "\n",
        "for _ in range(iterations):\n",
        "  meta_test_error = 0.0\n",
        "  meta_test_accuracy = 0.0\n",
        "\n",
        "  for task in range(meta_batch_size):\n",
        "\n",
        "      # Compute meta-testing loss\n",
        "      learner = maml.clone()\n",
        "      batch = tasksets.test.sample()\n",
        "      evaluation_error, evaluation_accuracy = fast_adapt(batch,\n",
        "                                                          learner,\n",
        "                                                          loss,\n",
        "                                                          3,\n",
        "                                                          shots,\n",
        "                                                          ways,\n",
        "                                                          device)\n",
        "      meta_test_error += evaluation_error.item()\n",
        "      meta_test_accuracy += evaluation_accuracy.item()\n",
        "\n",
        "  # print('Meta Test Error', meta_test_error / meta_batch_size)\n",
        "  # print('Meta Test Accuracy', meta_test_accuracy / meta_batch_size)\n",
        "  acc_acuracy.append(meta_test_accuracy/meta_batch_size)\n",
        "\n",
        "\n",
        "acc_acuracy = np.array(acc_acuracy)\n",
        "means = np.mean(acc_acuracy, 0)\n",
        "stds = np.std(acc_acuracy, 0)\n",
        "ci95 = 1.96*stds/np.sqrt(iterations)\n",
        "\n",
        "print('Mean accuracy/loss, stddev, and confidence intervals')\n",
        "print((means, stds, ci95))\n",
        "\n",
        "print(acc_acuracy[acc_acuracy.argmin()])\n",
        "print(acc_acuracy[acc_acuracy.argmax()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:281: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "\n",
            "\n",
            "Iteration 0\n",
            "Meta Train Error 2.4023159593343735\n",
            "Meta Train Accuracy 0.2750000059604645\n",
            "\n",
            "\n",
            "Iteration 1\n",
            "Meta Train Error 1.9544251561164856\n",
            "Meta Train Accuracy 0.4000000078231096\n",
            "\n",
            "\n",
            "Iteration 2\n",
            "Meta Train Error 1.7129931673407555\n",
            "Meta Train Accuracy 0.4500000085681677\n",
            "Mean accuracy/loss, stddev, and confidence intervals\n",
            "(0.5623750121705234, 0.08327905596336382, 0.006663712316783581)\n",
            "0.35000000335276127\n",
            "0.8250000067055225\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O34LzAw3mXyC",
        "cellView": "form",
        "outputId": "8a3768f6-9fb9-42db-973f-17dfc120f79f"
      },
      "source": [
        "#@title EXP6 lower fast_learning rate 0.3  and 3 iterations \n",
        "#@markdown meta_lr 0.013 \n",
        "\n",
        "#@markdown 400 generated images instead of 1 shot per class \n",
        "\n",
        "#@markdown Foud that adding more layers of folws specifically batch normalization flow layer achives higher accuracy \n",
        "\n",
        "#@markdown Flow details:\n",
        "\n",
        "#@markdown    BatchNorm(dim=dim),ActNorm(dim=dim).warm_start(x=trainX),BatchNorm(dim=dim),ActNorm(dim=dim).warm_start(x=trainX),\n",
        "\n",
        "#@markdown    BatchNorm(dim=dim), 6 times \n",
        "\n",
        "#@markdown    Affine(dim=dim),Affine(dim=dim),\n",
        "\n",
        "\n",
        "#@markdown BatchNorm(dim=dim), 25 times \n",
        "\n",
        "#@markdown -----\n",
        "\n",
        "#@markdown Mean accuracy/loss, stddev, and confidence intervals\n",
        "\n",
        "#@markdown (0.6194583455100655, 0.08578994689481148, 0.006864625435123306)\n",
        "\n",
        "#@markdown min accuracy: 0.3000000063329935\n",
        "\n",
        "#@markdown max accuracy: 0.8500000089406967\n",
        "\n",
        "def accuracy(predictions, targets):\n",
        "    predictions = predictions.argmax(dim=1).view(targets.shape)\n",
        "    return (predictions == targets).sum().float() / targets.size(0)\n",
        "\n",
        "\n",
        "def fast_adapt(batch, learner, loss, adaptation_steps, shots, ways, device):\n",
        "    data, labels = batch\n",
        "    # print(\"data:  \",data.shape)\n",
        "    data, labels = data.to(device), labels.to(device, dtype=torch.int64)\n",
        "    # Separate data into adaptation/evalutation sets\n",
        "    adaptation_indices = np.zeros(data.size(0), dtype=bool)\n",
        "    adaptation_indices[np.arange(shots*ways) * 2] = True\n",
        "    evaluation_indices = torch.from_numpy(~adaptation_indices)\n",
        "    adaptation_indices = torch.from_numpy(adaptation_indices)\n",
        "    adaptation_data, adaptation_labels = data[adaptation_indices], labels[adaptation_indices]\n",
        "    evaluation_data, evaluation_labels = data[evaluation_indices], labels[evaluation_indices]\n",
        "\n",
        "    # Adapt the model\n",
        "    for step in range(adaptation_steps):\n",
        "        train_error = loss(learner(adaptation_data), adaptation_labels)\n",
        "        learner.adapt(train_error)\n",
        "\n",
        "\n",
        "    # Evaluate the adapted model\n",
        "    predictions = learner(evaluation_data)\n",
        "    valid_error = loss(predictions, evaluation_labels)\n",
        "    valid_accuracy = accuracy(predictions, evaluation_labels)\n",
        "    return valid_error, valid_accuracy\n",
        "\n",
        "\n",
        "def fast_adapt_train(batch, learner, loss, adaptation_steps, shots, ways, device):\n",
        "\n",
        "    data, labels = batch\n",
        "    data, labels = data.to(device), labels.to(device, dtype=torch.int64)\n",
        "    # Separate data into adaptation/evalutation sets\n",
        "    indices = np.random.permutation(data.shape[0])\n",
        "    \n",
        "    adaptation_indices = indices[:360]\n",
        "    evaluation_indices = indices[360:]\n",
        "    adaptation_data, adaptation_labels = data[adaptation_indices], labels[adaptation_indices]\n",
        "    evaluation_data, evaluation_labels = data[evaluation_indices], labels[evaluation_indices]\n",
        "    # print(adaptation_data.shape)\n",
        "    # print(\"modified version\")\n",
        "    # Adapt the model\n",
        "    for step in range(adaptation_steps):\n",
        "        train_error = loss(learner(adaptation_data), adaptation_labels)\n",
        "        learner.adapt(train_error)\n",
        "\n",
        "\n",
        "    # Evaluate the adapted model\n",
        "    predictions = learner(evaluation_data)\n",
        "    valid_error = loss(predictions, evaluation_labels)\n",
        "    valid_accuracy = accuracy(predictions, evaluation_labels)\n",
        "    return valid_error, valid_accuracy\n",
        "\n",
        "def train_flow (trainX ,cond_train , device):\n",
        "\n",
        "  \n",
        "  # trainX has a shape of (count , channel , pixles,pixles)\n",
        "  \n",
        "\n",
        "  trainX = torch.flatten(trainX,1,-1)\n",
        "  # valX = torch.flatten(valX , 1,-1)\n",
        "  dim=trainX.shape[1]\n",
        "  \n",
        "  # print(cond_train)\n",
        "  cond_train = torch.nn.functional.one_hot(cond_train)\n",
        "  # cond_val   = torch.nn.functional.one_hot(cond_val) \n",
        "  # print(cond_train)\n",
        "  cond_dim = cond_train.size(1)\n",
        "  \n",
        "  flow = Sequential(      \n",
        "\n",
        "      # MADE(AffineTransformer(dim=dim) , cond_dim=cond_dim),\n",
        "      # MADE(AffineTransformer(dim=dim) , cond_dim=cond_dim),\n",
        "\n",
        "  # very slow in sampling \n",
        "    # inv_flow(Sigmoid)(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    ActNorm(dim=dim).warm_start(x=trainX),\n",
        "    BatchNorm(dim=dim),\n",
        "    ActNorm(dim=dim).warm_start(x=trainX),\n",
        "    # BatchNorm(dim=dim),\n",
        "    # ActNorm(dim=dim).warm_start(x=trainX),\n",
        "# //////////////////\n",
        "    #     BatchNorm(dim=dim),\n",
        "    # ActNorm(dim=dim).warm_start(x=trainX),\n",
        "    # BatchNorm(dim=dim),\n",
        "    # ActNorm(dim=dim).warm_start(x=trainX),\n",
        "    # BatchNorm(dim=dim),\n",
        "    # ActNorm(dim=dim).warm_start(x=trainX),\n",
        "    # BatchNorm(dim=dim),\n",
        "    # ActNorm(dim=dim).warm_start(x=trainX),\n",
        "    # BatchNorm(dim=dim),\n",
        "    # ActNorm(dim=dim).warm_start(x=trainX),\n",
        "# ////////\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    # MADE(DSF(dim=dim), cond_dim=cond_dim),\n",
        "    Affine(dim=dim),  \n",
        "    Affine(dim=dim),  \n",
        "BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "\n",
        "      # BatchNorm(dim=dim),\n",
        "      # Shuffle(dim=dim),\n",
        "      # CouplingLayers(AffineTransformer(dim=dim//2 ) ,dim=dim),\n",
        "\n",
        "  ).to(device)\n",
        "  train_losses, val_losses = train(flow, trainX, trainX ,cond_train=cond_train, cond_val=cond_train , patience=100 ,batch_size=8,n_epochs=1000)\n",
        " \n",
        "  test_labels = np.random.choice(5, size=(400))\n",
        "  test_labels = torch.from_numpy(test_labels)\n",
        "  test_cond = torch.nn.functional.one_hot(test_labels)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    train_data = flow.sample(400,cond=test_cond.to(device)).cpu()\n",
        "\n",
        "  # return train_data, train_losses , val_losses , mean , var\n",
        "  return torch.reshape(train_data , (400,1,28,28)) , test_labels\n",
        "\n",
        "\n",
        "\n",
        "ways=5\n",
        "shots=1\n",
        "meta_lr=0.013\n",
        "fast_lr=0.3\n",
        "meta_batch_size=8\n",
        "adaptation_steps=1\n",
        "num_iterations=3\n",
        "cuda=True\n",
        "# seed=42\n",
        "# Load train/validation/test tasksets using the benchmark interface\n",
        "tasksets = l2l.vision.benchmarks.get_tasksets('omniglot',\n",
        "                                                  train_ways=ways,\n",
        "                                                  train_samples=2*shots,\n",
        "                                                  test_ways=ways,\n",
        "                                                  test_samples=2*shots,\n",
        "                                                  num_tasks=20000,\n",
        "                                                  root='~/data',\n",
        "    )\n",
        "\n",
        "# dim = 28*28\n",
        "\n",
        "device = torch.device('cpu')\n",
        "if cuda:\n",
        "  # torch.cuda.manual_seed(seed)\n",
        "  device = torch.device('cuda')\n",
        "\n",
        "# Create model\n",
        "model = l2l.vision.models.OmniglotCNN(ways)\n",
        "# model = l2l.vision.models.OmniglotFC(28 ** 2, ways)\n",
        "model.to(device)\n",
        "maml = l2l.algorithms.MAML(model, lr=fast_lr, first_order=False)\n",
        "opt = optim.Adam(maml.parameters(), meta_lr)\n",
        "loss = nn.CrossEntropyLoss(reduction='mean')\n",
        "\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "for iteration in tqdm(range(num_iterations)):\n",
        "    opt.zero_grad()\n",
        "    meta_train_error = 0.0\n",
        "    meta_train_accuracy = 0.0\n",
        "    meta_valid_error = 0.0\n",
        "    meta_valid_accuracy = 0.0\n",
        "\n",
        "    for task in range(meta_batch_size):\n",
        "        # Compute meta-training loss\n",
        "        # learner = maml.clone()\n",
        "\n",
        "        # generate batch the batch contains # ways*shots , channels , img size  and labels \n",
        "        train_batch = tasksets.train.sample()\n",
        "        val_batch = tasksets.validation.sample()\n",
        "\n",
        "        # split batch based on classes in labels then   labels.split(int(data.shape[0]/ways))\n",
        "        train_data, train_labels = train_batch\n",
        "        val_data , val_labels= val_batch\n",
        "\n",
        "        \n",
        "        train_data_generator ,train_lable_generator  = train_flow (train_data ,train_labels  , device)\n",
        "\n",
        "        # train_data_generator = torch.cat(train_data_generator)\n",
        "        # train_lable_generator = torch.cat(train_lable_generator)\n",
        "        \n",
        "        batch = [train_data_generator ,train_lable_generator]\n",
        "\n",
        "        learner = maml.clone()            \n",
        "        \n",
        "        evaluation_error, evaluation_accuracy = fast_adapt_train(batch,\n",
        "                                                            learner,\n",
        "                                                            loss,\n",
        "                                                            adaptation_steps,\n",
        "                                                            shots,\n",
        "                                                            ways,\n",
        "                                                            device)\n",
        "        evaluation_error.backward()\n",
        "        meta_train_error += evaluation_error.item()\n",
        "        meta_train_accuracy += evaluation_accuracy.item()\n",
        "\n",
        "# ''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
        "\n",
        "        # # Compute meta-validation loss\n",
        "        # batch = tasksets.validation.sample()\n",
        "        \n",
        "        # learner = maml.clone()\n",
        "        # evaluation_error, evaluation_accuracy = fast_adapt(batch,learner,loss,adaptation_steps,shots,ways,\n",
        "        #                                                     device)\n",
        "        # meta_valid_error += evaluation_error.item()\n",
        "        # meta_valid_accuracy += evaluation_accuracy.item()\n",
        "\n",
        "    # Print some metrics\n",
        "    print('\\n')\n",
        "    print('Iteration', iteration)\n",
        "    print('Meta Train Error', meta_train_error / meta_batch_size)\n",
        "    print('Meta Train Accuracy', meta_train_accuracy / meta_batch_size)\n",
        "    # print('Meta Valid Error', meta_valid_error / meta_batch_size)\n",
        "    # print('Meta Valid Accuracy', meta_valid_accuracy / meta_batch_size)\n",
        "\n",
        "    # Average the accumulated gradients and optimize\n",
        "    for p in maml.parameters():\n",
        "        p.grad.data.mul_(1.0 / meta_batch_size)\n",
        "    opt.step()\n",
        "\n",
        "\n",
        "acc_acuracy=[]\n",
        "iterations= 600\n",
        "for _ in range(iterations):\n",
        "  meta_test_error = 0.0\n",
        "  meta_test_accuracy = 0.0\n",
        "\n",
        "  for task in range(meta_batch_size):\n",
        "\n",
        "      # Compute meta-testing loss\n",
        "      learner = maml.clone()\n",
        "      batch = tasksets.test.sample()\n",
        "      evaluation_error, evaluation_accuracy = fast_adapt(batch,\n",
        "                                                          learner,\n",
        "                                                          loss,\n",
        "                                                          3,\n",
        "                                                          shots,\n",
        "                                                          ways,\n",
        "                                                          device)\n",
        "      meta_test_error += evaluation_error.item()\n",
        "      meta_test_accuracy += evaluation_accuracy.item()\n",
        "\n",
        "  # print('Meta Test Error', meta_test_error / meta_batch_size)\n",
        "  # print('Meta Test Accuracy', meta_test_accuracy / meta_batch_size)\n",
        "  acc_acuracy.append(meta_test_accuracy/meta_batch_size)\n",
        "\n",
        "\n",
        "acc_acuracy = np.array(acc_acuracy)\n",
        "means = np.mean(acc_acuracy, 0)\n",
        "stds = np.std(acc_acuracy, 0)\n",
        "ci95 = 1.96*stds/np.sqrt(iterations)\n",
        "\n",
        "print('Mean accuracy/loss, stddev, and confidence intervals')\n",
        "print((means, stds, ci95))\n",
        "\n",
        "print(acc_acuracy[acc_acuracy.argmin()])\n",
        "print(acc_acuracy[acc_acuracy.argmax()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:281: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "158it [00:25,  6.18it/s, epoch_progress=100%, train_loss=-2.131e+05, last_val_loss=+1.212e+22, best_epoch=58, best_loss=+7.539e+21]\n",
            "116it [00:18,  6.17it/s, epoch_progress=100%, train_loss=-1.931e+05, last_val_loss=+1.498e+22, best_epoch=16, best_loss=+2.559e+21]\n",
            "118it [00:18,  6.23it/s, epoch_progress=100%, train_loss=-2.231e+05, last_val_loss=+1.463e+22, best_epoch=18, best_loss=+1.260e+21]\n",
            "134it [00:21,  6.28it/s, epoch_progress=100%, train_loss=-1.803e+05, last_val_loss=+1.213e+22, best_epoch=34, best_loss=+5.320e+21]\n",
            "117it [00:18,  6.27it/s, epoch_progress=100%, train_loss=-2.431e+05, last_val_loss=+1.504e+22, best_epoch=17, best_loss=+2.121e+21]\n",
            "151it [00:23,  6.35it/s, epoch_progress=100%, train_loss=-2.298e+05, last_val_loss=+1.885e+22, best_epoch=51, best_loss=+5.011e+21]\n",
            "139it [00:22,  6.19it/s, epoch_progress=100%, train_loss=-2.464e+05, last_val_loss=+2.158e+22, best_epoch=39, best_loss=+6.262e+21]\n",
            "116it [00:18,  6.30it/s, epoch_progress=100%, train_loss=-2.539e+05, last_val_loss=+1.429e+22, best_epoch=16, best_loss=+2.627e+21]\n",
            " 33%|███▎      | 1/3 [02:49<05:39, 169.96s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Iteration 0\n",
            "Meta Train Error 1.8237886130809784\n",
            "Meta Train Accuracy 0.20000000298023224\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "121it [00:19,  6.24it/s, epoch_progress=100%, train_loss=-2.122e+05, last_val_loss=+3.005e+22, best_epoch=21, best_loss=+6.557e+21]\n",
            "125it [00:19,  6.34it/s, epoch_progress=100%, train_loss=-2.117e+05, last_val_loss=+2.679e+22, best_epoch=25, best_loss=+6.031e+21]\n",
            "116it [00:18,  6.31it/s, epoch_progress=100%, train_loss=-2.134e+05, last_val_loss=+2.246e+22, best_epoch=16, best_loss=+5.310e+21]\n",
            "117it [00:19,  6.13it/s, epoch_progress=100%, train_loss=-2.252e+05, last_val_loss=+3.898e+23, best_epoch=17, best_loss=+3.590e+21]\n",
            "239it [00:38,  6.23it/s, epoch_progress=100%, train_loss=-1.920e+05, last_val_loss=+2.237e+22, best_epoch=139, best_loss=+7.123e+21]\n",
            "119it [00:19,  6.14it/s, epoch_progress=100%, train_loss=-2.269e+05, last_val_loss=+1.270e+22, best_epoch=19, best_loss=+3.217e+21]\n",
            "122it [00:19,  6.14it/s, epoch_progress=100%, train_loss=-1.624e+05, last_val_loss=+7.836e+21, best_epoch=22, best_loss=+4.787e+21]\n",
            "123it [00:19,  6.18it/s, epoch_progress=100%, train_loss=-2.515e+05, last_val_loss=+2.475e+22, best_epoch=23, best_loss=+6.598e+21]\n",
            " 67%|██████▋   | 2/3 [05:46<02:53, 173.56s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Iteration 1\n",
            "Meta Train Error 1.7138043642044067\n",
            "Meta Train Accuracy 0.2343750074505806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "114it [00:18,  6.19it/s, epoch_progress=100%, train_loss=-2.267e+05, last_val_loss=+1.098e+22, best_epoch=14, best_loss=+3.678e+21]\n",
            "128it [00:21,  6.02it/s, epoch_progress=100%, train_loss=-1.883e+05, last_val_loss=+1.772e+28, best_epoch=28, best_loss=+7.278e+21]\n",
            "154it [00:25,  6.08it/s, epoch_progress=100%, train_loss=-1.781e+05, last_val_loss=+2.336e+22, best_epoch=54, best_loss=+7.276e+21]\n",
            "179it [00:28,  6.18it/s, epoch_progress=100%, train_loss=-1.907e+05, last_val_loss=+3.013e+22, best_epoch=79, best_loss=+8.359e+21]\n",
            "121it [00:19,  6.12it/s, epoch_progress=100%, train_loss=-1.950e+05, last_val_loss=+2.129e+22, best_epoch=21, best_loss=+5.357e+21]\n",
            "125it [00:20,  6.04it/s, epoch_progress=100%, train_loss=-2.314e+05, last_val_loss=+1.753e+22, best_epoch=25, best_loss=+3.301e+21]\n",
            "116it [00:18,  6.11it/s, epoch_progress=100%, train_loss=-2.342e+05, last_val_loss=+1.532e+22, best_epoch=16, best_loss=+3.329e+21]\n",
            "132it [00:21,  6.28it/s, epoch_progress=100%, train_loss=-2.086e+05, last_val_loss=+2.557e+22, best_epoch=32, best_loss=+5.271e+21]\n",
            "100%|██████████| 3/3 [08:42<00:00, 174.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 2\n",
            "Meta Train Error 1.7486406862735748\n",
            "Meta Train Accuracy 0.17187500279396772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean accuracy/loss, stddev, and confidence intervals\n",
            "(0.6194583455100655, 0.08578994689481148, 0.006864625435123306)\n",
            "0.3000000063329935\n",
            "0.8500000089406967\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gJraykxXisk"
      },
      "source": [
        "\n",
        "**SUMMARY OF EXP5**\n",
        "---\n",
        "\n",
        "lower fast_learning rate 0.2  and 3 iterations \n",
        "\n",
        "* **Standard MAML** \n",
        "\n",
        "  * Mean accuracy/loss, stddev, and confidence intervals\n",
        "  * (0.5799166787912449, 0.08488223104448211, 0.006791993040075019)\n",
        "\n",
        "-----\n",
        "\n",
        "* **with the following flows**\n",
        "\n",
        "  * Mean accuracy/loss, stddev, and confidence intervals\n",
        "  * (0.6055000121239573, 0.08472357040113233, 0.006779297544538376)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Kh3Myeq65Yd",
        "cellView": "form",
        "outputId": "39a0f782-bedd-45c7-f3cb-554728bb9cb3"
      },
      "source": [
        "#@title COMPARE WITH EXP5 standard maml with fast_lr 0.2 and 3 iterations and rest of parameters as EXP4\n",
        "\n",
        "#@markdown Mean accuracy/loss, stddev, and confidence intervals\n",
        "\n",
        "#@markdown (0.5799166787912449, 0.08488223104448211, 0.006791993040075019)\n",
        "\n",
        "#@markdown 0.32500000670552254\n",
        "\n",
        "#@markdown 0.8250000067055225\n",
        "\n",
        "\"\"\"\n",
        "  Demonstrates how to:\n",
        "    * use the MAML wrapper for fast-adaptation,\n",
        "    * use the benchmark interface to load Omniglot, and\n",
        "    * sample tasks and split them in adaptation and evaluation sets.\n",
        "\"\"\"\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import learn2learn as l2l\n",
        "\n",
        "from torch import nn, optim\n",
        "\n",
        "\n",
        "\n",
        "def accuracy(predictions, targets):\n",
        "    predictions = predictions.argmax(dim=1).view(targets.shape)\n",
        "    return (predictions == targets).sum().float() / targets.size(0)\n",
        "\n",
        "\n",
        "def fast_adapt(batch, learner, loss, adaptation_steps, shots, ways, device):\n",
        "    data, labels = batch\n",
        "    data, labels = data.to(device), labels.to(device)\n",
        "\n",
        "    # Separate data into adaptation/evalutation sets\n",
        "    adaptation_indices = np.zeros(data.size(0), dtype=bool)\n",
        "    adaptation_indices[np.arange(shots*ways) * 2] = True\n",
        "    evaluation_indices = torch.from_numpy(~adaptation_indices)\n",
        "    adaptation_indices = torch.from_numpy(adaptation_indices)\n",
        "    adaptation_data, adaptation_labels = data[adaptation_indices], labels[adaptation_indices]\n",
        "    evaluation_data, evaluation_labels = data[evaluation_indices], labels[evaluation_indices]\n",
        "\n",
        "    # Adapt the model\n",
        "    for step in range(adaptation_steps):\n",
        "        train_error = loss(learner(adaptation_data), adaptation_labels)\n",
        "        learner.adapt(train_error)\n",
        "\n",
        "    # Evaluate the adapted model\n",
        "    predictions = learner(evaluation_data)\n",
        "    valid_error = loss(predictions, evaluation_labels)\n",
        "    valid_accuracy = accuracy(predictions, evaluation_labels)\n",
        "    return valid_error, valid_accuracy\n",
        "\n",
        "\n",
        "ways=5\n",
        "shots=1\n",
        "meta_lr=0.013\n",
        "fast_lr=0.2\n",
        "meta_batch_size=8\n",
        "adaptation_steps=1\n",
        "num_iterations=3\n",
        "cuda=True\n",
        "# seed=42,\n",
        "\n",
        "# random.seed(seed)\n",
        "# np.random.seed(seed)\n",
        "# torch.manual_seed(seed)\n",
        "device = torch.device('cpu')\n",
        "if cuda:\n",
        "    # torch.cuda.manual_seed(seed)\n",
        "    device = torch.device('cuda')\n",
        "\n",
        "# Load train/validation/test tasksets using the benchmark interface\n",
        "tasksets = l2l.vision.benchmarks.get_tasksets('omniglot',\n",
        "                                              train_ways=ways,\n",
        "                                              train_samples=2*shots,\n",
        "                                              test_ways=ways,\n",
        "                                              test_samples=2*shots,\n",
        "                                              num_tasks=20000,\n",
        "                                              root='~/data',\n",
        ")\n",
        "\n",
        "# Create model\n",
        "model =  l2l.vision.models.OmniglotCNN(ways)\n",
        "#model =  l2l.vision.models.OmniglotFC(28 ** 2, ways)\n",
        "model.to(device)\n",
        "maml = l2l.algorithms.MAML(model, lr=fast_lr, first_order=False)\n",
        "opt = optim.Adam(maml.parameters(), meta_lr)\n",
        "loss = nn.CrossEntropyLoss(reduction='mean')\n",
        "\n",
        "for iteration in range(num_iterations):\n",
        "    opt.zero_grad()\n",
        "    meta_train_error = 0.0\n",
        "    meta_train_accuracy = 0.0\n",
        "    meta_valid_error = 0.0\n",
        "    meta_valid_accuracy = 0.0\n",
        "    for task in range(meta_batch_size):\n",
        "        # Compute meta-training loss\n",
        "        learner = maml.clone()\n",
        "        batch = tasksets.train.sample()\n",
        "        evaluation_error, evaluation_accuracy = fast_adapt(batch,\n",
        "                                                            learner,\n",
        "                                                            loss,\n",
        "                                                            adaptation_steps,\n",
        "                                                            shots,\n",
        "                                                            ways,\n",
        "                                                            device)\n",
        "        evaluation_error.backward()\n",
        "        meta_train_error += evaluation_error.item()\n",
        "        meta_train_accuracy += evaluation_accuracy.item()\n",
        "\n",
        "        # Compute meta-validation loss\n",
        "        # learner = maml.clone()\n",
        "        # batch = tasksets.validation.sample()\n",
        "        # evaluation_error, evaluation_accuracy = fast_adapt(batch,\n",
        "        #                                                     learner,\n",
        "        #                                                     loss,\n",
        "        #                                                     adaptation_steps,\n",
        "        #                                                     shots,\n",
        "        #                                                     ways,\n",
        "        #                                                     device)\n",
        "        # meta_valid_error += evaluation_error.item()\n",
        "        # meta_valid_accuracy += evaluation_accuracy.item()\n",
        "\n",
        "    # Print some metrics\n",
        "    print('\\n')\n",
        "    print('Iteration', iteration)\n",
        "    print('Meta Train Error', meta_train_error / meta_batch_size)\n",
        "    print('Meta Train Accuracy', meta_train_accuracy / meta_batch_size)\n",
        "    # print('Meta Valid Error', meta_valid_error / meta_batch_size)\n",
        "    # print('Meta Valid Accuracy', meta_valid_accuracy / meta_batch_size)\n",
        "\n",
        "    # Average the accumulated gradients and optimize\n",
        "    for p in maml.parameters():\n",
        "        p.grad.data.mul_(1.0 / meta_batch_size)\n",
        "    opt.step()\n",
        "\n",
        "\n",
        "\n",
        "acc_acuracy=[]\n",
        "iterations=600\n",
        "\n",
        "for _ in range(iterations):\n",
        "  meta_test_error = 0.0\n",
        "  meta_test_accuracy = 0.0\n",
        "\n",
        "  for task in range(meta_batch_size):\n",
        "\n",
        "      # Compute meta-testing loss\n",
        "      learner = maml.clone()\n",
        "      batch = tasksets.test.sample()\n",
        "      evaluation_error, evaluation_accuracy = fast_adapt(batch,\n",
        "                                                          learner,\n",
        "                                                          loss,\n",
        "                                                          3,\n",
        "                                                          shots,\n",
        "                                                          ways,\n",
        "                                                          device)\n",
        "      meta_test_error += evaluation_error.item()\n",
        "      meta_test_accuracy += evaluation_accuracy.item()\n",
        "\n",
        "  # print('Meta Test Error', meta_test_error / meta_batch_size)\n",
        "  # print('Meta Test Accuracy', meta_test_accuracy / meta_batch_size)\n",
        "  acc_acuracy.append(meta_test_accuracy/meta_batch_size)\n",
        "\n",
        "\n",
        "acc_acuracy = np.array(acc_acuracy)\n",
        "means = np.mean(acc_acuracy, 0)\n",
        "stds = np.std(acc_acuracy, 0)\n",
        "ci95 = 1.96*stds/np.sqrt(iterations)\n",
        "\n",
        "print('Mean accuracy/loss, stddev, and confidence intervals')\n",
        "print((means, stds, ci95))\n",
        "\n",
        "print(acc_acuracy[acc_acuracy.argmin()])\n",
        "print(acc_acuracy[acc_acuracy.argmax()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:281: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "\n",
            "\n",
            "Iteration 0\n",
            "Meta Train Error 1.3961520940065384\n",
            "Meta Train Accuracy 0.4500000085681677\n",
            "\n",
            "\n",
            "Iteration 1\n",
            "Meta Train Error 1.56709473580122\n",
            "Meta Train Accuracy 0.4250000063329935\n",
            "\n",
            "\n",
            "Iteration 2\n",
            "Meta Train Error 1.0159304700791836\n",
            "Meta Train Accuracy 0.7250000108033419\n",
            "Mean accuracy/loss, stddev, and confidence intervals\n",
            "(0.5799166787912449, 0.08488223104448211, 0.006791993040075019)\n",
            "0.32500000670552254\n",
            "0.8250000067055225\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtqVblER3rV9",
        "outputId": "3564bd34-531f-4047-bdb9-47940c65ab16"
      },
      "source": [
        "#@title EXP5 lower fast_learning rate 0.2  and 3 iterations \n",
        "#@markdown meta_lr 0.013 \n",
        "\n",
        "#@markdown 400 generated images instead of 1 shot per class \n",
        "\n",
        "#@markdown Foud that adding more layers of folws specifically batch normalization flow layer achives higher accuracy \n",
        "\n",
        "#@markdown Flow details:\n",
        "\n",
        "#@markdown    BatchNorm(dim=dim),ActNorm(dim=dim).warm_start(x=trainX),BatchNorm(dim=dim),ActNorm(dim=dim).warm_start(x=trainX),\n",
        "\n",
        "#@markdown    BatchNorm(dim=dim), 6 times \n",
        "\n",
        "#@markdown    Affine(dim=dim),Affine(dim=dim),\n",
        "\n",
        "\n",
        "#@markdown BatchNorm(dim=dim), 25 times \n",
        "\n",
        "#@markdown ----\n",
        "\n",
        "#@markdown Mean accuracy/loss, stddev, and confidence intervals\n",
        "\n",
        "#@markdown (0.6055000121239573, 0.08472357040113233, 0.006779297544538376)\n",
        "\n",
        "#@markdown min accuracy: 0.3500000052154064\n",
        "\n",
        "#@markdown max accuracy: 0.8500000089406967\n",
        "\n",
        "def accuracy(predictions, targets):\n",
        "    predictions = predictions.argmax(dim=1).view(targets.shape)\n",
        "    return (predictions == targets).sum().float() / targets.size(0)\n",
        "\n",
        "\n",
        "def fast_adapt(batch, learner, loss, adaptation_steps, shots, ways, device):\n",
        "    data, labels = batch\n",
        "    # print(\"data:  \",data.shape)\n",
        "    data, labels = data.to(device), labels.to(device, dtype=torch.int64)\n",
        "    # Separate data into adaptation/evalutation sets\n",
        "    adaptation_indices = np.zeros(data.size(0), dtype=bool)\n",
        "    adaptation_indices[np.arange(shots*ways) * 2] = True\n",
        "    evaluation_indices = torch.from_numpy(~adaptation_indices)\n",
        "    adaptation_indices = torch.from_numpy(adaptation_indices)\n",
        "    adaptation_data, adaptation_labels = data[adaptation_indices], labels[adaptation_indices]\n",
        "    evaluation_data, evaluation_labels = data[evaluation_indices], labels[evaluation_indices]\n",
        "\n",
        "    # Adapt the model\n",
        "    for step in range(adaptation_steps):\n",
        "        train_error = loss(learner(adaptation_data), adaptation_labels)\n",
        "        learner.adapt(train_error)\n",
        "\n",
        "\n",
        "    # Evaluate the adapted model\n",
        "    predictions = learner(evaluation_data)\n",
        "    valid_error = loss(predictions, evaluation_labels)\n",
        "    valid_accuracy = accuracy(predictions, evaluation_labels)\n",
        "    return valid_error, valid_accuracy\n",
        "\n",
        "\n",
        "def fast_adapt_train(batch, learner, loss, adaptation_steps, shots, ways, device):\n",
        "\n",
        "    data, labels = batch\n",
        "    data, labels = data.to(device), labels.to(device, dtype=torch.int64)\n",
        "    # Separate data into adaptation/evalutation sets\n",
        "    indices = np.random.permutation(data.shape[0])\n",
        "    \n",
        "    adaptation_indices = indices[:360]\n",
        "    evaluation_indices = indices[360:]\n",
        "    adaptation_data, adaptation_labels = data[adaptation_indices], labels[adaptation_indices]\n",
        "    evaluation_data, evaluation_labels = data[evaluation_indices], labels[evaluation_indices]\n",
        "    # print(adaptation_data.shape)\n",
        "    # print(\"modified version\")\n",
        "    # Adapt the model\n",
        "    for step in range(adaptation_steps):\n",
        "        train_error = loss(learner(adaptation_data), adaptation_labels)\n",
        "        learner.adapt(train_error)\n",
        "\n",
        "\n",
        "    # Evaluate the adapted model\n",
        "    predictions = learner(evaluation_data)\n",
        "    valid_error = loss(predictions, evaluation_labels)\n",
        "    valid_accuracy = accuracy(predictions, evaluation_labels)\n",
        "    return valid_error, valid_accuracy\n",
        "\n",
        "def train_flow (trainX ,cond_train , device):\n",
        "\n",
        "  \n",
        "  # trainX has a shape of (count , channel , pixles,pixles)\n",
        "  \n",
        "\n",
        "  trainX = torch.flatten(trainX,1,-1)\n",
        "  # valX = torch.flatten(valX , 1,-1)\n",
        "  dim=trainX.shape[1]\n",
        "  \n",
        "  # print(cond_train)\n",
        "  cond_train = torch.nn.functional.one_hot(cond_train)\n",
        "  # cond_val   = torch.nn.functional.one_hot(cond_val) \n",
        "  # print(cond_train)\n",
        "  cond_dim = cond_train.size(1)\n",
        "  \n",
        "  flow = Sequential(      \n",
        "\n",
        "      # MADE(AffineTransformer(dim=dim) , cond_dim=cond_dim),\n",
        "      # MADE(AffineTransformer(dim=dim) , cond_dim=cond_dim),\n",
        "\n",
        "  # very slow in sampling \n",
        "    # inv_flow(Sigmoid)(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    ActNorm(dim=dim).warm_start(x=trainX),\n",
        "    BatchNorm(dim=dim),\n",
        "    ActNorm(dim=dim).warm_start(x=trainX),\n",
        "    # BatchNorm(dim=dim),\n",
        "    # ActNorm(dim=dim).warm_start(x=trainX),\n",
        "# //////////////////\n",
        "    #     BatchNorm(dim=dim),\n",
        "    # ActNorm(dim=dim).warm_start(x=trainX),\n",
        "    # BatchNorm(dim=dim),\n",
        "    # ActNorm(dim=dim).warm_start(x=trainX),\n",
        "    # BatchNorm(dim=dim),\n",
        "    # ActNorm(dim=dim).warm_start(x=trainX),\n",
        "    # BatchNorm(dim=dim),\n",
        "    # ActNorm(dim=dim).warm_start(x=trainX),\n",
        "    # BatchNorm(dim=dim),\n",
        "    # ActNorm(dim=dim).warm_start(x=trainX),\n",
        "# ////////\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    # MADE(DSF(dim=dim), cond_dim=cond_dim),\n",
        "    Affine(dim=dim),  \n",
        "    Affine(dim=dim),  \n",
        "BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "\n",
        "      # BatchNorm(dim=dim),\n",
        "      # Shuffle(dim=dim),\n",
        "      # CouplingLayers(AffineTransformer(dim=dim//2 ) ,dim=dim),\n",
        "\n",
        "  ).to(device)\n",
        "  train_losses, val_losses = train(flow, trainX, trainX ,cond_train=cond_train, cond_val=cond_train , patience=100 ,batch_size=8,n_epochs=1000)\n",
        " \n",
        "  test_labels = np.random.choice(5, size=(400))\n",
        "  test_labels = torch.from_numpy(test_labels)\n",
        "  test_cond = torch.nn.functional.one_hot(test_labels)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    train_data = flow.sample(400,cond=test_cond.to(device)).cpu()\n",
        "\n",
        "  # return train_data, train_losses , val_losses , mean , var\n",
        "  return torch.reshape(train_data , (400,1,28,28)) , test_labels\n",
        "\n",
        "\n",
        "\n",
        "ways=5\n",
        "shots=1\n",
        "meta_lr=0.013\n",
        "fast_lr=0.2\n",
        "meta_batch_size=8\n",
        "adaptation_steps=1\n",
        "num_iterations=3\n",
        "cuda=True\n",
        "# seed=42\n",
        "# Load train/validation/test tasksets using the benchmark interface\n",
        "tasksets = l2l.vision.benchmarks.get_tasksets('omniglot',\n",
        "                                                  train_ways=ways,\n",
        "                                                  train_samples=2*shots,\n",
        "                                                  test_ways=ways,\n",
        "                                                  test_samples=2*shots,\n",
        "                                                  num_tasks=20000,\n",
        "                                                  root='~/data',\n",
        "    )\n",
        "\n",
        "# dim = 28*28\n",
        "\n",
        "device = torch.device('cpu')\n",
        "if cuda:\n",
        "  # torch.cuda.manual_seed(seed)\n",
        "  device = torch.device('cuda')\n",
        "\n",
        "# Create model\n",
        "model = l2l.vision.models.OmniglotCNN(ways)\n",
        "# model = l2l.vision.models.OmniglotFC(28 ** 2, ways)\n",
        "model.to(device)\n",
        "maml = l2l.algorithms.MAML(model, lr=fast_lr, first_order=False)\n",
        "opt = optim.Adam(maml.parameters(), meta_lr)\n",
        "loss = nn.CrossEntropyLoss(reduction='mean')\n",
        "\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "for iteration in tqdm(range(num_iterations)):\n",
        "    opt.zero_grad()\n",
        "    meta_train_error = 0.0\n",
        "    meta_train_accuracy = 0.0\n",
        "    meta_valid_error = 0.0\n",
        "    meta_valid_accuracy = 0.0\n",
        "\n",
        "    for task in range(meta_batch_size):\n",
        "        # Compute meta-training loss\n",
        "        # learner = maml.clone()\n",
        "\n",
        "        # generate batch the batch contains # ways*shots , channels , img size  and labels \n",
        "        train_batch = tasksets.train.sample()\n",
        "        val_batch = tasksets.validation.sample()\n",
        "\n",
        "        # split batch based on classes in labels then   labels.split(int(data.shape[0]/ways))\n",
        "        train_data, train_labels = train_batch\n",
        "        val_data , val_labels= val_batch\n",
        "\n",
        "        \n",
        "        train_data_generator ,train_lable_generator  = train_flow (train_data ,train_labels  , device)\n",
        "\n",
        "        # train_data_generator = torch.cat(train_data_generator)\n",
        "        # train_lable_generator = torch.cat(train_lable_generator)\n",
        "        \n",
        "        batch = [train_data_generator ,train_lable_generator]\n",
        "\n",
        "        learner = maml.clone()            \n",
        "        \n",
        "        evaluation_error, evaluation_accuracy = fast_adapt_train(batch,\n",
        "                                                            learner,\n",
        "                                                            loss,\n",
        "                                                            adaptation_steps,\n",
        "                                                            shots,\n",
        "                                                            ways,\n",
        "                                                            device)\n",
        "        evaluation_error.backward()\n",
        "        meta_train_error += evaluation_error.item()\n",
        "        meta_train_accuracy += evaluation_accuracy.item()\n",
        "\n",
        "# ''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
        "\n",
        "        # # Compute meta-validation loss\n",
        "        # batch = tasksets.validation.sample()\n",
        "        \n",
        "        # learner = maml.clone()\n",
        "        # evaluation_error, evaluation_accuracy = fast_adapt(batch,learner,loss,adaptation_steps,shots,ways,\n",
        "        #                                                     device)\n",
        "        # meta_valid_error += evaluation_error.item()\n",
        "        # meta_valid_accuracy += evaluation_accuracy.item()\n",
        "\n",
        "    # Print some metrics\n",
        "    print('\\n')\n",
        "    print('Iteration', iteration)\n",
        "    print('Meta Train Error', meta_train_error / meta_batch_size)\n",
        "    print('Meta Train Accuracy', meta_train_accuracy / meta_batch_size)\n",
        "    # print('Meta Valid Error', meta_valid_error / meta_batch_size)\n",
        "    # print('Meta Valid Accuracy', meta_valid_accuracy / meta_batch_size)\n",
        "\n",
        "    # Average the accumulated gradients and optimize\n",
        "    for p in maml.parameters():\n",
        "        p.grad.data.mul_(1.0 / meta_batch_size)\n",
        "    opt.step()\n",
        "\n",
        "\n",
        "acc_acuracy=[]\n",
        "iterations= 600\n",
        "for _ in range(iterations):\n",
        "  meta_test_error = 0.0\n",
        "  meta_test_accuracy = 0.0\n",
        "\n",
        "  for task in range(meta_batch_size):\n",
        "\n",
        "      # Compute meta-testing loss\n",
        "      learner = maml.clone()\n",
        "      batch = tasksets.test.sample()\n",
        "      evaluation_error, evaluation_accuracy = fast_adapt(batch,\n",
        "                                                          learner,\n",
        "                                                          loss,\n",
        "                                                          3,\n",
        "                                                          shots,\n",
        "                                                          ways,\n",
        "                                                          device)\n",
        "      meta_test_error += evaluation_error.item()\n",
        "      meta_test_accuracy += evaluation_accuracy.item()\n",
        "\n",
        "  # print('Meta Test Error', meta_test_error / meta_batch_size)\n",
        "  # print('Meta Test Accuracy', meta_test_accuracy / meta_batch_size)\n",
        "  acc_acuracy.append(meta_test_accuracy/meta_batch_size)\n",
        "\n",
        "\n",
        "acc_acuracy = np.array(acc_acuracy)\n",
        "means = np.mean(acc_acuracy, 0)\n",
        "stds = np.std(acc_acuracy, 0)\n",
        "ci95 = 1.96*stds/np.sqrt(iterations)\n",
        "\n",
        "print('Mean accuracy/loss, stddev, and confidence intervals')\n",
        "print((means, stds, ci95))\n",
        "\n",
        "print(acc_acuracy[acc_acuracy.argmin()])\n",
        "print(acc_acuracy[acc_acuracy.argmax()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:281: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "166it [00:26,  6.18it/s, epoch_progress=100%, train_loss=-1.778e+05, last_val_loss=+1.554e+22, best_epoch=66, best_loss=+8.660e+21]\n",
            "142it [00:22,  6.23it/s, epoch_progress=100%, train_loss=-2.013e+05, last_val_loss=+6.145e+21, best_epoch=42, best_loss=+4.804e+21]\n",
            "115it [00:18,  6.23it/s, epoch_progress=100%, train_loss=-2.254e+05, last_val_loss=+5.582e+21, best_epoch=15, best_loss=+3.139e+21]\n",
            "155it [00:25,  6.19it/s, epoch_progress=100%, train_loss=-1.752e+05, last_val_loss=+2.089e+22, best_epoch=55, best_loss=+6.566e+21]\n",
            "122it [00:19,  6.25it/s, epoch_progress=100%, train_loss=-1.914e+05, last_val_loss=+1.621e+22, best_epoch=22, best_loss=+5.538e+21]\n",
            "118it [00:19,  6.09it/s, epoch_progress=100%, train_loss=-1.979e+05, last_val_loss=+2.142e+22, best_epoch=18, best_loss=+5.643e+21]\n",
            "118it [00:19,  6.04it/s, epoch_progress=100%, train_loss=-2.315e+05, last_val_loss=+1.948e+22, best_epoch=18, best_loss=+2.097e+21]\n",
            "124it [00:20,  6.09it/s, epoch_progress=100%, train_loss=-2.474e+05, last_val_loss=+1.383e+22, best_epoch=24, best_loss=+4.576e+21]\n",
            " 33%|███▎      | 1/3 [02:53<05:47, 173.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 0\n",
            "Meta Train Error 1.9839521050453186\n",
            "Meta Train Accuracy 0.17812499962747097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "124it [00:19,  6.22it/s, epoch_progress=100%, train_loss=-1.551e+05, last_val_loss=+1.056e+22, best_epoch=24, best_loss=+5.629e+21]\n",
            "123it [00:19,  6.18it/s, epoch_progress=100%, train_loss=-2.089e+05, last_val_loss=+1.023e+22, best_epoch=23, best_loss=+4.600e+21]\n",
            "117it [00:18,  6.19it/s, epoch_progress=100%, train_loss=-1.967e+05, last_val_loss=+1.689e+22, best_epoch=17, best_loss=+3.069e+21]\n",
            "115it [00:18,  6.31it/s, epoch_progress=100%, train_loss=-2.152e+05, last_val_loss=+2.794e+22, best_epoch=15, best_loss=+7.502e+21]\n",
            "152it [00:24,  6.21it/s, epoch_progress=100%, train_loss=-2.080e+05, last_val_loss=+2.277e+22, best_epoch=52, best_loss=+9.384e+21]\n",
            "137it [00:21,  6.25it/s, epoch_progress=100%, train_loss=-2.103e+05, last_val_loss=+2.813e+22, best_epoch=37, best_loss=+5.945e+21]\n",
            "117it [00:19,  6.15it/s, epoch_progress=100%, train_loss=-2.113e+05, last_val_loss=+1.182e+22, best_epoch=17, best_loss=+3.789e+21]\n",
            "114it [00:18,  6.19it/s, epoch_progress=100%, train_loss=-2.289e+05, last_val_loss=+2.773e+22, best_epoch=14, best_loss=+2.334e+21]\n",
            " 67%|██████▋   | 2/3 [05:36<02:47, 167.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 1\n",
            "Meta Train Error 1.764745444059372\n",
            "Meta Train Accuracy 0.17500000353902578\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "114it [00:18,  6.27it/s, epoch_progress=100%, train_loss=-2.096e+05, last_val_loss=+1.178e+22, best_epoch=14, best_loss=+2.064e+21]\n",
            "124it [00:20,  6.16it/s, epoch_progress=100%, train_loss=-2.271e+05, last_val_loss=+1.216e+22, best_epoch=24, best_loss=+3.808e+21]\n",
            "150it [00:23,  6.27it/s, epoch_progress=100%, train_loss=-2.162e+05, last_val_loss=+2.012e+22, best_epoch=50, best_loss=+2.666e+21]\n",
            "118it [00:19,  6.14it/s, epoch_progress=100%, train_loss=-1.743e+05, last_val_loss=+1.198e+22, best_epoch=18, best_loss=+5.975e+21]\n",
            "114it [00:18,  6.25it/s, epoch_progress=100%, train_loss=-2.056e+05, last_val_loss=+3.300e+22, best_epoch=14, best_loss=+1.244e+21]\n",
            "121it [00:19,  6.10it/s, epoch_progress=100%, train_loss=-1.974e+05, last_val_loss=+1.688e+22, best_epoch=21, best_loss=+6.867e+21]\n",
            "116it [00:19,  6.11it/s, epoch_progress=100%, train_loss=-1.963e+05, last_val_loss=+8.433e+23, best_epoch=16, best_loss=+5.754e+21]\n",
            "133it [00:21,  6.06it/s, epoch_progress=100%, train_loss=-2.053e+05, last_val_loss=+1.623e+22, best_epoch=33, best_loss=+6.564e+21]\n",
            "100%|██████████| 3/3 [08:19<00:00, 166.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 2\n",
            "Meta Train Error 1.6917263120412827\n",
            "Meta Train Accuracy 0.1906250063329935\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean accuracy/loss, stddev, and confidence intervals\n",
            "(0.6055000121239573, 0.08472357040113233, 0.006779297544538376)\n",
            "0.3500000052154064\n",
            "0.8500000089406967\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzv5X_llXxMW"
      },
      "source": [
        "**SUMMARY OF EXP4**\n",
        "----\n",
        "\n",
        "higher meta learning rate 0.013  and 3 iterations \n",
        "\n",
        "* **Standard MAML** \n",
        "\n",
        "  *  Mean accuracy/loss, stddev, and confidence intervals\n",
        "  * (0.5756250124828269, 0.08111607608978898, 0.006490637880987425)\n",
        "\n",
        "-----\n",
        "\n",
        "* **with the following flows**\n",
        "\n",
        "  * Mean accuracy/loss, stddev, and confidence intervals\n",
        "  * (0.5979166786403706, 0.08530480494926775, 0.006825805994622801)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yp4c3hdv3W11",
        "cellView": "form",
        "outputId": "1cea2d00-4ed6-4898-bf6c-fa4bee04cac7"
      },
      "source": [
        "#@title COMPARE WITH EXP4 Standart MAML with meta lr 0.013 on 3 iterations \n",
        "\n",
        "#@markdown Mean accuracy/loss, stddev, and confidence intervals\n",
        "\n",
        "#@markdown (0.5756250124828269, 0.08111607608978898, 0.006490637880987425)\n",
        "\n",
        "#@markdown min accuracy: 0.3000000100582838\n",
        "\n",
        "#@markdown max accuracy: 0.7750000134110451\n",
        "\n",
        "\"\"\"\n",
        "  Demonstrates how to:\n",
        "    * use the MAML wrapper for fast-adaptation,\n",
        "    * use the benchmark interface to load Omniglot, and\n",
        "    * sample tasks and split them in adaptation and evaluation sets.\n",
        "\"\"\"\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import learn2learn as l2l\n",
        "\n",
        "from torch import nn, optim\n",
        "\n",
        "\n",
        "\n",
        "def accuracy(predictions, targets):\n",
        "    predictions = predictions.argmax(dim=1).view(targets.shape)\n",
        "    return (predictions == targets).sum().float() / targets.size(0)\n",
        "\n",
        "\n",
        "def fast_adapt(batch, learner, loss, adaptation_steps, shots, ways, device):\n",
        "    data, labels = batch\n",
        "    data, labels = data.to(device), labels.to(device)\n",
        "\n",
        "    # Separate data into adaptation/evalutation sets\n",
        "    adaptation_indices = np.zeros(data.size(0), dtype=bool)\n",
        "    adaptation_indices[np.arange(shots*ways) * 2] = True\n",
        "    evaluation_indices = torch.from_numpy(~adaptation_indices)\n",
        "    adaptation_indices = torch.from_numpy(adaptation_indices)\n",
        "    adaptation_data, adaptation_labels = data[adaptation_indices], labels[adaptation_indices]\n",
        "    evaluation_data, evaluation_labels = data[evaluation_indices], labels[evaluation_indices]\n",
        "\n",
        "    # Adapt the model\n",
        "    for step in range(adaptation_steps):\n",
        "        train_error = loss(learner(adaptation_data), adaptation_labels)\n",
        "        learner.adapt(train_error)\n",
        "\n",
        "    # Evaluate the adapted model\n",
        "    predictions = learner(evaluation_data)\n",
        "    valid_error = loss(predictions, evaluation_labels)\n",
        "    valid_accuracy = accuracy(predictions, evaluation_labels)\n",
        "    return valid_error, valid_accuracy\n",
        "\n",
        "\n",
        "ways=5\n",
        "shots=1\n",
        "meta_lr=0.013\n",
        "fast_lr=0.5\n",
        "meta_batch_size=8\n",
        "adaptation_steps=1\n",
        "num_iterations=3\n",
        "cuda=True\n",
        "# seed=42,\n",
        "\n",
        "# random.seed(seed)\n",
        "# np.random.seed(seed)\n",
        "# torch.manual_seed(seed)\n",
        "device = torch.device('cpu')\n",
        "if cuda:\n",
        "    # torch.cuda.manual_seed(seed)\n",
        "    device = torch.device('cuda')\n",
        "\n",
        "# Load train/validation/test tasksets using the benchmark interface\n",
        "tasksets = l2l.vision.benchmarks.get_tasksets('omniglot',\n",
        "                                              train_ways=ways,\n",
        "                                              train_samples=2*shots,\n",
        "                                              test_ways=ways,\n",
        "                                              test_samples=2*shots,\n",
        "                                              num_tasks=20000,\n",
        "                                              root='~/data',\n",
        ")\n",
        "\n",
        "# Create model\n",
        "model =  l2l.vision.models.OmniglotCNN(ways)\n",
        "#model =  l2l.vision.models.OmniglotFC(28 ** 2, ways)\n",
        "model.to(device)\n",
        "maml = l2l.algorithms.MAML(model, lr=fast_lr, first_order=False)\n",
        "opt = optim.Adam(maml.parameters(), meta_lr)\n",
        "loss = nn.CrossEntropyLoss(reduction='mean')\n",
        "\n",
        "for iteration in range(num_iterations):\n",
        "    opt.zero_grad()\n",
        "    meta_train_error = 0.0\n",
        "    meta_train_accuracy = 0.0\n",
        "    meta_valid_error = 0.0\n",
        "    meta_valid_accuracy = 0.0\n",
        "    for task in range(meta_batch_size):\n",
        "        # Compute meta-training loss\n",
        "        learner = maml.clone()\n",
        "        batch = tasksets.train.sample()\n",
        "        evaluation_error, evaluation_accuracy = fast_adapt(batch,\n",
        "                                                            learner,\n",
        "                                                            loss,\n",
        "                                                            adaptation_steps,\n",
        "                                                            shots,\n",
        "                                                            ways,\n",
        "                                                            device)\n",
        "        evaluation_error.backward()\n",
        "        meta_train_error += evaluation_error.item()\n",
        "        meta_train_accuracy += evaluation_accuracy.item()\n",
        "\n",
        "        # Compute meta-validation loss\n",
        "        # learner = maml.clone()\n",
        "        # batch = tasksets.validation.sample()\n",
        "        # evaluation_error, evaluation_accuracy = fast_adapt(batch,\n",
        "        #                                                     learner,\n",
        "        #                                                     loss,\n",
        "        #                                                     adaptation_steps,\n",
        "        #                                                     shots,\n",
        "        #                                                     ways,\n",
        "        #                                                     device)\n",
        "        # meta_valid_error += evaluation_error.item()\n",
        "        # meta_valid_accuracy += evaluation_accuracy.item()\n",
        "\n",
        "    # Print some metrics\n",
        "    print('\\n')\n",
        "    print('Iteration', iteration)\n",
        "    print('Meta Train Error', meta_train_error / meta_batch_size)\n",
        "    print('Meta Train Accuracy', meta_train_accuracy / meta_batch_size)\n",
        "    # print('Meta Valid Error', meta_valid_error / meta_batch_size)\n",
        "    # print('Meta Valid Accuracy', meta_valid_accuracy / meta_batch_size)\n",
        "\n",
        "    # Average the accumulated gradients and optimize\n",
        "    for p in maml.parameters():\n",
        "        p.grad.data.mul_(1.0 / meta_batch_size)\n",
        "    opt.step()\n",
        "\n",
        "\n",
        "\n",
        "acc_acuracy=[]\n",
        "iterations=600\n",
        "\n",
        "for _ in range(iterations):\n",
        "  meta_test_error = 0.0\n",
        "  meta_test_accuracy = 0.0\n",
        "\n",
        "  for task in range(meta_batch_size):\n",
        "\n",
        "      # Compute meta-testing loss\n",
        "      learner = maml.clone()\n",
        "      batch = tasksets.test.sample()\n",
        "      evaluation_error, evaluation_accuracy = fast_adapt(batch,\n",
        "                                                          learner,\n",
        "                                                          loss,\n",
        "                                                          3,\n",
        "                                                          shots,\n",
        "                                                          ways,\n",
        "                                                          device)\n",
        "      meta_test_error += evaluation_error.item()\n",
        "      meta_test_accuracy += evaluation_accuracy.item()\n",
        "\n",
        "  # print('Meta Test Error', meta_test_error / meta_batch_size)\n",
        "  # print('Meta Test Accuracy', meta_test_accuracy / meta_batch_size)\n",
        "  acc_acuracy.append(meta_test_accuracy/meta_batch_size)\n",
        "\n",
        "\n",
        "acc_acuracy = np.array(acc_acuracy)\n",
        "means = np.mean(acc_acuracy, 0)\n",
        "stds = np.std(acc_acuracy, 0)\n",
        "ci95 = 1.96*stds/np.sqrt(iterations)\n",
        "\n",
        "print('Mean accuracy/loss, stddev, and confidence intervals')\n",
        "print((means, stds, ci95))\n",
        "\n",
        "print(acc_acuracy[acc_acuracy.argmin()])\n",
        "print(acc_acuracy[acc_acuracy.argmax()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:281: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "\n",
            "\n",
            "Iteration 0\n",
            "Meta Train Error 1.9204799234867096\n",
            "Meta Train Accuracy 0.3000000063329935\n",
            "\n",
            "\n",
            "Iteration 1\n",
            "Meta Train Error 1.7800371944904327\n",
            "Meta Train Accuracy 0.42500001192092896\n",
            "\n",
            "\n",
            "Iteration 2\n",
            "Meta Train Error 1.650674894452095\n",
            "Meta Train Accuracy 0.4250000100582838\n",
            "Mean accuracy/loss, stddev, and confidence intervals\n",
            "(0.5756250124828269, 0.08111607608978898, 0.006490637880987425)\n",
            "0.3000000100582838\n",
            "0.7750000134110451\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7RyFMQfHiWe",
        "cellView": "form",
        "outputId": "75f99b14-1bfd-496e-b464-20d14f85d01c"
      },
      "source": [
        "#@title EXP4 with normalizing flow and higer meta_lr 0.013 on 3 on 3 iterations\n",
        "\n",
        "#@markdown 400 generated images instead of 1 shot per class \n",
        "\n",
        "#@markdown Foud that adding more layers of folws specifically batch normalization flow layer achives higher accuracy \n",
        "\n",
        "#@markdown Flow details:\n",
        "\n",
        "#@markdown    BatchNorm(dim=dim),ActNorm(dim=dim).warm_start(x=trainX),BatchNorm(dim=dim),ActNorm(dim=dim).warm_start(x=trainX),\n",
        "\n",
        "#@markdown    BatchNorm(dim=dim), 6 times \n",
        "\n",
        "#@markdown    Affine(dim=dim),Affine(dim=dim),\n",
        "\n",
        "\n",
        "#@markdown BatchNorm(dim=dim), 25 times \n",
        "\n",
        "#@markdown -----\n",
        "\n",
        "#@markdown Mean accuracy/loss, stddev, and confidence intervals\n",
        "\n",
        "#@markdown (0.5979166786403706, 0.08530480494926775, 0.006825805994622801)\n",
        "\n",
        "#@markdown min accuracy: 0.3500000089406967\n",
        "\n",
        "#@markdown max accuracy: 0.8500000089406967 \n",
        "\n",
        "def accuracy(predictions, targets):\n",
        "    predictions = predictions.argmax(dim=1).view(targets.shape)\n",
        "    return (predictions == targets).sum().float() / targets.size(0)\n",
        "\n",
        "\n",
        "def fast_adapt(batch, learner, loss, adaptation_steps, shots, ways, device):\n",
        "    data, labels = batch\n",
        "    # print(\"data:  \",data.shape)\n",
        "    data, labels = data.to(device), labels.to(device, dtype=torch.int64)\n",
        "    # Separate data into adaptation/evalutation sets\n",
        "    adaptation_indices = np.zeros(data.size(0), dtype=bool)\n",
        "    adaptation_indices[np.arange(shots*ways) * 2] = True\n",
        "    evaluation_indices = torch.from_numpy(~adaptation_indices)\n",
        "    adaptation_indices = torch.from_numpy(adaptation_indices)\n",
        "    adaptation_data, adaptation_labels = data[adaptation_indices], labels[adaptation_indices]\n",
        "    evaluation_data, evaluation_labels = data[evaluation_indices], labels[evaluation_indices]\n",
        "\n",
        "    # Adapt the model\n",
        "    for step in range(adaptation_steps):\n",
        "        train_error = loss(learner(adaptation_data), adaptation_labels)\n",
        "        learner.adapt(train_error)\n",
        "\n",
        "\n",
        "    # Evaluate the adapted model\n",
        "    predictions = learner(evaluation_data)\n",
        "    valid_error = loss(predictions, evaluation_labels)\n",
        "    valid_accuracy = accuracy(predictions, evaluation_labels)\n",
        "    return valid_error, valid_accuracy\n",
        "\n",
        "\n",
        "def fast_adapt_train(batch, learner, loss, adaptation_steps, shots, ways, device):\n",
        "\n",
        "    data, labels = batch\n",
        "    data, labels = data.to(device), labels.to(device, dtype=torch.int64)\n",
        "    # Separate data into adaptation/evalutation sets\n",
        "    indices = np.random.permutation(data.shape[0])\n",
        "    \n",
        "    adaptation_indices = indices[:360]\n",
        "    evaluation_indices = indices[360:]\n",
        "    adaptation_data, adaptation_labels = data[adaptation_indices], labels[adaptation_indices]\n",
        "    evaluation_data, evaluation_labels = data[evaluation_indices], labels[evaluation_indices]\n",
        "    # print(adaptation_data.shape)\n",
        "    # print(\"modified version\")\n",
        "    # Adapt the model\n",
        "    for step in range(adaptation_steps):\n",
        "        train_error = loss(learner(adaptation_data), adaptation_labels)\n",
        "        learner.adapt(train_error)\n",
        "\n",
        "\n",
        "    # Evaluate the adapted model\n",
        "    predictions = learner(evaluation_data)\n",
        "    valid_error = loss(predictions, evaluation_labels)\n",
        "    valid_accuracy = accuracy(predictions, evaluation_labels)\n",
        "    return valid_error, valid_accuracy\n",
        "\n",
        "def train_flow (trainX ,cond_train , device):\n",
        "\n",
        "  \n",
        "  # trainX has a shape of (count , channel , pixles,pixles)\n",
        "  \n",
        "\n",
        "  trainX = torch.flatten(trainX,1,-1)\n",
        "  # valX = torch.flatten(valX , 1,-1)\n",
        "  dim=trainX.shape[1]\n",
        "  \n",
        "  # print(cond_train)\n",
        "  cond_train = torch.nn.functional.one_hot(cond_train)\n",
        "  # cond_val   = torch.nn.functional.one_hot(cond_val) \n",
        "  # print(cond_train)\n",
        "  cond_dim = cond_train.size(1)\n",
        "  \n",
        "  flow = Sequential(      \n",
        "\n",
        "      # MADE(AffineTransformer(dim=dim) , cond_dim=cond_dim),\n",
        "      # MADE(AffineTransformer(dim=dim) , cond_dim=cond_dim),\n",
        "\n",
        "  # very slow in sampling \n",
        "    # inv_flow(Sigmoid)(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    ActNorm(dim=dim).warm_start(x=trainX),\n",
        "    BatchNorm(dim=dim),\n",
        "    ActNorm(dim=dim).warm_start(x=trainX),\n",
        "    # BatchNorm(dim=dim),\n",
        "    # ActNorm(dim=dim).warm_start(x=trainX),\n",
        "# //////////////////\n",
        "    #     BatchNorm(dim=dim),\n",
        "    # ActNorm(dim=dim).warm_start(x=trainX),\n",
        "    # BatchNorm(dim=dim),\n",
        "    # ActNorm(dim=dim).warm_start(x=trainX),\n",
        "    # BatchNorm(dim=dim),\n",
        "    # ActNorm(dim=dim).warm_start(x=trainX),\n",
        "    # BatchNorm(dim=dim),\n",
        "    # ActNorm(dim=dim).warm_start(x=trainX),\n",
        "    # BatchNorm(dim=dim),\n",
        "    # ActNorm(dim=dim).warm_start(x=trainX),\n",
        "# ////////\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    # MADE(DSF(dim=dim), cond_dim=cond_dim),\n",
        "    Affine(dim=dim),  \n",
        "    Affine(dim=dim),  \n",
        "BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "\n",
        "      # BatchNorm(dim=dim),\n",
        "      # Shuffle(dim=dim),\n",
        "      # CouplingLayers(AffineTransformer(dim=dim//2 ) ,dim=dim),\n",
        "\n",
        "  ).to(device)\n",
        "  train_losses, val_losses = train(flow, trainX, trainX ,cond_train=cond_train, cond_val=cond_train , patience=100 ,batch_size=8,n_epochs=1000)\n",
        " \n",
        "  test_labels = np.random.choice(5, size=(400))\n",
        "  test_labels = torch.from_numpy(test_labels)\n",
        "  test_cond = torch.nn.functional.one_hot(test_labels)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    train_data = flow.sample(400,cond=test_cond.to(device)).cpu()\n",
        "\n",
        "  # return train_data, train_losses , val_losses , mean , var\n",
        "  return torch.reshape(train_data , (400,1,28,28)) , test_labels\n",
        "\n",
        "\n",
        "\n",
        "ways=5\n",
        "shots=1\n",
        "meta_lr=0.013\n",
        "fast_lr=0.5\n",
        "meta_batch_size=8\n",
        "adaptation_steps=1\n",
        "num_iterations=3\n",
        "cuda=True\n",
        "# seed=42\n",
        "# Load train/validation/test tasksets using the benchmark interface\n",
        "tasksets = l2l.vision.benchmarks.get_tasksets('omniglot',\n",
        "                                                  train_ways=ways,\n",
        "                                                  train_samples=2*shots,\n",
        "                                                  test_ways=ways,\n",
        "                                                  test_samples=2*shots,\n",
        "                                                  num_tasks=20000,\n",
        "                                                  root='~/data',\n",
        "    )\n",
        "\n",
        "# dim = 28*28\n",
        "\n",
        "device = torch.device('cpu')\n",
        "if cuda:\n",
        "  # torch.cuda.manual_seed(seed)\n",
        "  device = torch.device('cuda')\n",
        "\n",
        "# Create model\n",
        "model = l2l.vision.models.OmniglotCNN(ways)\n",
        "# model = l2l.vision.models.OmniglotFC(28 ** 2, ways)\n",
        "model.to(device)\n",
        "maml = l2l.algorithms.MAML(model, lr=fast_lr, first_order=False)\n",
        "opt = optim.Adam(maml.parameters(), meta_lr)\n",
        "loss = nn.CrossEntropyLoss(reduction='mean')\n",
        "\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "for iteration in tqdm(range(num_iterations)):\n",
        "    opt.zero_grad()\n",
        "    meta_train_error = 0.0\n",
        "    meta_train_accuracy = 0.0\n",
        "    meta_valid_error = 0.0\n",
        "    meta_valid_accuracy = 0.0\n",
        "\n",
        "    for task in range(meta_batch_size):\n",
        "        # Compute meta-training loss\n",
        "        # learner = maml.clone()\n",
        "\n",
        "        # generate batch the batch contains # ways*shots , channels , img size  and labels \n",
        "        train_batch = tasksets.train.sample()\n",
        "        val_batch = tasksets.validation.sample()\n",
        "\n",
        "        # split batch based on classes in labels then   labels.split(int(data.shape[0]/ways))\n",
        "        train_data, train_labels = train_batch\n",
        "        val_data , val_labels= val_batch\n",
        "\n",
        "        \n",
        "        train_data_generator ,train_lable_generator  = train_flow (train_data ,train_labels  , device)\n",
        "\n",
        "        # train_data_generator = torch.cat(train_data_generator)\n",
        "        # train_lable_generator = torch.cat(train_lable_generator)\n",
        "        \n",
        "        batch = [train_data_generator ,train_lable_generator]\n",
        "\n",
        "        learner = maml.clone()            \n",
        "        \n",
        "        evaluation_error, evaluation_accuracy = fast_adapt_train(batch,\n",
        "                                                            learner,\n",
        "                                                            loss,\n",
        "                                                            adaptation_steps,\n",
        "                                                            shots,\n",
        "                                                            ways,\n",
        "                                                            device)\n",
        "        evaluation_error.backward()\n",
        "        meta_train_error += evaluation_error.item()\n",
        "        meta_train_accuracy += evaluation_accuracy.item()\n",
        "\n",
        "# ''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
        "\n",
        "        # # Compute meta-validation loss\n",
        "        # batch = tasksets.validation.sample()\n",
        "        \n",
        "        # learner = maml.clone()\n",
        "        # evaluation_error, evaluation_accuracy = fast_adapt(batch,learner,loss,adaptation_steps,shots,ways,\n",
        "        #                                                     device)\n",
        "        # meta_valid_error += evaluation_error.item()\n",
        "        # meta_valid_accuracy += evaluation_accuracy.item()\n",
        "\n",
        "    # Print some metrics\n",
        "    print('\\n')\n",
        "    print('Iteration', iteration)\n",
        "    print('Meta Train Error', meta_train_error / meta_batch_size)\n",
        "    print('Meta Train Accuracy', meta_train_accuracy / meta_batch_size)\n",
        "    # print('Meta Valid Error', meta_valid_error / meta_batch_size)\n",
        "    # print('Meta Valid Accuracy', meta_valid_accuracy / meta_batch_size)\n",
        "\n",
        "    # Average the accumulated gradients and optimize\n",
        "    for p in maml.parameters():\n",
        "        p.grad.data.mul_(1.0 / meta_batch_size)\n",
        "    opt.step()\n",
        "/\n",
        "\n",
        "acc_acuracy=[]\n",
        "iterations= 600\n",
        "for _ in range(iterations):\n",
        "  meta_test_error = 0.0\n",
        "  meta_test_accuracy = 0.0\n",
        "\n",
        "  for task in range(meta_batch_size):\n",
        "\n",
        "      # Compute meta-testing loss\n",
        "      learner = maml.clone()\n",
        "      batch = tasksets.test.sample()\n",
        "      evaluation_error, evaluation_accuracy = fast_adapt(batch,\n",
        "                                                          learner,\n",
        "                                                          loss,\n",
        "                                                          3,\n",
        "                                                          shots,\n",
        "                                                          ways,\n",
        "                                                          device)\n",
        "      meta_test_error += evaluation_error.item()\n",
        "      meta_test_accuracy += evaluation_accuracy.item()\n",
        "\n",
        "  # print('Meta Test Error', meta_test_error / meta_batch_size)\n",
        "  # print('Meta Test Accuracy', meta_test_accuracy / meta_batch_size)\n",
        "  acc_acuracy.append(meta_test_accuracy/meta_batch_size)\n",
        "\n",
        "\n",
        "acc_acuracy = np.array(acc_acuracy)\n",
        "means = np.mean(acc_acuracy, 0)\n",
        "stds = np.std(acc_acuracy, 0)\n",
        "ci95 = 1.96*stds/np.sqrt(iterations)\n",
        "\n",
        "print('Mean accuracy/loss, stddev, and confidence intervals')\n",
        "print((means, stds, ci95))\n",
        "\n",
        "print(acc_acuracy[acc_acuracy.argmin()])\n",
        "print(acc_acuracy[acc_acuracy.argmax()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:281: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "141it [00:21,  6.71it/s, epoch_progress=100%, train_loss=-2.216e+05, last_val_loss=+2.024e+22, best_epoch=41, best_loss=+8.101e+21]\n",
            "116it [00:17,  6.72it/s, epoch_progress=100%, train_loss=-2.301e+05, last_val_loss=+1.284e+22, best_epoch=16, best_loss=+1.524e+21]\n",
            "126it [00:18,  6.65it/s, epoch_progress=100%, train_loss=-1.963e+05, last_val_loss=+2.425e+22, best_epoch=26, best_loss=+2.654e+21]\n",
            "126it [00:18,  6.82it/s, epoch_progress=100%, train_loss=-1.966e+05, last_val_loss=+6.942e+21, best_epoch=26, best_loss=+4.960e+21]\n",
            "134it [00:19,  6.71it/s, epoch_progress=100%, train_loss=-2.058e+05, last_val_loss=+1.807e+22, best_epoch=34, best_loss=+4.316e+21]\n",
            "149it [00:21,  6.80it/s, epoch_progress=100%, train_loss=-2.392e+05, last_val_loss=+1.905e+22, best_epoch=49, best_loss=+5.043e+21]\n",
            "213it [00:31,  6.74it/s, epoch_progress=100%, train_loss=-2.645e+05, last_val_loss=+1.273e+22, best_epoch=113, best_loss=+4.650e+21]\n",
            "166it [00:24,  6.66it/s, epoch_progress=100%, train_loss=-1.780e+05, last_val_loss=+2.423e+22, best_epoch=66, best_loss=+6.125e+21]\n",
            " 33%|███▎      | 1/3 [02:56<05:52, 176.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 0\n",
            "Meta Train Error 2.7952945232391357\n",
            "Meta Train Accuracy 0.1843750039115548\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "120it [00:17,  6.73it/s, epoch_progress=100%, train_loss=-2.028e+05, last_val_loss=+9.757e+21, best_epoch=20, best_loss=+1.833e+21]\n",
            "128it [00:19,  6.71it/s, epoch_progress=100%, train_loss=-2.087e+05, last_val_loss=+8.668e+21, best_epoch=28, best_loss=+4.499e+21]\n",
            "132it [00:19,  6.70it/s, epoch_progress=100%, train_loss=-1.931e+05, last_val_loss=+2.087e+22, best_epoch=32, best_loss=+8.881e+21]\n",
            "166it [00:24,  6.67it/s, epoch_progress=100%, train_loss=-2.276e+05, last_val_loss=+1.318e+22, best_epoch=66, best_loss=+3.994e+21]\n",
            "101it [00:14,  6.83it/s, epoch_progress=100%, train_loss=-1.910e+05, last_val_loss=+1.430e+22, best_epoch=1, best_loss=+2.108e+04]\n",
            "126it [00:18,  6.73it/s, epoch_progress=100%, train_loss=-2.009e+05, last_val_loss=+1.346e+22, best_epoch=26, best_loss=+7.908e+21]\n",
            "164it [00:24,  6.74it/s, epoch_progress=100%, train_loss=-2.088e+05, last_val_loss=+1.310e+22, best_epoch=64, best_loss=+6.454e+21]\n",
            "116it [00:17,  6.60it/s, epoch_progress=100%, train_loss=-2.431e+05, last_val_loss=+1.681e+22, best_epoch=16, best_loss=+3.964e+21]\n",
            " 67%|██████▋   | 2/3 [05:34<02:45, 165.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 1\n",
            "Meta Train Error 2.34393247961998\n",
            "Meta Train Accuracy 0.18437500344589353\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "119it [00:17,  6.64it/s, epoch_progress=100%, train_loss=-2.159e+05, last_val_loss=+1.051e+22, best_epoch=19, best_loss=+2.940e+21]\n",
            "122it [00:18,  6.65it/s, epoch_progress=100%, train_loss=-2.094e+05, last_val_loss=+1.142e+22, best_epoch=22, best_loss=+6.362e+21]\n",
            "183it [00:27,  6.73it/s, epoch_progress=100%, train_loss=-2.089e+05, last_val_loss=+1.141e+22, best_epoch=83, best_loss=+6.276e+21]\n",
            "115it [00:16,  6.77it/s, epoch_progress=100%, train_loss=-1.908e+05, last_val_loss=+1.344e+22, best_epoch=15, best_loss=+4.190e+21]\n",
            "139it [00:20,  6.63it/s, epoch_progress=100%, train_loss=-2.279e+05, last_val_loss=+3.192e+22, best_epoch=39, best_loss=+4.113e+21]\n",
            "118it [00:17,  6.74it/s, epoch_progress=100%, train_loss=-2.240e+05, last_val_loss=+1.913e+22, best_epoch=18, best_loss=+5.594e+21]\n",
            "147it [00:22,  6.64it/s, epoch_progress=100%, train_loss=-2.004e+05, last_val_loss=+1.702e+22, best_epoch=47, best_loss=+5.641e+21]\n",
            "172it [00:25,  6.70it/s, epoch_progress=100%, train_loss=-1.911e+05, last_val_loss=+1.253e+22, best_epoch=72, best_loss=+6.896e+21]\n",
            "100%|██████████| 3/3 [08:23<00:00, 167.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 2\n",
            "Meta Train Error 2.3716704547405243\n",
            "Meta Train Accuracy 0.22812500828877091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean accuracy/loss, stddev, and confidence intervals\n",
            "(0.5979166786403706, 0.08530480494926775, 0.006825805994622801)\n",
            "0.3500000089406967\n",
            "0.8500000089406967\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLVETKc0Srl-"
      },
      "source": [
        "**Summary of EXP3**\n",
        "---\n",
        "Foud that adding more layers of folws specifically batch normalization flow layer achives higher accuracy\n",
        "\n",
        "* **Standard MAML**\n",
        "  * not tested \n",
        "----\n",
        "* **with following flow**\n",
        "  * Mean accuracy/loss, stddev, and confidence intervals\n",
        "  * (0.6064166788539539, 0.07988581283694113, 0.006392196318507478)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSWXidvkZGFr",
        "cellView": "form",
        "outputId": "507d62af-c12a-44f8-9aff-fc9407262e3d"
      },
      "source": [
        "#@title EXP3 400 generated images instead of 1 shot per class and 15 iterations\n",
        "\n",
        "#@markdown Foud that adding more layers of folws specifically batch normalization flow layer achives higher accuracy \n",
        "\n",
        "#@markdown Flow details: \n",
        "\n",
        "#@markdown BatchNorm(dim=dim),\n",
        "\n",
        "#@markdown ActNorm(dim=dim).warm_start(x=trainX),\n",
        "\n",
        "#@markdown    BatchNorm(dim=dim),\n",
        "\n",
        "#@markdown    ActNorm(dim=dim).warm_start(x=trainX),\n",
        "\n",
        "#@markdown    BatchNorm(dim=dim),\n",
        "\n",
        "#@markdown    ActNorm(dim=dim).warm_start(x=trainX),\n",
        "\n",
        "#@markdown    BatchNorm(dim=dim),\n",
        "\n",
        "#@markdown    BatchNorm(dim=dim),\n",
        "\n",
        "#@markdown    BatchNorm(dim=dim),\n",
        "\n",
        "#@markdown    BatchNorm(dim=dim),\n",
        "\n",
        "#@markdown   BatchNorm(dim=dim),\n",
        "\n",
        "#@markdown    BatchNorm(dim=dim),\n",
        "\n",
        "#@markdown -----\n",
        "\n",
        "#@markdown Mean accuracy/loss, stddev, and confidence intervals\n",
        "\n",
        "#@markdown (0.6064166788539539, 0.07988581283694113, 0.006392196318507478)\n",
        "\n",
        "#@markdown 0.35000001080334187\n",
        "\n",
        "#@markdown 0.8250000104308128\n",
        "\n",
        "\n",
        "def accuracy(predictions, targets):\n",
        "    predictions = predictions.argmax(dim=1).view(targets.shape)\n",
        "    return (predictions == targets).sum().float() / targets.size(0)\n",
        "\n",
        "\n",
        "def fast_adapt(batch, learner, loss, adaptation_steps, shots, ways, device):\n",
        "    data, labels = batch\n",
        "    # print(\"data:  \",data.shape)\n",
        "    data, labels = data.to(device), labels.to(device, dtype=torch.int64)\n",
        "    # Separate data into adaptation/evalutation sets\n",
        "    adaptation_indices = np.zeros(data.size(0), dtype=bool)\n",
        "    adaptation_indices[np.arange(shots*ways) * 2] = True\n",
        "    evaluation_indices = torch.from_numpy(~adaptation_indices)\n",
        "    adaptation_indices = torch.from_numpy(adaptation_indices)\n",
        "    adaptation_data, adaptation_labels = data[adaptation_indices], labels[adaptation_indices]\n",
        "    evaluation_data, evaluation_labels = data[evaluation_indices], labels[evaluation_indices]\n",
        "\n",
        "    # Adapt the model\n",
        "    for step in range(adaptation_steps):\n",
        "        train_error = loss(learner(adaptation_data), adaptation_labels)\n",
        "        learner.adapt(train_error)\n",
        "\n",
        "\n",
        "    # Evaluate the adapted model\n",
        "    predictions = learner(evaluation_data)\n",
        "    valid_error = loss(predictions, evaluation_labels)\n",
        "    valid_accuracy = accuracy(predictions, evaluation_labels)\n",
        "    return valid_error, valid_accuracy\n",
        "\n",
        "\n",
        "def fast_adapt_train(batch, learner, loss, adaptation_steps, shots, ways, device):\n",
        "\n",
        "    data, labels = batch\n",
        "    data, labels = data.to(device), labels.to(device, dtype=torch.int64)\n",
        "    # Separate data into adaptation/evalutation sets\n",
        "    indices = np.random.permutation(data.shape[0])\n",
        "    \n",
        "    adaptation_indices = indices[:360]\n",
        "    evaluation_indices = indices[360:]\n",
        "    adaptation_data, adaptation_labels = data[adaptation_indices], labels[adaptation_indices]\n",
        "    evaluation_data, evaluation_labels = data[evaluation_indices], labels[evaluation_indices]\n",
        "    # print(adaptation_data.shape)\n",
        "    # print(\"modified version\")\n",
        "    # Adapt the model\n",
        "    for step in range(adaptation_steps):\n",
        "        train_error = loss(learner(adaptation_data), adaptation_labels)\n",
        "        learner.adapt(train_error)\n",
        "\n",
        "\n",
        "    # Evaluate the adapted model\n",
        "    predictions = learner(evaluation_data)\n",
        "    valid_error = loss(predictions, evaluation_labels)\n",
        "    valid_accuracy = accuracy(predictions, evaluation_labels)\n",
        "    return valid_error, valid_accuracy\n",
        "\n",
        "def train_flow (trainX ,cond_train , device):\n",
        "\n",
        "  \n",
        "  # trainX has a shape of (count , channel , pixles,pixles)\n",
        "  \n",
        "\n",
        "  trainX = torch.flatten(trainX,1,-1)\n",
        "  # valX = torch.flatten(valX , 1,-1)\n",
        "  dim=trainX.shape[1]\n",
        "  \n",
        "  # print(cond_train)\n",
        "  cond_train = torch.nn.functional.one_hot(cond_train)\n",
        "  # cond_val   = torch.nn.functional.one_hot(cond_val) \n",
        "  # print(cond_train)\n",
        "  cond_dim = cond_train.size(1)\n",
        "  flow = Sequential(      \n",
        "\n",
        "  # very slow in sampling \n",
        "    # inv_flow(Sigmoid)(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    ActNorm(dim=dim).warm_start(x=trainX),\n",
        "    BatchNorm(dim=dim),\n",
        "    ActNorm(dim=dim).warm_start(x=trainX),\n",
        "    BatchNorm(dim=dim),\n",
        "    ActNorm(dim=dim).warm_start(x=trainX),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    # MADE(DSF(dim=dim), cond_dim=cond_dim),\n",
        "    # Affine(dim=dim),  \n",
        "\n",
        "      # MADE(AffineTransformer(dim=dim) , cond_dim=cond_dim),\n",
        "      # BatchNorm(dim=dim),\n",
        "      # Shuffle(dim=dim),\n",
        "      # CouplingLayers(AffineTransformer(dim=dim//2 ) ,dim=dim),\n",
        "\n",
        "  ).to(device)\n",
        "\n",
        "  train_losses, val_losses = train(flow, trainX, trainX ,cond_train=cond_train, cond_val=cond_train , patience=100 ,batch_size=8,n_epochs=1000)\n",
        " \n",
        "  test_labels = np.random.choice(5, size=(400))\n",
        "  test_labels = torch.from_numpy(test_labels)\n",
        "  test_cond = torch.nn.functional.one_hot(test_labels)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    train_data = flow.sample(400,cond=test_cond.to(device)).cpu()\n",
        "\n",
        "  # return train_data, train_losses , val_losses , mean , var\n",
        "  return torch.reshape(train_data , (400,1,28,28)) , test_labels\n",
        "\n",
        "\n",
        "\n",
        "ways=5\n",
        "shots=1\n",
        "meta_lr=0.003\n",
        "fast_lr=0.5\n",
        "meta_batch_size=8\n",
        "adaptation_steps=1\n",
        "num_iterations=15\n",
        "cuda=True\n",
        "# seed=42\n",
        "# Load train/validation/test tasksets using the benchmark interface\n",
        "tasksets = l2l.vision.benchmarks.get_tasksets('omniglot',\n",
        "                                                  train_ways=ways,\n",
        "                                                  train_samples=2*shots,\n",
        "                                                  test_ways=ways,\n",
        "                                                  test_samples=2*shots,\n",
        "                                                  num_tasks=20000,\n",
        "                                                  root='~/data',\n",
        "    )\n",
        "\n",
        "# dim = 28*28\n",
        "\n",
        "device = torch.device('cpu')\n",
        "if cuda:\n",
        "  # torch.cuda.manual_seed(seed)\n",
        "  device = torch.device('cuda')\n",
        "\n",
        "# Create model\n",
        "model = l2l.vision.models.OmniglotCNN(ways)\n",
        "# model = l2l.vision.models.OmniglotFC(28 ** 2, ways)\n",
        "model.to(device)\n",
        "maml = l2l.algorithms.MAML(model, lr=fast_lr, first_order=False)\n",
        "opt = optim.Adam(maml.parameters(), meta_lr)\n",
        "loss = nn.CrossEntropyLoss(reduction='mean')\n",
        "\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "for iteration in tqdm(range(num_iterations)):\n",
        "    opt.zero_grad()\n",
        "    meta_train_error = 0.0\n",
        "    meta_train_accuracy = 0.0\n",
        "    meta_valid_error = 0.0\n",
        "    meta_valid_accuracy = 0.0\n",
        "\n",
        "    for task in range(meta_batch_size):\n",
        "        # Compute meta-training loss\n",
        "        # learner = maml.clone()\n",
        "\n",
        "        # generate batch the batch contains # ways*shots , channels , img size  and labels \n",
        "        train_batch = tasksets.train.sample()\n",
        "        val_batch = tasksets.validation.sample()\n",
        "\n",
        "        # split batch based on classes in labels then   labels.split(int(data.shape[0]/ways))\n",
        "        train_data, train_labels = train_batch\n",
        "        val_data , val_labels= val_batch\n",
        "\n",
        "        \n",
        "        train_data_generator ,train_lable_generator  = train_flow (train_data ,train_labels  , device)\n",
        "\n",
        "        # train_data_generator = torch.cat(train_data_generator)\n",
        "        # train_lable_generator = torch.cat(train_lable_generator)\n",
        "        \n",
        "        batch = [train_data_generator ,train_lable_generator]\n",
        "\n",
        "        learner = maml.clone()            \n",
        "        \n",
        "        evaluation_error, evaluation_accuracy = fast_adapt_train(batch,\n",
        "                                                            learner,\n",
        "                                                            loss,\n",
        "                                                            adaptation_steps,\n",
        "                                                            shots,\n",
        "                                                            ways,\n",
        "                                                            device)\n",
        "        evaluation_error.backward()\n",
        "        meta_train_error += evaluation_error.item()\n",
        "        meta_train_accuracy += evaluation_accuracy.item()\n",
        "\n",
        "# ''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
        "\n",
        "        # # Compute meta-validation loss\n",
        "        # batch = tasksets.validation.sample()\n",
        "        \n",
        "        # learner = maml.clone()\n",
        "        # evaluation_error, evaluation_accuracy = fast_adapt(batch,learner,loss,adaptation_steps,shots,ways,\n",
        "        #                                                     device)\n",
        "        # meta_valid_error += evaluation_error.item()\n",
        "        # meta_valid_accuracy += evaluation_accuracy.item()\n",
        "\n",
        "    # Print some metrics\n",
        "    print('\\n')\n",
        "    print('Iteration', iteration)\n",
        "    print('Meta Train Error', meta_train_error / meta_batch_size)\n",
        "    print('Meta Train Accuracy', meta_train_accuracy / meta_batch_size)\n",
        "    # print('Meta Valid Error', meta_valid_error / meta_batch_size)\n",
        "    # print('Meta Valid Accuracy', meta_valid_accuracy / meta_batch_size)\n",
        "\n",
        "    # Average the accumulated gradients and optimize\n",
        "    for p in maml.parameters():\n",
        "        p.grad.data.mul_(1.0 / meta_batch_size)\n",
        "    opt.step()\n",
        "\n",
        "\n",
        "acc_acuracy=[]\n",
        "iterations= 600\n",
        "for _ in range(iterations):\n",
        "  meta_test_error = 0.0\n",
        "  meta_test_accuracy = 0.0\n",
        "\n",
        "  for task in range(meta_batch_size):\n",
        "\n",
        "      # Compute meta-testing loss\n",
        "      learner = maml.clone()\n",
        "      batch = tasksets.test.sample()\n",
        "      evaluation_error, evaluation_accuracy = fast_adapt(batch,\n",
        "                                                          learner,\n",
        "                                                          loss,\n",
        "                                                          3,\n",
        "                                                          shots,\n",
        "                                                          ways,\n",
        "                                                          device)\n",
        "      meta_test_error += evaluation_error.item()\n",
        "      meta_test_accuracy += evaluation_accuracy.item()\n",
        "\n",
        "  # print('Meta Test Error', meta_test_error / meta_batch_size)\n",
        "  # print('Meta Test Accuracy', meta_test_accuracy / meta_batch_size)\n",
        "  acc_acuracy.append(meta_test_accuracy/meta_batch_size)\n",
        "\n",
        "\n",
        "acc_acuracy = np.array(acc_acuracy)\n",
        "means = np.mean(acc_acuracy, 0)\n",
        "stds = np.std(acc_acuracy, 0)\n",
        "ci95 = 1.96*stds/np.sqrt(iterations)\n",
        "\n",
        "print('Mean accuracy/loss, stddev, and confidence intervals')\n",
        "print((means, stds, ci95))\n",
        "\n",
        "print(acc_acuracy[acc_acuracy.argmin()])\n",
        "print(acc_acuracy[acc_acuracy.argmax()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:281: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "118it [00:06, 17.41it/s, epoch_progress=100%, train_loss=-6.552e+04, last_val_loss=+1.866e+07, best_epoch=18, best_loss=+1.073e+07]\n",
            "131it [00:07, 17.93it/s, epoch_progress=100%, train_loss=-6.858e+04, last_val_loss=+3.157e+07, best_epoch=31, best_loss=+1.636e+07]\n",
            "135it [00:07, 17.59it/s, epoch_progress=100%, train_loss=-7.263e+04, last_val_loss=+3.050e+07, best_epoch=35, best_loss=+1.851e+07]\n",
            "112it [00:06, 18.01it/s, epoch_progress=100%, train_loss=-7.016e+04, last_val_loss=+1.378e+07, best_epoch=12, best_loss=+6.496e+06]\n",
            "112it [00:06, 17.54it/s, epoch_progress=100%, train_loss=-6.565e+04, last_val_loss=+2.255e+07, best_epoch=12, best_loss=+9.927e+06]\n",
            "124it [00:07, 17.58it/s, epoch_progress=100%, train_loss=-6.397e+04, last_val_loss=+2.673e+07, best_epoch=24, best_loss=+1.273e+07]\n",
            "101it [00:05, 18.05it/s, epoch_progress=100%, train_loss=-6.936e+04, last_val_loss=+2.289e+07, best_epoch=1, best_loss=-5.324e+04]\n",
            "113it [00:06, 17.88it/s, epoch_progress=100%, train_loss=-7.355e+04, last_val_loss=+2.559e+07, best_epoch=13, best_loss=+9.444e+06]\n",
            "  7%|▋         | 1/15 [00:54<12:46, 54.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 0\n",
            "Meta Train Error 2.974050909280777\n",
            "Meta Train Accuracy 0.2031250037252903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "110it [00:06, 17.99it/s, epoch_progress=100%, train_loss=-7.711e+04, last_val_loss=+2.412e+07, best_epoch=10, best_loss=+4.353e+06]\n",
            "111it [00:06, 17.45it/s, epoch_progress=100%, train_loss=-6.294e+04, last_val_loss=+2.575e+07, best_epoch=11, best_loss=+7.095e+06]\n",
            "152it [00:08, 17.68it/s, epoch_progress=100%, train_loss=-6.770e+04, last_val_loss=+3.735e+07, best_epoch=52, best_loss=+1.498e+07]\n",
            "113it [00:06, 17.47it/s, epoch_progress=100%, train_loss=-5.992e+04, last_val_loss=+2.218e+07, best_epoch=13, best_loss=+8.122e+06]\n",
            "117it [00:06, 17.82it/s, epoch_progress=100%, train_loss=-6.328e+04, last_val_loss=+2.108e+07, best_epoch=17, best_loss=+9.954e+06]\n",
            "110it [00:06, 17.79it/s, epoch_progress=100%, train_loss=-6.852e+04, last_val_loss=+3.429e+07, best_epoch=10, best_loss=+5.033e+06]\n",
            "115it [00:06, 17.10it/s, epoch_progress=100%, train_loss=-8.158e+04, last_val_loss=+1.775e+07, best_epoch=15, best_loss=+9.203e+06]\n",
            "117it [00:06, 17.14it/s, epoch_progress=100%, train_loss=-5.941e+04, last_val_loss=+3.529e+07, best_epoch=17, best_loss=+1.249e+07]\n",
            " 13%|█▎        | 2/15 [01:49<11:55, 55.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 1\n",
            "Meta Train Error 2.8988442718982697\n",
            "Meta Train Accuracy 0.1812500013038516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "156it [00:08, 17.90it/s, epoch_progress=100%, train_loss=-5.955e+04, last_val_loss=+1.870e+07, best_epoch=56, best_loss=+1.461e+07]\n",
            "115it [00:06, 17.61it/s, epoch_progress=100%, train_loss=-6.017e+04, last_val_loss=+1.748e+07, best_epoch=15, best_loss=+1.074e+07]\n",
            "116it [00:06, 17.37it/s, epoch_progress=100%, train_loss=-5.933e+04, last_val_loss=+2.289e+07, best_epoch=16, best_loss=+1.654e+07]\n",
            "113it [00:06, 17.46it/s, epoch_progress=100%, train_loss=-6.179e+04, last_val_loss=+2.112e+07, best_epoch=13, best_loss=+9.702e+06]\n",
            "115it [00:06, 17.58it/s, epoch_progress=100%, train_loss=-7.170e+04, last_val_loss=+2.452e+07, best_epoch=15, best_loss=+1.045e+07]\n",
            "120it [00:06, 17.41it/s, epoch_progress=100%, train_loss=-5.907e+04, last_val_loss=+3.451e+07, best_epoch=20, best_loss=+1.448e+07]\n",
            "115it [00:06, 17.54it/s, epoch_progress=100%, train_loss=-7.881e+04, last_val_loss=+4.330e+07, best_epoch=15, best_loss=+1.615e+07]\n",
            "111it [00:06, 17.10it/s, epoch_progress=100%, train_loss=-7.979e+04, last_val_loss=+1.643e+07, best_epoch=11, best_loss=+6.255e+06]\n",
            " 20%|██        | 3/15 [02:46<11:07, 55.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 2\n",
            "Meta Train Error 2.586864322423935\n",
            "Meta Train Accuracy 0.19687500223517418\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "112it [00:06, 17.31it/s, epoch_progress=100%, train_loss=-7.084e+04, last_val_loss=+2.128e+07, best_epoch=12, best_loss=+6.501e+06]\n",
            "198it [00:11, 17.76it/s, epoch_progress=100%, train_loss=-7.469e+04, last_val_loss=+2.958e+07, best_epoch=98, best_loss=+1.335e+07]\n",
            "125it [00:07, 17.44it/s, epoch_progress=100%, train_loss=-7.256e+04, last_val_loss=+2.566e+07, best_epoch=25, best_loss=+1.750e+07]\n",
            "161it [00:09, 17.38it/s, epoch_progress=100%, train_loss=-7.664e+04, last_val_loss=+4.375e+07, best_epoch=61, best_loss=+1.224e+07]\n",
            "116it [00:06, 17.26it/s, epoch_progress=100%, train_loss=-7.281e+04, last_val_loss=+3.232e+07, best_epoch=16, best_loss=+1.179e+07]\n",
            "115it [00:06, 17.25it/s, epoch_progress=100%, train_loss=-7.359e+04, last_val_loss=+2.992e+07, best_epoch=15, best_loss=+1.288e+07]\n",
            "114it [00:06, 17.39it/s, epoch_progress=100%, train_loss=-7.470e+04, last_val_loss=+1.562e+07, best_epoch=14, best_loss=+7.121e+06]\n",
            "111it [00:06, 17.39it/s, epoch_progress=100%, train_loss=-6.678e+04, last_val_loss=+2.570e+07, best_epoch=11, best_loss=+6.599e+06]\n",
            " 27%|██▋       | 4/15 [03:48<10:38, 58.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 3\n",
            "Meta Train Error 2.6751424074172974\n",
            "Meta Train Accuracy 0.2343750037252903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [00:05, 17.40it/s, epoch_progress=100%, train_loss=-6.863e+04, last_val_loss=+2.938e+07, best_epoch=1, best_loss=-4.548e+04]\n",
            "120it [00:06, 17.41it/s, epoch_progress=100%, train_loss=-8.632e+04, last_val_loss=+1.749e+07, best_epoch=20, best_loss=+1.012e+07]\n",
            "114it [00:06, 17.30it/s, epoch_progress=100%, train_loss=-5.808e+04, last_val_loss=+2.106e+07, best_epoch=14, best_loss=+1.112e+07]\n",
            "114it [00:06, 17.37it/s, epoch_progress=100%, train_loss=-6.975e+04, last_val_loss=+3.095e+07, best_epoch=14, best_loss=+9.856e+06]\n",
            "139it [00:07, 17.41it/s, epoch_progress=100%, train_loss=-6.181e+04, last_val_loss=+3.395e+07, best_epoch=39, best_loss=+1.486e+07]\n",
            "117it [00:06, 17.29it/s, epoch_progress=100%, train_loss=-6.928e+04, last_val_loss=+2.339e+07, best_epoch=17, best_loss=+9.972e+06]\n",
            "112it [00:06, 17.40it/s, epoch_progress=100%, train_loss=-6.436e+04, last_val_loss=+2.756e+07, best_epoch=12, best_loss=+1.091e+07]\n",
            "101it [00:05, 17.45it/s, epoch_progress=100%, train_loss=-6.856e+04, last_val_loss=+2.457e+07, best_epoch=1, best_loss=-5.738e+04]\n",
            " 33%|███▎      | 5/15 [04:42<09:26, 56.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 4\n",
            "Meta Train Error 2.329778105020523\n",
            "Meta Train Accuracy 0.20625000540167093\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "121it [00:06, 17.35it/s, epoch_progress=100%, train_loss=-7.380e+04, last_val_loss=+3.627e+07, best_epoch=21, best_loss=+1.607e+07]\n",
            "114it [00:06, 17.45it/s, epoch_progress=100%, train_loss=-6.258e+04, last_val_loss=+2.526e+07, best_epoch=14, best_loss=+1.579e+07]\n",
            "111it [00:06, 17.56it/s, epoch_progress=100%, train_loss=-6.395e+04, last_val_loss=+3.450e+07, best_epoch=11, best_loss=+8.893e+06]\n",
            "123it [00:07, 17.39it/s, epoch_progress=100%, train_loss=-6.108e+04, last_val_loss=+1.869e+07, best_epoch=23, best_loss=+1.311e+07]\n",
            "112it [00:06, 17.44it/s, epoch_progress=100%, train_loss=-7.413e+04, last_val_loss=+3.274e+07, best_epoch=12, best_loss=+1.065e+07]\n",
            "111it [00:06, 17.48it/s, epoch_progress=100%, train_loss=-7.250e+04, last_val_loss=+2.350e+07, best_epoch=11, best_loss=+8.275e+06]\n",
            "112it [00:06, 17.03it/s, epoch_progress=100%, train_loss=-7.112e+04, last_val_loss=+2.767e+07, best_epoch=12, best_loss=+8.379e+06]\n",
            "128it [00:07, 17.20it/s, epoch_progress=100%, train_loss=-7.780e+04, last_val_loss=+2.267e+07, best_epoch=28, best_loss=+1.185e+07]\n",
            " 40%|████      | 6/15 [05:37<08:25, 56.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 5\n",
            "Meta Train Error 2.351452976465225\n",
            "Meta Train Accuracy 0.2000000048428774\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "133it [00:07, 17.34it/s, epoch_progress=100%, train_loss=-6.264e+04, last_val_loss=+2.610e+07, best_epoch=33, best_loss=+9.878e+06]\n",
            "128it [00:07, 17.20it/s, epoch_progress=100%, train_loss=-5.909e+04, last_val_loss=+1.739e+07, best_epoch=28, best_loss=+9.831e+06]\n",
            "111it [00:06, 17.39it/s, epoch_progress=100%, train_loss=-7.616e+04, last_val_loss=+2.227e+07, best_epoch=11, best_loss=+1.233e+07]\n",
            "114it [00:06, 17.04it/s, epoch_progress=100%, train_loss=-7.422e+04, last_val_loss=+2.599e+07, best_epoch=14, best_loss=+9.792e+06]\n",
            "128it [00:07, 17.34it/s, epoch_progress=100%, train_loss=-6.928e+04, last_val_loss=+2.979e+07, best_epoch=28, best_loss=+1.340e+07]\n",
            "113it [00:06, 17.44it/s, epoch_progress=100%, train_loss=-6.900e+04, last_val_loss=+2.845e+07, best_epoch=13, best_loss=+1.354e+07]\n",
            "129it [00:07, 17.19it/s, epoch_progress=100%, train_loss=-7.788e+04, last_val_loss=+3.527e+07, best_epoch=29, best_loss=+1.577e+07]\n",
            "138it [00:08, 17.13it/s, epoch_progress=100%, train_loss=-6.853e+04, last_val_loss=+2.456e+07, best_epoch=38, best_loss=+1.572e+07]\n",
            " 47%|████▋     | 7/15 [06:36<07:36, 57.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 6\n",
            "Meta Train Error 2.328180342912674\n",
            "Meta Train Accuracy 0.16250000149011612\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "113it [00:06, 16.93it/s, epoch_progress=100%, train_loss=-7.941e+04, last_val_loss=+2.670e+07, best_epoch=13, best_loss=+9.444e+06]\n",
            "112it [00:06, 17.31it/s, epoch_progress=100%, train_loss=-6.363e+04, last_val_loss=+3.051e+07, best_epoch=12, best_loss=+8.812e+06]\n",
            "124it [00:07, 17.36it/s, epoch_progress=100%, train_loss=-7.543e+04, last_val_loss=+2.786e+07, best_epoch=24, best_loss=+1.331e+07]\n",
            "160it [00:09, 17.29it/s, epoch_progress=100%, train_loss=-6.887e+04, last_val_loss=+3.140e+07, best_epoch=60, best_loss=+1.825e+07]\n",
            "176it [00:10, 17.16it/s, epoch_progress=100%, train_loss=-6.894e+04, last_val_loss=+3.064e+07, best_epoch=76, best_loss=+1.447e+07]\n",
            "122it [00:06, 17.49it/s, epoch_progress=100%, train_loss=-7.957e+04, last_val_loss=+3.603e+07, best_epoch=22, best_loss=+1.240e+07]\n",
            "120it [00:06, 17.44it/s, epoch_progress=100%, train_loss=-6.739e+04, last_val_loss=+2.310e+07, best_epoch=20, best_loss=+1.285e+07]\n",
            "113it [00:06, 17.25it/s, epoch_progress=100%, train_loss=-7.653e+04, last_val_loss=+4.052e+07, best_epoch=13, best_loss=+9.379e+06]\n",
            " 53%|█████▎    | 8/15 [07:37<06:49, 58.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 7\n",
            "Meta Train Error 2.225425139069557\n",
            "Meta Train Accuracy 0.1718750037252903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "119it [00:06, 17.18it/s, epoch_progress=100%, train_loss=-8.368e+04, last_val_loss=+2.103e+07, best_epoch=19, best_loss=+1.003e+07]\n",
            "114it [00:06, 17.28it/s, epoch_progress=100%, train_loss=-7.745e+04, last_val_loss=+2.355e+07, best_epoch=14, best_loss=+1.005e+07]\n",
            "112it [00:06, 17.39it/s, epoch_progress=100%, train_loss=-5.772e+04, last_val_loss=+2.645e+07, best_epoch=12, best_loss=+8.436e+06]\n",
            "116it [00:06, 17.04it/s, epoch_progress=100%, train_loss=-6.077e+04, last_val_loss=+2.582e+07, best_epoch=16, best_loss=+1.425e+07]\n",
            "169it [00:09, 17.32it/s, epoch_progress=100%, train_loss=-7.330e+04, last_val_loss=+2.847e+07, best_epoch=69, best_loss=+1.434e+07]\n",
            "120it [00:07, 17.07it/s, epoch_progress=100%, train_loss=-8.294e+04, last_val_loss=+2.823e+07, best_epoch=20, best_loss=+1.215e+07]\n",
            "113it [00:06, 17.44it/s, epoch_progress=100%, train_loss=-7.901e+04, last_val_loss=+1.496e+07, best_epoch=13, best_loss=+6.392e+06]\n",
            "136it [00:07, 17.02it/s, epoch_progress=100%, train_loss=-7.070e+04, last_val_loss=+3.121e+07, best_epoch=36, best_loss=+1.539e+07]\n",
            " 60%|██████    | 9/15 [08:37<05:52, 58.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 8\n",
            "Meta Train Error 2.127370983362198\n",
            "Meta Train Accuracy 0.21250000689178705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "111it [00:06, 17.29it/s, epoch_progress=100%, train_loss=-6.568e+04, last_val_loss=+2.684e+07, best_epoch=11, best_loss=+6.638e+06]\n",
            "116it [00:06, 17.12it/s, epoch_progress=100%, train_loss=-6.351e+04, last_val_loss=+3.217e+07, best_epoch=16, best_loss=+1.328e+07]\n",
            "113it [00:06, 17.22it/s, epoch_progress=100%, train_loss=-7.209e+04, last_val_loss=+2.573e+07, best_epoch=13, best_loss=+9.366e+06]\n",
            "139it [00:08, 17.03it/s, epoch_progress=100%, train_loss=-7.488e+04, last_val_loss=+3.780e+07, best_epoch=39, best_loss=+1.742e+07]\n",
            "158it [00:09, 17.26it/s, epoch_progress=100%, train_loss=-6.843e+04, last_val_loss=+3.524e+07, best_epoch=58, best_loss=+1.611e+07]\n",
            "121it [00:07, 16.96it/s, epoch_progress=100%, train_loss=-7.527e+04, last_val_loss=+2.968e+07, best_epoch=21, best_loss=+1.480e+07]\n",
            "111it [00:06, 17.11it/s, epoch_progress=100%, train_loss=-7.083e+04, last_val_loss=+2.823e+07, best_epoch=11, best_loss=+5.568e+06]\n",
            "113it [00:06, 17.20it/s, epoch_progress=100%, train_loss=-5.933e+04, last_val_loss=+2.610e+07, best_epoch=13, best_loss=+7.611e+06]\n",
            " 67%|██████▋   | 10/15 [09:36<04:53, 58.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 9\n",
            "Meta Train Error 2.139521449804306\n",
            "Meta Train Accuracy 0.18125000223517418\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "113it [00:06, 17.33it/s, epoch_progress=100%, train_loss=-7.261e+04, last_val_loss=+3.539e+07, best_epoch=13, best_loss=+7.120e+06]\n",
            "145it [00:08, 17.18it/s, epoch_progress=100%, train_loss=-6.337e+04, last_val_loss=+1.836e+07, best_epoch=45, best_loss=+1.456e+07]\n",
            "111it [00:06, 17.09it/s, epoch_progress=100%, train_loss=-6.175e+04, last_val_loss=+1.594e+07, best_epoch=11, best_loss=+8.972e+06]\n",
            "111it [00:06, 17.17it/s, epoch_progress=100%, train_loss=-7.839e+04, last_val_loss=+2.197e+07, best_epoch=11, best_loss=+6.298e+06]\n",
            "136it [00:07, 17.12it/s, epoch_progress=100%, train_loss=-5.986e+04, last_val_loss=+3.381e+07, best_epoch=36, best_loss=+1.337e+07]\n",
            "148it [00:08, 17.03it/s, epoch_progress=100%, train_loss=-7.140e+04, last_val_loss=+2.334e+07, best_epoch=48, best_loss=+1.451e+07]\n",
            "114it [00:06, 16.88it/s, epoch_progress=100%, train_loss=-7.571e+04, last_val_loss=+1.704e+07, best_epoch=14, best_loss=+6.861e+06]\n",
            "129it [00:07, 17.27it/s, epoch_progress=100%, train_loss=-8.379e+04, last_val_loss=+2.351e+07, best_epoch=29, best_loss=+1.228e+07]\n",
            " 73%|███████▎  | 11/15 [10:36<03:56, 59.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 10\n",
            "Meta Train Error 2.173894092440605\n",
            "Meta Train Accuracy 0.21562500670552254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "120it [00:07, 16.95it/s, epoch_progress=100%, train_loss=-7.460e+04, last_val_loss=+1.662e+07, best_epoch=20, best_loss=+1.188e+07]\n",
            "111it [00:06, 17.21it/s, epoch_progress=100%, train_loss=-6.469e+04, last_val_loss=+1.467e+07, best_epoch=11, best_loss=+3.159e+06]\n",
            "114it [00:06, 17.26it/s, epoch_progress=100%, train_loss=-7.018e+04, last_val_loss=+2.461e+07, best_epoch=14, best_loss=+1.253e+07]\n",
            "119it [00:07, 16.78it/s, epoch_progress=100%, train_loss=-6.595e+04, last_val_loss=+2.372e+07, best_epoch=19, best_loss=+1.261e+07]\n",
            "112it [00:06, 16.93it/s, epoch_progress=100%, train_loss=-7.813e+04, last_val_loss=+3.049e+07, best_epoch=12, best_loss=+6.747e+06]\n",
            "113it [00:06, 17.09it/s, epoch_progress=100%, train_loss=-6.504e+04, last_val_loss=+1.313e+07, best_epoch=13, best_loss=+7.761e+06]\n",
            "111it [00:06, 17.28it/s, epoch_progress=100%, train_loss=-5.180e+04, last_val_loss=+3.578e+07, best_epoch=11, best_loss=+1.401e+07]\n",
            "177it [00:10, 17.26it/s, epoch_progress=100%, train_loss=-7.224e+04, last_val_loss=+3.458e+07, best_epoch=77, best_loss=+1.486e+07]\n",
            " 80%|████████  | 12/15 [11:34<02:56, 58.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 11\n",
            "Meta Train Error 2.033772721886635\n",
            "Meta Train Accuracy 0.19062500353902578\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "113it [00:06, 17.39it/s, epoch_progress=100%, train_loss=-6.745e+04, last_val_loss=+2.352e+07, best_epoch=13, best_loss=+9.646e+06]\n",
            "114it [00:06, 17.12it/s, epoch_progress=100%, train_loss=-6.160e+04, last_val_loss=+2.105e+07, best_epoch=14, best_loss=+9.411e+06]\n",
            "152it [00:08, 17.15it/s, epoch_progress=100%, train_loss=-7.706e+04, last_val_loss=+3.145e+07, best_epoch=52, best_loss=+1.540e+07]\n",
            "122it [00:07, 17.19it/s, epoch_progress=100%, train_loss=-6.876e+04, last_val_loss=+2.333e+07, best_epoch=22, best_loss=+1.111e+07]\n",
            "115it [00:06, 17.05it/s, epoch_progress=100%, train_loss=-8.191e+04, last_val_loss=+3.313e+07, best_epoch=15, best_loss=+1.028e+07]\n",
            "111it [00:06, 17.20it/s, epoch_progress=100%, train_loss=-6.972e+04, last_val_loss=+2.141e+07, best_epoch=11, best_loss=+5.560e+06]\n",
            "112it [00:06, 17.49it/s, epoch_progress=100%, train_loss=-7.392e+04, last_val_loss=+2.149e+07, best_epoch=12, best_loss=+1.268e+07]\n",
            "115it [00:06, 17.40it/s, epoch_progress=100%, train_loss=-6.873e+04, last_val_loss=+3.032e+07, best_epoch=15, best_loss=+1.674e+07]\n",
            " 87%|████████▋ | 13/15 [12:31<01:56, 58.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 12\n",
            "Meta Train Error 1.8904107362031937\n",
            "Meta Train Accuracy 0.18750000186264515\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "115it [00:06, 17.30it/s, epoch_progress=100%, train_loss=-6.858e+04, last_val_loss=+2.847e+07, best_epoch=15, best_loss=+1.053e+07]\n",
            "114it [00:06, 16.94it/s, epoch_progress=100%, train_loss=-7.920e+04, last_val_loss=+4.180e+07, best_epoch=14, best_loss=+1.604e+07]\n",
            "113it [00:06, 17.24it/s, epoch_progress=100%, train_loss=-7.684e+04, last_val_loss=+2.667e+07, best_epoch=13, best_loss=+9.784e+06]\n",
            "132it [00:07, 17.05it/s, epoch_progress=100%, train_loss=-7.099e+04, last_val_loss=+2.067e+07, best_epoch=32, best_loss=+1.328e+07]\n",
            "111it [00:06, 17.07it/s, epoch_progress=100%, train_loss=-7.748e+04, last_val_loss=+1.828e+07, best_epoch=11, best_loss=+5.350e+06]\n",
            "115it [00:06, 16.91it/s, epoch_progress=100%, train_loss=-7.077e+04, last_val_loss=+1.876e+07, best_epoch=15, best_loss=+1.147e+07]\n",
            "110it [00:06, 17.12it/s, epoch_progress=100%, train_loss=-7.290e+04, last_val_loss=+1.761e+07, best_epoch=10, best_loss=+4.434e+06]\n",
            "153it [00:08, 17.08it/s, epoch_progress=100%, train_loss=-5.063e+04, last_val_loss=+2.442e+07, best_epoch=53, best_loss=+1.580e+07]\n",
            " 93%|█████████▎| 14/15 [13:29<00:58, 58.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 13\n",
            "Meta Train Error 1.8283534944057465\n",
            "Meta Train Accuracy 0.21250000409781933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "117it [00:06, 17.43it/s, epoch_progress=100%, train_loss=-7.413e+04, last_val_loss=+1.555e+07, best_epoch=17, best_loss=+9.279e+06]\n",
            "112it [00:06, 17.07it/s, epoch_progress=100%, train_loss=-7.211e+04, last_val_loss=+2.102e+07, best_epoch=12, best_loss=+1.281e+07]\n",
            "150it [00:08, 16.88it/s, epoch_progress=100%, train_loss=-7.254e+04, last_val_loss=+2.289e+07, best_epoch=50, best_loss=+1.382e+07]\n",
            "126it [00:07, 16.99it/s, epoch_progress=100%, train_loss=-7.135e+04, last_val_loss=+2.740e+07, best_epoch=26, best_loss=+1.581e+07]\n",
            "118it [00:06, 17.22it/s, epoch_progress=100%, train_loss=-6.397e+04, last_val_loss=+3.198e+07, best_epoch=18, best_loss=+1.415e+07]\n",
            "116it [00:06, 17.24it/s, epoch_progress=100%, train_loss=-7.323e+04, last_val_loss=+1.493e+07, best_epoch=16, best_loss=+7.414e+06]\n",
            "142it [00:08, 16.85it/s, epoch_progress=100%, train_loss=-6.830e+04, last_val_loss=+2.660e+07, best_epoch=42, best_loss=+1.885e+07]\n",
            "134it [00:07, 17.03it/s, epoch_progress=100%, train_loss=-7.300e+04, last_val_loss=+2.268e+07, best_epoch=34, best_loss=+1.339e+07]\n",
            "100%|██████████| 15/15 [14:29<00:00, 58.00s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 14\n",
            "Meta Train Error 2.0196507275104523\n",
            "Meta Train Accuracy 0.18750000558793545\n",
            "Mean accuracy/loss, stddev, and confidence intervals\n",
            "(0.5629583456149946, 0.08016778296272273, 0.006414758627582673)\n",
            "0.32500000670552254\n",
            "0.7500000149011612\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joJFPtLETmlk"
      },
      "source": [
        "\n",
        "**Summary of EXP2** \n",
        "---\n",
        "\n",
        "400 generated images instead of 1 shot per class and 15 iterations, Flow of single batch norm layer\n",
        "\n",
        "* **Standard MAML**\n",
        "  * not tested \n",
        "\n",
        "---\n",
        "* **with following flow**\n",
        "\n",
        "  * Mean accuracy/loss, stddev, and confidence intervals\n",
        "  * (0.5512083456323793, 0.07986706701169034, 0.006390696340089533)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f907b80691c74b518ea9a3f7e0ac7d61",
            "449a1e68a8e64e3ca2567fd8c5ccfa21",
            "2beaa6c5a00644e3a90fdbb5dfb99f04",
            "c83930462699457e8dde7abcfa4a2796",
            "1f61d1ceb8cc49d69a9090b6110571f1",
            "705fcc4b70154bdd8ff19923a0654343",
            "8a3e2883eab4436d99aac38386b61914",
            "561e8bed18c846b6b20e196dc8934988",
            "76548f5459ae40528914a315031a95ee",
            "e4d43f3ef3c54d0b8fa203c424dffd2b",
            "b30bdb84fe394bd9872f742e4b141195",
            "80fe0f490d174e658c857b3c602612e2",
            "6f57a61114ae45a7a428915e437b3ea1",
            "e241ea9a8cb34ac79035692ce5b93eab",
            "7f41134525624762824ab81d5fad5823",
            "85fb670ef2804ef78286cc7fef15d401",
            "9dcc7fe9e11e4bc8a9b28618d9d9e3a9",
            "936cbdbce44749f0b7a256e642c5ff16",
            "42b17376fc354e5eba847ec7d3572750",
            "d27a53423e164b42b32bb12f101d6784",
            "edcca8011f714d19a46788a9def374e7",
            "f01e903b4f4b4590b0e2496b7ee60200"
          ]
        },
        "id": "1xgFWQOqgxk1",
        "cellView": "form",
        "outputId": "12e00c20-4c39-462c-864c-a469f26983c5"
      },
      "source": [
        "#@title EXP2 400 generated images instead of 1 shot per class and 15 iterations, Flow of single batch norm layer with pacience=100\n",
        "\n",
        "#@markdown ----\n",
        "\n",
        "#@markdown Mean accuracy/loss, stddev, and confidence intervals\n",
        "\n",
        "#@markdown (0.5512083456323793, 0.07986706701169034, 0.006390696340089533)\n",
        "\n",
        "#@markdown min accuracy: 0.2750000078231096\n",
        "\n",
        "#@markdown max accuracy:  0.800000011920929\n",
        "\n",
        "\n",
        "\n",
        "def accuracy(predictions, targets):\n",
        "    predictions = predictions.argmax(dim=1).view(targets.shape)\n",
        "    return (predictions == targets).sum().float() / targets.size(0)\n",
        "\n",
        "\n",
        "def fast_adapt(batch, learner, loss, adaptation_steps, shots, ways, device):\n",
        "    data, labels = batch\n",
        "    # print(\"data:  \",data.shape)\n",
        "    data, labels = data.to(device), labels.to(device, dtype=torch.int64)\n",
        "    # Separate data into adaptation/evalutation sets\n",
        "    adaptation_indices = np.zeros(data.size(0), dtype=bool)\n",
        "    adaptation_indices[np.arange(shots*ways) * 2] = True\n",
        "    evaluation_indices = torch.from_numpy(~adaptation_indices)\n",
        "    adaptation_indices = torch.from_numpy(adaptation_indices)\n",
        "    adaptation_data, adaptation_labels = data[adaptation_indices], labels[adaptation_indices]\n",
        "    evaluation_data, evaluation_labels = data[evaluation_indices], labels[evaluation_indices]\n",
        "\n",
        "    # Adapt the model\n",
        "    for step in range(adaptation_steps):\n",
        "        train_error = loss(learner(adaptation_data), adaptation_labels)\n",
        "        learner.adapt(train_error)\n",
        "\n",
        "\n",
        "    # Evaluate the adapted model\n",
        "    predictions = learner(evaluation_data)\n",
        "    valid_error = loss(predictions, evaluation_labels)\n",
        "    valid_accuracy = accuracy(predictions, evaluation_labels)\n",
        "    return valid_error, valid_accuracy\n",
        "\n",
        "\n",
        "def fast_adapt_train(batch, learner, loss, adaptation_steps, shots, ways, device):\n",
        "\n",
        "    data, labels = batch\n",
        "    data, labels = data.to(device), labels.to(device, dtype=torch.int64)\n",
        "    # Separate data into adaptation/evalutation sets\n",
        "    indices = np.random.permutation(data.shape[0])\n",
        "    \n",
        "    adaptation_indices = indices[:360]\n",
        "    evaluation_indices = indices[360:]\n",
        "    adaptation_data, adaptation_labels = data[adaptation_indices], labels[adaptation_indices]\n",
        "    evaluation_data, evaluation_labels = data[evaluation_indices], labels[evaluation_indices]\n",
        "    # print(adaptation_data.shape)\n",
        "    # print(\"modified version\")\n",
        "    # Adapt the model\n",
        "    for step in range(adaptation_steps):\n",
        "        train_error = loss(learner(adaptation_data), adaptation_labels)\n",
        "        learner.adapt(train_error)\n",
        "\n",
        "\n",
        "    # Evaluate the adapted model\n",
        "    predictions = learner(evaluation_data)\n",
        "    valid_error = loss(predictions, evaluation_labels)\n",
        "    valid_accuracy = accuracy(predictions, evaluation_labels)\n",
        "    return valid_error, valid_accuracy\n",
        "\n",
        "def train_flow (trainX ,cond_train , device):\n",
        "\n",
        "  \n",
        "  # trainX has a shape of (count , channel , pixles,pixles)\n",
        "  \n",
        "\n",
        "  trainX = torch.flatten(trainX,1,-1)\n",
        "  # valX = torch.flatten(valX , 1,-1)\n",
        "  dim=trainX.shape[1]\n",
        "  \n",
        "  # print(cond_train)\n",
        "  cond_train = torch.nn.functional.one_hot(cond_train)\n",
        "  # cond_val   = torch.nn.functional.one_hot(cond_val) \n",
        "  # print(cond_train)\n",
        "  cond_dim = cond_train.size(1)\n",
        "  flow = Sequential(      \n",
        "\n",
        "# very slow in sampling \n",
        "    inv_flow(Sigmoid)(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    # MADE(DSF(dim=dim), cond_dim=cond_dim),\n",
        "    # Affine(dim=dim),  \n",
        "\n",
        "      # BatchNorm(dim=dim),\n",
        "      # MADE(AffineTransformer(dim=dim) , cond_dim=cond_dim),\n",
        "  ).to(device)\n",
        "\n",
        "\n",
        "  train_losses, val_losses = train(flow, trainX, trainX ,cond_train=cond_train, cond_val=cond_train , patience=100 ,batch_size=8,n_epochs=1000)\n",
        " \n",
        "  test_labels = np.random.choice(5, size=(400))\n",
        "  test_labels = torch.from_numpy(test_labels)\n",
        "  test_cond = torch.nn.functional.one_hot(test_labels)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    train_data = flow.sample(400,cond=test_cond.to(device)).cpu()\n",
        "\n",
        "  # return train_data, train_losses , val_losses , mean , var\n",
        "  return torch.reshape(train_data , (400,1,28,28)) , test_labels\n",
        "\n",
        "\n",
        "\n",
        "ways=5\n",
        "shots=1\n",
        "meta_lr=0.003\n",
        "fast_lr=0.5\n",
        "meta_batch_size=8\n",
        "adaptation_steps=1\n",
        "num_iterations=15\n",
        "cuda=True\n",
        "# seed=42\n",
        "# Load train/validation/test tasksets using the benchmark interface\n",
        "tasksets = l2l.vision.benchmarks.get_tasksets('omniglot',\n",
        "                                                  train_ways=ways,\n",
        "                                                  train_samples=2*shots,\n",
        "                                                  test_ways=ways,\n",
        "                                                  test_samples=2*shots,\n",
        "                                                  num_tasks=20000,\n",
        "                                                  root='~/data',\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "device = torch.device('cpu')\n",
        "if cuda:\n",
        "  # torch.cuda.manual_seed(seed)\n",
        "  device = torch.device('cuda')\n",
        "\n",
        "# Create model\n",
        "model = l2l.vision.models.OmniglotCNN(ways)\n",
        "# model = l2l.vision.models.OmniglotFC(28 ** 2, ways)\n",
        "model.to(device)\n",
        "maml = l2l.algorithms.MAML(model, lr=fast_lr, first_order=False)\n",
        "opt = optim.Adam(maml.parameters(), meta_lr)\n",
        "loss = nn.CrossEntropyLoss(reduction='mean')\n",
        "\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "for iteration in tqdm(range(num_iterations)):\n",
        "    opt.zero_grad()\n",
        "    meta_train_error = 0.0\n",
        "    meta_train_accuracy = 0.0\n",
        "    meta_valid_error = 0.0\n",
        "    meta_valid_accuracy = 0.0\n",
        "\n",
        "    for task in range(meta_batch_size):\n",
        "        # Compute meta-training loss\n",
        "        # learner = maml.clone()\n",
        "\n",
        "        # generate batch the batch contains # ways*shots , channels , img size  and labels \n",
        "        train_batch = tasksets.train.sample()\n",
        "        val_batch = tasksets.validation.sample()\n",
        "\n",
        "        # split batch based on classes in labels then   labels.split(int(data.shape[0]/ways))\n",
        "        train_data, train_labels = train_batch\n",
        "        val_data , val_labels= val_batch\n",
        "\n",
        "        \n",
        "        train_data_generator ,train_lable_generator  = train_flow (train_data ,train_labels  , device)\n",
        "\n",
        "        # train_data_generator = torch.cat(train_data_generator)\n",
        "        # train_lable_generator = torch.cat(train_lable_generator)\n",
        "        \n",
        "        batch = [train_data_generator ,train_lable_generator]\n",
        "\n",
        "        learner = maml.clone()            \n",
        "        \n",
        "        evaluation_error, evaluation_accuracy = fast_adapt_train(batch,\n",
        "                                                            learner,\n",
        "                                                            loss,\n",
        "                                                            adaptation_steps,\n",
        "                                                            shots,\n",
        "                                                            ways,\n",
        "                                                            device)\n",
        "        evaluation_error.backward()\n",
        "        meta_train_error += evaluation_error.item()\n",
        "        meta_train_accuracy += evaluation_accuracy.item()\n",
        "\n",
        "# ''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
        "\n",
        "        # # Compute meta-validation loss\n",
        "        # batch = tasksets.validation.sample()\n",
        "        \n",
        "        # learner = maml.clone()\n",
        "        # evaluation_error, evaluation_accuracy = fast_adapt(batch,learner,loss,adaptation_steps,shots,ways,\n",
        "        #                                                     device)\n",
        "        # meta_valid_error += evaluation_error.item()\n",
        "        # meta_valid_accuracy += evaluation_accuracy.item()\n",
        "\n",
        "    # Print some metrics\n",
        "    print('\\n')\n",
        "    print('Iteration', iteration)\n",
        "    print('Meta Train Error', meta_train_error / meta_batch_size)\n",
        "    print('Meta Train Accuracy', meta_train_accuracy / meta_batch_size)\n",
        "    # print('Meta Valid Error', meta_valid_error / meta_batch_size)\n",
        "    # print('Meta Valid Accuracy', meta_valid_accuracy / meta_batch_size)\n",
        "\n",
        "    # Average the accumulated gradients and optimize\n",
        "    for p in maml.parameters():\n",
        "        p.grad.data.mul_(1.0 / meta_batch_size)\n",
        "    opt.step()\n",
        "\n",
        "\n",
        "acc_acuracy=[]\n",
        "iterations= 600\n",
        "for _ in range(iterations):\n",
        "  meta_test_error = 0.0\n",
        "  meta_test_accuracy = 0.0\n",
        "\n",
        "  for task in range(meta_batch_size):\n",
        "\n",
        "      # Compute meta-testing loss\n",
        "      learner = maml.clone()\n",
        "      batch = tasksets.test.sample()\n",
        "      evaluation_error, evaluation_accuracy = fast_adapt(batch,\n",
        "                                                          learner,\n",
        "                                                          loss,\n",
        "                                                          3,\n",
        "                                                          shots,\n",
        "                                                          ways,\n",
        "                                                          device)\n",
        "      meta_test_error += evaluation_error.item()\n",
        "      meta_test_accuracy += evaluation_accuracy.item()\n",
        "\n",
        "  # print('Meta Test Error', meta_test_error / meta_batch_size)\n",
        "  # print('Meta Test Accuracy', meta_test_accuracy / meta_batch_size)\n",
        "  acc_acuracy.append(meta_test_accuracy/meta_batch_size)\n",
        "\n",
        "\n",
        "acc_acuracy = np.array(acc_acuracy)\n",
        "means = np.mean(acc_acuracy, 0)\n",
        "stds = np.std(acc_acuracy, 0)\n",
        "ci95 = 1.96*stds/np.sqrt(iterations)\n",
        "\n",
        "print('Mean accuracy/loss, stddev, and confidence intervals')\n",
        "print((means, stds, ci95))\n",
        "\n",
        "print(acc_acuracy[acc_acuracy.argmin()])\n",
        "print(acc_acuracy[acc_acuracy.argmax()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:281: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://raw.githubusercontent.com/brendenlake/omniglot/master/python/images_background.zip to /root/data/omniglot-py/images_background.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f907b80691c74b518ea9a3f7e0ac7d61",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/9464212 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /root/data/omniglot-py/images_background.zip to /root/data/omniglot-py\n",
            "Downloading https://raw.githubusercontent.com/brendenlake/omniglot/master/python/images_evaluation.zip to /root/data/omniglot-py/images_evaluation.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "80fe0f490d174e658c857b3c602612e2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/6462886 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /root/data/omniglot-py/images_evaluation.zip to /root/data/omniglot-py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1000it [00:23, 41.90it/s, epoch_progress=100%, train_loss=-9.744e+03, last_val_loss=-7.186e+03, best_epoch=991, best_loss=-7.209e+03]\n",
            "106it [00:02, 41.97it/s, epoch_progress=100%, train_loss=-9.795e+03, last_val_loss=-5.624e+03, best_epoch=6, best_loss=-5.663e+03]\n",
            "104it [00:02, 42.71it/s, epoch_progress=100%, train_loss=-8.905e+03, last_val_loss=-5.615e+03, best_epoch=4, best_loss=-5.648e+03]\n",
            "1000it [00:23, 42.31it/s, epoch_progress=100%, train_loss=-9.417e+03, last_val_loss=-7.128e+03, best_epoch=974, best_loss=-7.137e+03]\n",
            "1000it [00:23, 42.19it/s, epoch_progress=100%, train_loss=-1.013e+04, last_val_loss=-6.818e+03, best_epoch=993, best_loss=-6.875e+03]\n",
            "1000it [00:23, 42.09it/s, epoch_progress=100%, train_loss=-1.039e+04, last_val_loss=-6.956e+03, best_epoch=961, best_loss=-6.994e+03]\n",
            "1000it [00:24, 41.37it/s, epoch_progress=100%, train_loss=-1.010e+04, last_val_loss=-7.502e+03, best_epoch=988, best_loss=-7.585e+03]\n",
            "405it [00:09, 42.22it/s, epoch_progress=100%, train_loss=-8.211e+03, last_val_loss=-5.665e+03, best_epoch=305, best_loss=-5.706e+03]\n",
            "  7%|▋         | 1/15 [02:15<31:31, 135.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 0\n",
            "Meta Train Error 3.3627621233463287\n",
            "Meta Train Accuracy 0.2593750059604645\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "107it [00:02, 41.31it/s, epoch_progress=100%, train_loss=-9.092e+03, last_val_loss=-5.793e+03, best_epoch=7, best_loss=-5.810e+03]\n",
            "104it [00:02, 42.61it/s, epoch_progress=100%, train_loss=-8.471e+03, last_val_loss=-5.706e+03, best_epoch=4, best_loss=-5.722e+03]\n",
            "1000it [00:23, 42.31it/s, epoch_progress=100%, train_loss=-9.943e+03, last_val_loss=-7.070e+03, best_epoch=971, best_loss=-7.149e+03]\n",
            "1000it [00:23, 43.10it/s, epoch_progress=100%, train_loss=-1.008e+04, last_val_loss=-6.613e+03, best_epoch=990, best_loss=-6.670e+03]\n",
            "1000it [00:23, 42.66it/s, epoch_progress=100%, train_loss=-9.279e+03, last_val_loss=-5.959e+03, best_epoch=997, best_loss=-6.009e+03]\n",
            "1000it [00:23, 42.77it/s, epoch_progress=100%, train_loss=-1.055e+04, last_val_loss=-6.665e+03, best_epoch=991, best_loss=-6.701e+03]\n",
            "1000it [00:23, 42.66it/s, epoch_progress=100%, train_loss=-1.058e+04, last_val_loss=-7.032e+03, best_epoch=977, best_loss=-7.139e+03]\n",
            "1000it [00:23, 42.87it/s, epoch_progress=100%, train_loss=-1.024e+04, last_val_loss=-7.113e+03, best_epoch=964, best_loss=-7.171e+03]\n",
            " 13%|█▎        | 2/15 [04:41<30:45, 141.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 1\n",
            "Meta Train Error 4.208547413349152\n",
            "Meta Train Accuracy 0.16875000298023224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1000it [00:23, 43.40it/s, epoch_progress=100%, train_loss=-9.518e+03, last_val_loss=-6.402e+03, best_epoch=990, best_loss=-6.440e+03]\n",
            "1000it [00:23, 43.38it/s, epoch_progress=100%, train_loss=-9.136e+03, last_val_loss=-6.017e+03, best_epoch=981, best_loss=-6.105e+03]\n",
            "1000it [00:23, 43.21it/s, epoch_progress=100%, train_loss=-9.241e+03, last_val_loss=-7.667e+03, best_epoch=1000, best_loss=-7.667e+03]\n",
            "1000it [00:23, 42.89it/s, epoch_progress=100%, train_loss=-1.008e+04, last_val_loss=-7.113e+03, best_epoch=974, best_loss=-7.146e+03]\n",
            "1000it [00:23, 43.34it/s, epoch_progress=100%, train_loss=-9.876e+03, last_val_loss=-6.251e+03, best_epoch=962, best_loss=-6.292e+03]\n",
            "141it [00:03, 43.33it/s, epoch_progress=100%, train_loss=-7.677e+03, last_val_loss=-5.418e+03, best_epoch=41, best_loss=-5.425e+03]\n",
            "1000it [00:23, 42.45it/s, epoch_progress=100%, train_loss=-1.057e+04, last_val_loss=-7.501e+03, best_epoch=986, best_loss=-7.591e+03]\n",
            "1000it [00:23, 42.75it/s, epoch_progress=100%, train_loss=-1.010e+04, last_val_loss=-8.118e+03, best_epoch=1000, best_loss=-8.118e+03]\n",
            " 20%|██        | 3/15 [07:28<30:41, 153.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 2\n",
            "Meta Train Error 3.729107141494751\n",
            "Meta Train Accuracy 0.18125000316649675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1000it [00:23, 43.23it/s, epoch_progress=100%, train_loss=-9.593e+03, last_val_loss=-6.235e+03, best_epoch=990, best_loss=-6.237e+03]\n",
            "1000it [00:23, 42.73it/s, epoch_progress=100%, train_loss=-9.020e+03, last_val_loss=-7.153e+03, best_epoch=979, best_loss=-7.175e+03]\n",
            "106it [00:02, 41.93it/s, epoch_progress=100%, train_loss=-8.958e+03, last_val_loss=-5.962e+03, best_epoch=6, best_loss=-5.989e+03]\n",
            "1000it [00:23, 42.61it/s, epoch_progress=100%, train_loss=-9.805e+03, last_val_loss=-8.583e+03, best_epoch=984, best_loss=-8.596e+03]\n",
            "1000it [00:23, 42.12it/s, epoch_progress=100%, train_loss=-9.848e+03, last_val_loss=-6.644e+03, best_epoch=983, best_loss=-6.737e+03]\n",
            "1000it [00:23, 42.66it/s, epoch_progress=100%, train_loss=-1.046e+04, last_val_loss=-6.660e+03, best_epoch=938, best_loss=-6.732e+03]\n",
            "104it [00:02, 42.87it/s, epoch_progress=100%, train_loss=-8.993e+03, last_val_loss=-5.540e+03, best_epoch=4, best_loss=-5.583e+03]\n",
            "184it [00:04, 42.86it/s, epoch_progress=100%, train_loss=-9.676e+03, last_val_loss=-5.747e+03, best_epoch=84, best_loss=-5.778e+03]\n",
            " 27%|██▋       | 4/15 [09:36<26:16, 143.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 3\n",
            "Meta Train Error 3.545693129301071\n",
            "Meta Train Accuracy 0.18125000316649675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "104it [00:02, 43.39it/s, epoch_progress=100%, train_loss=-9.038e+03, last_val_loss=-5.696e+03, best_epoch=4, best_loss=-5.716e+03]\n",
            "1000it [00:23, 42.89it/s, epoch_progress=100%, train_loss=-1.059e+04, last_val_loss=-6.723e+03, best_epoch=986, best_loss=-6.843e+03]\n",
            "1000it [00:23, 43.19it/s, epoch_progress=100%, train_loss=-1.027e+04, last_val_loss=-7.495e+03, best_epoch=970, best_loss=-7.520e+03]\n",
            "1000it [00:23, 42.88it/s, epoch_progress=100%, train_loss=-9.459e+03, last_val_loss=-7.311e+03, best_epoch=989, best_loss=-7.332e+03]\n",
            "1000it [00:23, 42.36it/s, epoch_progress=100%, train_loss=-1.108e+04, last_val_loss=-6.973e+03, best_epoch=977, best_loss=-7.040e+03]\n",
            "146it [00:03, 42.10it/s, epoch_progress=100%, train_loss=-9.500e+03, last_val_loss=-5.523e+03, best_epoch=46, best_loss=-5.611e+03]\n",
            "1000it [00:23, 42.56it/s, epoch_progress=100%, train_loss=-8.091e+03, last_val_loss=-6.213e+03, best_epoch=993, best_loss=-6.278e+03]\n",
            "1000it [00:23, 42.91it/s, epoch_progress=100%, train_loss=-9.963e+03, last_val_loss=-6.397e+03, best_epoch=987, best_loss=-6.443e+03]\n",
            " 33%|███▎      | 5/15 [12:04<24:07, 144.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 4\n",
            "Meta Train Error 3.316021889448166\n",
            "Meta Train Accuracy 0.23437500186264515\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1000it [00:23, 41.82it/s, epoch_progress=100%, train_loss=-9.583e+03, last_val_loss=-7.122e+03, best_epoch=991, best_loss=-7.152e+03]\n",
            "1000it [00:23, 42.00it/s, epoch_progress=100%, train_loss=-1.221e+04, last_val_loss=-7.304e+03, best_epoch=989, best_loss=-7.368e+03]\n",
            "1000it [00:23, 42.19it/s, epoch_progress=100%, train_loss=-9.170e+03, last_val_loss=-5.767e+03, best_epoch=999, best_loss=-5.773e+03]\n",
            "1000it [00:23, 42.56it/s, epoch_progress=100%, train_loss=-1.061e+04, last_val_loss=-6.811e+03, best_epoch=962, best_loss=-6.842e+03]\n",
            "109it [00:02, 42.15it/s, epoch_progress=100%, train_loss=-9.313e+03, last_val_loss=-4.723e+03, best_epoch=9, best_loss=-4.818e+03]\n",
            "102it [00:02, 41.80it/s, epoch_progress=100%, train_loss=-9.881e+03, last_val_loss=-5.723e+03, best_epoch=2, best_loss=-5.788e+03]\n",
            "1000it [00:23, 42.64it/s, epoch_progress=100%, train_loss=-9.289e+03, last_val_loss=-6.901e+03, best_epoch=994, best_loss=-6.915e+03]\n",
            "1000it [00:23, 42.30it/s, epoch_progress=100%, train_loss=-9.753e+03, last_val_loss=-5.815e+03, best_epoch=969, best_loss=-5.918e+03]\n",
            " 40%|████      | 6/15 [14:32<21:53, 145.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 5\n",
            "Meta Train Error 3.044095456600189\n",
            "Meta Train Accuracy 0.17812500335276127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "245it [00:05, 43.17it/s, epoch_progress=100%, train_loss=-9.427e+03, last_val_loss=-5.991e+03, best_epoch=145, best_loss=-6.016e+03]\n",
            "103it [00:02, 43.36it/s, epoch_progress=100%, train_loss=-9.057e+03, last_val_loss=-5.019e+03, best_epoch=3, best_loss=-5.084e+03]\n",
            "1000it [00:23, 42.50it/s, epoch_progress=100%, train_loss=-9.141e+03, last_val_loss=-6.868e+03, best_epoch=974, best_loss=-6.926e+03]\n",
            "1000it [00:23, 42.71it/s, epoch_progress=100%, train_loss=-9.469e+03, last_val_loss=-6.700e+03, best_epoch=943, best_loss=-6.745e+03]\n",
            "1000it [00:23, 42.71it/s, epoch_progress=100%, train_loss=-8.906e+03, last_val_loss=-6.388e+03, best_epoch=962, best_loss=-6.421e+03]\n",
            "1000it [00:23, 42.59it/s, epoch_progress=100%, train_loss=-9.308e+03, last_val_loss=-6.610e+03, best_epoch=990, best_loss=-6.641e+03]\n",
            "1000it [00:23, 42.87it/s, epoch_progress=100%, train_loss=-9.891e+03, last_val_loss=-6.677e+03, best_epoch=968, best_loss=-6.717e+03]\n",
            "102it [00:02, 43.39it/s, epoch_progress=100%, train_loss=-8.363e+03, last_val_loss=-6.163e+03, best_epoch=2, best_loss=-6.176e+03]\n",
            " 47%|████▋     | 7/15 [16:41<18:42, 140.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 6\n",
            "Meta Train Error 2.597676932811737\n",
            "Meta Train Accuracy 0.18125000409781933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1000it [00:23, 43.12it/s, epoch_progress=100%, train_loss=-1.050e+04, last_val_loss=-7.492e+03, best_epoch=994, best_loss=-7.538e+03]\n",
            "1000it [00:23, 42.73it/s, epoch_progress=100%, train_loss=-1.051e+04, last_val_loss=-6.596e+03, best_epoch=997, best_loss=-6.636e+03]\n",
            "1000it [00:23, 42.45it/s, epoch_progress=100%, train_loss=-9.925e+03, last_val_loss=-7.091e+03, best_epoch=990, best_loss=-7.114e+03]\n",
            "1000it [00:23, 42.19it/s, epoch_progress=100%, train_loss=-1.008e+04, last_val_loss=-7.011e+03, best_epoch=996, best_loss=-7.044e+03]\n",
            "1000it [00:23, 42.59it/s, epoch_progress=100%, train_loss=-9.944e+03, last_val_loss=-7.709e+03, best_epoch=995, best_loss=-7.723e+03]\n",
            "1000it [00:23, 42.37it/s, epoch_progress=100%, train_loss=-1.025e+04, last_val_loss=-7.086e+03, best_epoch=990, best_loss=-7.123e+03]\n",
            "1000it [00:23, 42.53it/s, epoch_progress=100%, train_loss=-8.590e+03, last_val_loss=-6.117e+03, best_epoch=1000, best_loss=-6.117e+03]\n",
            "1000it [00:23, 42.58it/s, epoch_progress=100%, train_loss=-9.759e+03, last_val_loss=-7.060e+03, best_epoch=975, best_loss=-7.108e+03]\n",
            " 53%|█████▎    | 8/15 [19:50<18:11, 155.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 7\n",
            "Meta Train Error 2.097398415207863\n",
            "Meta Train Accuracy 0.21562500298023224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "103it [00:02, 43.91it/s, epoch_progress=100%, train_loss=-9.092e+03, last_val_loss=-6.470e+03, best_epoch=3, best_loss=-6.508e+03]\n",
            "1000it [00:23, 42.79it/s, epoch_progress=100%, train_loss=-1.226e+04, last_val_loss=-7.914e+03, best_epoch=989, best_loss=-8.006e+03]\n",
            "1000it [00:23, 43.00it/s, epoch_progress=100%, train_loss=-9.744e+03, last_val_loss=-7.025e+03, best_epoch=989, best_loss=-7.031e+03]\n",
            "1000it [00:23, 42.98it/s, epoch_progress=100%, train_loss=-9.571e+03, last_val_loss=-8.032e+03, best_epoch=1000, best_loss=-8.032e+03]\n",
            "1000it [00:23, 42.75it/s, epoch_progress=100%, train_loss=-1.042e+04, last_val_loss=-7.154e+03, best_epoch=961, best_loss=-7.306e+03]\n",
            "1000it [00:23, 42.51it/s, epoch_progress=100%, train_loss=-9.458e+03, last_val_loss=-8.064e+03, best_epoch=1000, best_loss=-8.064e+03]\n",
            "104it [00:02, 43.45it/s, epoch_progress=100%, train_loss=-9.086e+03, last_val_loss=-5.868e+03, best_epoch=4, best_loss=-5.915e+03]\n",
            "104it [00:02, 43.76it/s, epoch_progress=100%, train_loss=-8.189e+03, last_val_loss=-4.602e+03, best_epoch=4, best_loss=-4.649e+03]\n",
            " 60%|██████    | 9/15 [21:55<14:37, 146.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 8\n",
            "Meta Train Error 2.125116318464279\n",
            "Meta Train Accuracy 0.20312500558793545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "107it [00:02, 42.67it/s, epoch_progress=100%, train_loss=-8.504e+03, last_val_loss=-5.530e+03, best_epoch=7, best_loss=-5.561e+03]\n",
            "1000it [00:23, 42.43it/s, epoch_progress=100%, train_loss=-1.059e+04, last_val_loss=-7.138e+03, best_epoch=965, best_loss=-7.188e+03]\n",
            "1000it [00:23, 42.49it/s, epoch_progress=100%, train_loss=-9.033e+03, last_val_loss=-5.732e+03, best_epoch=993, best_loss=-5.777e+03]\n",
            "596it [00:13, 43.23it/s, epoch_progress=100%, train_loss=-1.103e+04, last_val_loss=-6.905e+03, best_epoch=496, best_loss=-7.041e+03]\n",
            "1000it [00:23, 42.96it/s, epoch_progress=100%, train_loss=-8.820e+03, last_val_loss=-6.923e+03, best_epoch=1000, best_loss=-6.923e+03]\n",
            "1000it [00:23, 42.62it/s, epoch_progress=100%, train_loss=-9.651e+03, last_val_loss=-7.042e+03, best_epoch=983, best_loss=-7.083e+03]\n",
            "1000it [00:23, 42.07it/s, epoch_progress=100%, train_loss=-9.276e+03, last_val_loss=-7.344e+03, best_epoch=1000, best_loss=-7.344e+03]\n",
            "1000it [00:23, 42.22it/s, epoch_progress=100%, train_loss=-1.068e+04, last_val_loss=-6.765e+03, best_epoch=983, best_loss=-6.904e+03]\n",
            " 67%|██████▋   | 10/15 [24:34<12:30, 150.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 9\n",
            "Meta Train Error 2.057040199637413\n",
            "Meta Train Accuracy 0.23125000298023224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1000it [00:23, 42.51it/s, epoch_progress=100%, train_loss=-9.908e+03, last_val_loss=-7.845e+03, best_epoch=999, best_loss=-7.860e+03]\n",
            "1000it [00:23, 42.01it/s, epoch_progress=100%, train_loss=-1.015e+04, last_val_loss=-7.768e+03, best_epoch=981, best_loss=-7.806e+03]\n",
            "105it [00:02, 42.21it/s, epoch_progress=100%, train_loss=-9.486e+03, last_val_loss=-6.273e+03, best_epoch=5, best_loss=-6.310e+03]\n",
            "1000it [00:23, 42.23it/s, epoch_progress=100%, train_loss=-1.117e+04, last_val_loss=-8.241e+03, best_epoch=994, best_loss=-8.318e+03]\n",
            "111it [00:02, 41.58it/s, epoch_progress=100%, train_loss=-8.833e+03, last_val_loss=-4.937e+03, best_epoch=11, best_loss=-4.950e+03]\n",
            "1000it [00:23, 41.84it/s, epoch_progress=100%, train_loss=-9.893e+03, last_val_loss=-7.776e+03, best_epoch=1000, best_loss=-7.776e+03]\n",
            "1000it [00:23, 41.72it/s, epoch_progress=100%, train_loss=-1.066e+04, last_val_loss=-6.963e+03, best_epoch=968, best_loss=-7.007e+03]\n",
            "1000it [00:24, 40.11it/s, epoch_progress=100%, train_loss=-1.075e+04, last_val_loss=-8.209e+03, best_epoch=984, best_loss=-8.234e+03]\n",
            " 73%|███████▎  | 11/15 [27:04<10:00, 150.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 10\n",
            "Meta Train Error 2.1146217733621597\n",
            "Meta Train Accuracy 0.2031250037252903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1000it [00:24, 41.36it/s, epoch_progress=100%, train_loss=-1.011e+04, last_val_loss=-6.399e+03, best_epoch=980, best_loss=-6.496e+03]\n",
            "1000it [00:23, 43.13it/s, epoch_progress=100%, train_loss=-9.139e+03, last_val_loss=-6.450e+03, best_epoch=989, best_loss=-6.460e+03]\n",
            "103it [00:02, 43.84it/s, epoch_progress=100%, train_loss=-9.371e+03, last_val_loss=-5.712e+03, best_epoch=3, best_loss=-5.784e+03]\n",
            "107it [00:02, 43.54it/s, epoch_progress=100%, train_loss=-8.937e+03, last_val_loss=-5.807e+03, best_epoch=7, best_loss=-5.820e+03]\n",
            "1000it [00:23, 42.61it/s, epoch_progress=100%, train_loss=-1.116e+04, last_val_loss=-7.322e+03, best_epoch=994, best_loss=-7.399e+03]\n",
            "1000it [00:23, 42.64it/s, epoch_progress=100%, train_loss=-1.024e+04, last_val_loss=-7.182e+03, best_epoch=998, best_loss=-7.206e+03]\n",
            "434it [00:10, 42.51it/s, epoch_progress=100%, train_loss=-8.727e+03, last_val_loss=-5.872e+03, best_epoch=334, best_loss=-5.925e+03]\n",
            "1000it [00:23, 42.59it/s, epoch_progress=100%, train_loss=-8.995e+03, last_val_loss=-6.640e+03, best_epoch=994, best_loss=-6.679e+03]\n",
            " 80%|████████  | 12/15 [29:18<07:15, 145.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 11\n",
            "Meta Train Error 2.059902861714363\n",
            "Meta Train Accuracy 0.20000000298023224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1000it [00:23, 43.40it/s, epoch_progress=100%, train_loss=-9.408e+03, last_val_loss=-6.396e+03, best_epoch=975, best_loss=-6.400e+03]\n",
            "1000it [00:23, 42.70it/s, epoch_progress=100%, train_loss=-9.511e+03, last_val_loss=-6.638e+03, best_epoch=997, best_loss=-6.638e+03]\n",
            "1000it [00:23, 42.15it/s, epoch_progress=100%, train_loss=-9.929e+03, last_val_loss=-6.970e+03, best_epoch=990, best_loss=-7.029e+03]\n",
            "1000it [00:23, 42.74it/s, epoch_progress=100%, train_loss=-1.067e+04, last_val_loss=-7.237e+03, best_epoch=997, best_loss=-7.264e+03]\n",
            "1000it [00:23, 42.84it/s, epoch_progress=100%, train_loss=-8.382e+03, last_val_loss=-6.265e+03, best_epoch=1000, best_loss=-6.265e+03]\n",
            "1000it [00:23, 42.26it/s, epoch_progress=100%, train_loss=-1.003e+04, last_val_loss=-7.529e+03, best_epoch=997, best_loss=-7.541e+03]\n",
            "1000it [00:23, 42.47it/s, epoch_progress=100%, train_loss=-8.817e+03, last_val_loss=-7.333e+03, best_epoch=1000, best_loss=-7.333e+03]\n",
            "1000it [00:23, 42.33it/s, epoch_progress=100%, train_loss=-9.959e+03, last_val_loss=-7.418e+03, best_epoch=994, best_loss=-7.460e+03]\n",
            " 87%|████████▋ | 13/15 [32:27<05:17, 158.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 12\n",
            "Meta Train Error 2.052701860666275\n",
            "Meta Train Accuracy 0.1781250024214387\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "260it [00:06, 42.06it/s, epoch_progress=100%, train_loss=-9.997e+03, last_val_loss=-5.867e+03, best_epoch=160, best_loss=-5.912e+03]\n",
            "1000it [00:23, 42.85it/s, epoch_progress=100%, train_loss=-8.002e+03, last_val_loss=-6.105e+03, best_epoch=977, best_loss=-6.150e+03]\n",
            "1000it [00:23, 42.65it/s, epoch_progress=100%, train_loss=-9.803e+03, last_val_loss=-7.151e+03, best_epoch=995, best_loss=-7.207e+03]\n",
            "1000it [00:23, 42.45it/s, epoch_progress=100%, train_loss=-1.062e+04, last_val_loss=-8.488e+03, best_epoch=994, best_loss=-8.502e+03]\n",
            "103it [00:02, 43.39it/s, epoch_progress=100%, train_loss=-7.789e+03, last_val_loss=-5.637e+03, best_epoch=3, best_loss=-5.697e+03]\n",
            "1000it [00:23, 42.48it/s, epoch_progress=100%, train_loss=-1.024e+04, last_val_loss=-7.910e+03, best_epoch=999, best_loss=-7.913e+03]\n",
            "1000it [00:23, 42.73it/s, epoch_progress=100%, train_loss=-9.386e+03, last_val_loss=-6.915e+03, best_epoch=989, best_loss=-6.937e+03]\n",
            "1000it [00:23, 42.55it/s, epoch_progress=100%, train_loss=-9.123e+03, last_val_loss=-6.290e+03, best_epoch=961, best_loss=-6.341e+03]\n",
            " 93%|█████████▎| 14/15 [34:58<02:36, 156.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 13\n",
            "Meta Train Error 1.97226083278656\n",
            "Meta Train Accuracy 0.17812500335276127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1000it [00:23, 43.16it/s, epoch_progress=100%, train_loss=-1.006e+04, last_val_loss=-6.614e+03, best_epoch=998, best_loss=-6.651e+03]\n",
            "1000it [00:23, 42.89it/s, epoch_progress=100%, train_loss=-1.023e+04, last_val_loss=-7.981e+03, best_epoch=998, best_loss=-8.022e+03]\n",
            "1000it [00:23, 42.42it/s, epoch_progress=100%, train_loss=-8.657e+03, last_val_loss=-7.054e+03, best_epoch=1000, best_loss=-7.054e+03]\n",
            "1000it [00:23, 42.86it/s, epoch_progress=100%, train_loss=-1.078e+04, last_val_loss=-8.029e+03, best_epoch=992, best_loss=-8.059e+03]\n",
            "1000it [00:23, 42.19it/s, epoch_progress=100%, train_loss=-1.008e+04, last_val_loss=-6.420e+03, best_epoch=988, best_loss=-6.453e+03]\n",
            "1000it [00:23, 42.43it/s, epoch_progress=100%, train_loss=-1.160e+04, last_val_loss=-8.741e+03, best_epoch=999, best_loss=-8.747e+03]\n",
            "1000it [00:23, 42.07it/s, epoch_progress=100%, train_loss=-1.080e+04, last_val_loss=-7.353e+03, best_epoch=988, best_loss=-7.396e+03]\n",
            "106it [00:02, 41.20it/s, epoch_progress=100%, train_loss=-9.595e+03, last_val_loss=-6.211e+03, best_epoch=6, best_loss=-6.237e+03]\n",
            "100%|██████████| 15/15 [37:46<00:00, 151.11s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 14\n",
            "Meta Train Error 2.00375896692276\n",
            "Meta Train Accuracy 0.20000000623986125\n",
            "Mean accuracy/loss, stddev, and confidence intervals\n",
            "(0.5512083456323793, 0.07986706701169034, 0.006390696340089533)\n",
            "0.2750000078231096\n",
            "0.800000011920929\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DW7wUN2UT8s"
      },
      "source": [
        "**Summary of EXP 1**\n",
        "---\n",
        "\n",
        "original code from stage 1 with 400 generated images instead of 1 shot per class and 15 iterations\n",
        "Flow of single batch norm layer and single MADE layer\n",
        "\n",
        "* **Standard MAML**\n",
        "  * not tested\n",
        "---\n",
        "* **with following flow**\n",
        "\n",
        "  * Mean accuracy/loss, stddev, and confidence intervals\n",
        "  *(0.5434166772446285, 0.10080092526546676, 0.008065753861693276)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvY66M5dg1IS",
        "cellView": "form",
        "outputId": "3254dc46-dd7a-4479-8b2f-44934749c5d3"
      },
      "source": [
        "#@title EXP 1 original code from stage 1 with 400 generated images instead of 1 shot per class and 15 iterations  \n",
        "\n",
        "#@markdown Flow of single batch norm layer and single MADE layer\n",
        "\n",
        "#@markdown -----\n",
        "\n",
        "#@markdown Mean accuracy/loss, stddev, and confidence intervals\n",
        "\n",
        "#@markdown (0.5434166772446285, 0.10080092526546676, 0.008065753861693276)\n",
        "\n",
        "#@markdown min accuracy: 0.27500000409781933\n",
        "\n",
        "#@markdown max accuracy: 0.8250000067055225\n",
        "\n",
        "def accuracy(predictions, targets):\n",
        "    predictions = predictions.argmax(dim=1).view(targets.shape)\n",
        "    return (predictions == targets).sum().float() / targets.size(0)\n",
        "\n",
        "\n",
        "def fast_adapt(batch, learner, loss, adaptation_steps, shots, ways, device):\n",
        "    data, labels = batch\n",
        "    # print(\"data:  \",data.shape)\n",
        "    data, labels = data.to(device), labels.to(device, dtype=torch.int64)\n",
        "    # Separate data into adaptation/evalutation sets\n",
        "    adaptation_indices = np.zeros(data.size(0), dtype=bool)\n",
        "    adaptation_indices[np.arange(shots*ways) * 2] = True\n",
        "    evaluation_indices = torch.from_numpy(~adaptation_indices)\n",
        "    adaptation_indices = torch.from_numpy(adaptation_indices)\n",
        "    adaptation_data, adaptation_labels = data[adaptation_indices], labels[adaptation_indices]\n",
        "    evaluation_data, evaluation_labels = data[evaluation_indices], labels[evaluation_indices]\n",
        "\n",
        "    # Adapt the model\n",
        "    for step in range(adaptation_steps):\n",
        "        train_error = loss(learner(adaptation_data), adaptation_labels)\n",
        "        learner.adapt(train_error)\n",
        "\n",
        "\n",
        "    # Evaluate the adapted model\n",
        "    predictions = learner(evaluation_data)\n",
        "    valid_error = loss(predictions, evaluation_labels)\n",
        "    valid_accuracy = accuracy(predictions, evaluation_labels)\n",
        "    return valid_error, valid_accuracy\n",
        "\n",
        "\n",
        "def fast_adapt_train(batch, learner, loss, adaptation_steps, shots, ways, device):\n",
        "\n",
        "    data, labels = batch\n",
        "    data, labels = data.to(device), labels.to(device, dtype=torch.int64)\n",
        "    # Separate data into adaptation/evalutation sets\n",
        "    indices = np.random.permutation(data.shape[0])\n",
        "    \n",
        "    adaptation_indices = indices[:360]\n",
        "    evaluation_indices = indices[360:]\n",
        "    adaptation_data, adaptation_labels = data[adaptation_indices], labels[adaptation_indices]\n",
        "    evaluation_data, evaluation_labels = data[evaluation_indices], labels[evaluation_indices]\n",
        "    # print(adaptation_data.shape)\n",
        "    # print(\"modified version\")\n",
        "    # Adapt the model\n",
        "    for step in range(adaptation_steps):\n",
        "        train_error = loss(learner(adaptation_data), adaptation_labels)\n",
        "        learner.adapt(train_error)\n",
        "\n",
        "\n",
        "    # Evaluate the adapted model\n",
        "    predictions = learner(evaluation_data)\n",
        "    valid_error = loss(predictions, evaluation_labels)\n",
        "    valid_accuracy = accuracy(predictions, evaluation_labels)\n",
        "    return valid_error, valid_accuracy\n",
        "\n",
        "    # Evaluate the adapted model\n",
        "    predictions = learner(evaluation_data)\n",
        "    valid_error = loss(predictions, evaluation_labels)\n",
        "    valid_accuracy = accuracy(predictions, evaluation_labels)\n",
        "    return valid_error, valid_accuracy\n",
        "\n",
        "def train_flow (trainX ,cond_train , device):\n",
        "\n",
        "  \n",
        "  # trainX has a shape of (count , channel , pixles,pixles)\n",
        "  \n",
        "\n",
        "  trainX = torch.flatten(trainX,1,-1)\n",
        "  # valX = torch.flatten(valX , 1,-1)\n",
        "  dim=trainX.shape[1]\n",
        "  \n",
        "  # print(cond_train)\n",
        "  cond_train = torch.nn.functional.one_hot(cond_train)\n",
        "  # cond_val   = torch.nn.functional.one_hot(cond_val) \n",
        "  # print(cond_train)\n",
        "  cond_dim = cond_train.size(1)\n",
        "  flow = Sequential(      \n",
        "\n",
        "# very slow in sampling \n",
        "    inv_flow(Sigmoid)(dim=dim),\n",
        "    BatchNorm(dim=dim),\n",
        "    # MADE(DSF(dim=dim), cond_dim=cond_dim),\n",
        "    # Affine(dim=dim),  \n",
        "\n",
        "      # BatchNorm(dim=dim),\n",
        "      MADE(AffineTransformer(dim=dim) , cond_dim=cond_dim),\n",
        "  ).to(device)\n",
        "\n",
        "\n",
        "  train_losses, val_losses = train(flow, trainX, trainX ,cond_train=cond_train, cond_val=cond_train , patience=100 ,batch_size=8,n_epochs=1000)\n",
        " \n",
        "  test_labels = np.random.choice(5, size=(400))\n",
        "  test_labels = torch.from_numpy(test_labels)\n",
        "  test_cond = torch.nn.functional.one_hot(test_labels)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    train_data = flow.sample(400,cond=test_cond.to(device)).cpu()\n",
        "\n",
        "  # return train_data, train_losses , val_losses , mean , var\n",
        "  return torch.reshape(train_data , (400,1,28,28)) , test_labels\n",
        "\n",
        "\n",
        "\n",
        "ways=5\n",
        "shots=1\n",
        "meta_lr=0.003\n",
        "fast_lr=0.5\n",
        "meta_batch_size=8\n",
        "adaptation_steps=1\n",
        "num_iterations=15\n",
        "cuda=True\n",
        "# seed=42\n",
        "# Load train/validation/test tasksets using the benchmark interface\n",
        "tasksets = l2l.vision.benchmarks.get_tasksets('omniglot',\n",
        "                                                  train_ways=ways,\n",
        "                                                  train_samples=2*shots,\n",
        "                                                  test_ways=ways,\n",
        "                                                  test_samples=2*shots,\n",
        "                                                  num_tasks=20000,\n",
        "                                                  root='~/data',\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "device = torch.device('cpu')\n",
        "if cuda:\n",
        "  # torch.cuda.manual_seed(seed)\n",
        "  device = torch.device('cuda')\n",
        "\n",
        "# Create model\n",
        "# model = l2l.vision.models.OmniglotCNN(ways)\n",
        "model = l2l.vision.models.OmniglotFC(28 ** 2, ways)\n",
        "model.to(device)\n",
        "maml = l2l.algorithms.MAML(model, lr=fast_lr, first_order=False)\n",
        "opt = optim.Adam(maml.parameters(), meta_lr)\n",
        "loss = nn.CrossEntropyLoss(reduction='mean')\n",
        "\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "for iteration in tqdm(range(num_iterations)):\n",
        "    opt.zero_grad()\n",
        "    meta_train_error = 0.0\n",
        "    meta_train_accuracy = 0.0\n",
        "    meta_valid_error = 0.0\n",
        "    meta_valid_accuracy = 0.0\n",
        "\n",
        "    for task in range(meta_batch_size):\n",
        "        # Compute meta-training loss\n",
        "        # learner = maml.clone()\n",
        "\n",
        "        # generate batch the batch contains # ways*shots , channels , img size  and labels \n",
        "        train_batch = tasksets.train.sample()\n",
        "        val_batch = tasksets.validation.sample()\n",
        "\n",
        "        # split batch based on classes in labels then   labels.split(int(data.shape[0]/ways))\n",
        "        train_data, train_labels = train_batch\n",
        "        val_data , val_labels= val_batch\n",
        "\n",
        "        \n",
        "        train_data_generator ,train_lable_generator  = train_flow (train_data ,train_labels  , device)\n",
        "\n",
        "        # train_data_generator = torch.cat(train_data_generator)\n",
        "        # train_lable_generator = torch.cat(train_lable_generator)\n",
        "        \n",
        "        batch = [train_data_generator ,train_lable_generator]\n",
        "\n",
        "        learner = maml.clone()            \n",
        "        \n",
        "        evaluation_error, evaluation_accuracy = fast_adapt_train(batch,\n",
        "                                                            learner,\n",
        "                                                            loss,\n",
        "                                                            adaptation_steps,\n",
        "                                                            shots,\n",
        "                                                            ways,\n",
        "                                                            device)\n",
        "        evaluation_error.backward()\n",
        "        meta_train_error += evaluation_error.item()\n",
        "        meta_train_accuracy += evaluation_accuracy.item()\n",
        "\n",
        "# ''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
        "\n",
        "        # # Compute meta-validation loss\n",
        "        # batch = tasksets.validation.sample()\n",
        "        \n",
        "        # learner = maml.clone()\n",
        "        # evaluation_error, evaluation_accuracy = fast_adapt(batch,learner,loss,adaptation_steps,shots,ways,\n",
        "        #                                                     device)\n",
        "        # meta_valid_error += evaluation_error.item()\n",
        "        # meta_valid_accuracy += evaluation_accuracy.item()\n",
        "\n",
        "    # Print some metrics\n",
        "    print('\\n')\n",
        "    print('Iteration', iteration)\n",
        "    print('Meta Train Error', meta_train_error / meta_batch_size)\n",
        "    print('Meta Train Accuracy', meta_train_accuracy / meta_batch_size)\n",
        "    # print('Meta Valid Error', meta_valid_error / meta_batch_size)\n",
        "    # print('Meta Valid Accuracy', meta_valid_accuracy / meta_batch_size)\n",
        "\n",
        "    # Average the accumulated gradients and optimize\n",
        "    for p in maml.parameters():\n",
        "        p.grad.data.mul_(1.0 / meta_batch_size)\n",
        "    opt.step()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:281: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "105it [00:16,  6.29it/s, epoch_progress=100%, train_loss=-9.641e+03, last_val_loss=+1.381e+05, best_epoch=5, best_loss=-6.126e+03]\n",
            "105it [00:15,  6.66it/s, epoch_progress=100%, train_loss=-1.221e+04, last_val_loss=+4.146e+05, best_epoch=5, best_loss=-7.486e+03]\n",
            "105it [00:16,  6.29it/s, epoch_progress=100%, train_loss=-1.143e+04, last_val_loss=+2.669e+05, best_epoch=5, best_loss=-6.419e+03]\n",
            "106it [00:17,  6.05it/s, epoch_progress=100%, train_loss=-1.197e+04, last_val_loss=+2.994e+05, best_epoch=6, best_loss=-5.869e+03]\n",
            "104it [00:14,  6.94it/s, epoch_progress=100%, train_loss=-1.110e+04, last_val_loss=+5.896e+05, best_epoch=4, best_loss=-6.736e+03]\n",
            "107it [00:18,  5.83it/s, epoch_progress=100%, train_loss=-9.927e+03, last_val_loss=+1.031e+05, best_epoch=7, best_loss=-5.997e+03]\n",
            "104it [00:15,  6.56it/s, epoch_progress=100%, train_loss=-1.013e+04, last_val_loss=+1.791e+05, best_epoch=4, best_loss=-5.866e+03]\n",
            "104it [00:15,  6.55it/s, epoch_progress=100%, train_loss=-1.132e+04, last_val_loss=+1.601e+05, best_epoch=4, best_loss=-6.457e+03]\n",
            "  7%|▋         | 1/15 [05:23<1:15:35, 323.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 0\n",
            "Meta Train Error 1.616212084889412\n",
            "Meta Train Accuracy 0.20625000447034836\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "106it [00:16,  6.36it/s, epoch_progress=100%, train_loss=-1.080e+04, last_val_loss=+1.639e+05, best_epoch=6, best_loss=-6.650e+03]\n",
            "104it [00:14,  6.96it/s, epoch_progress=100%, train_loss=-1.113e+04, last_val_loss=+4.536e+05, best_epoch=4, best_loss=-6.677e+03]\n",
            "104it [00:15,  6.61it/s, epoch_progress=100%, train_loss=-1.188e+04, last_val_loss=+4.196e+05, best_epoch=4, best_loss=-6.680e+03]\n",
            "106it [00:16,  6.38it/s, epoch_progress=100%, train_loss=-1.077e+04, last_val_loss=+2.781e+05, best_epoch=6, best_loss=-5.766e+03]\n",
            "107it [00:15,  7.07it/s, epoch_progress=100%, train_loss=-1.015e+04, last_val_loss=+9.564e+04, best_epoch=7, best_loss=-5.380e+03]\n",
            "103it [00:14,  6.88it/s, epoch_progress=100%, train_loss=-1.073e+04, last_val_loss=+2.696e+05, best_epoch=3, best_loss=-6.607e+03]\n",
            "105it [00:15,  6.64it/s, epoch_progress=100%, train_loss=-1.341e+04, last_val_loss=+4.837e+05, best_epoch=5, best_loss=-7.059e+03]\n",
            "105it [00:16,  6.30it/s, epoch_progress=100%, train_loss=-1.037e+04, last_val_loss=+3.239e+05, best_epoch=5, best_loss=-5.818e+03]\n",
            " 13%|█▎        | 2/15 [10:42<1:09:30, 320.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 1\n",
            "Meta Train Error 1.6119858175516129\n",
            "Meta Train Accuracy 0.22812500782310963\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "105it [00:15,  6.63it/s, epoch_progress=100%, train_loss=-1.115e+04, last_val_loss=+3.975e+05, best_epoch=5, best_loss=-7.259e+03]\n",
            "107it [00:16,  6.44it/s, epoch_progress=100%, train_loss=-9.436e+03, last_val_loss=+1.355e+05, best_epoch=7, best_loss=-6.569e+03]\n",
            "105it [00:14,  7.02it/s, epoch_progress=100%, train_loss=-1.274e+04, last_val_loss=+1.325e+05, best_epoch=5, best_loss=-5.620e+03]\n",
            "105it [00:14,  7.05it/s, epoch_progress=100%, train_loss=-1.181e+04, last_val_loss=+4.235e+05, best_epoch=5, best_loss=-6.002e+03]\n",
            "105it [00:14,  7.06it/s, epoch_progress=100%, train_loss=-1.127e+04, last_val_loss=+1.477e+05, best_epoch=5, best_loss=-6.784e+03]\n",
            "105it [00:16,  6.32it/s, epoch_progress=100%, train_loss=-1.192e+04, last_val_loss=+3.274e+05, best_epoch=5, best_loss=-6.831e+03]\n",
            "103it [00:14,  6.92it/s, epoch_progress=100%, train_loss=-9.675e+03, last_val_loss=+1.430e+05, best_epoch=3, best_loss=-6.605e+03]\n",
            "106it [00:16,  6.42it/s, epoch_progress=100%, train_loss=-1.256e+04, last_val_loss=+3.405e+05, best_epoch=6, best_loss=-7.157e+03]\n",
            " 20%|██        | 3/15 [15:59<1:03:50, 319.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 2\n",
            "Meta Train Error 1.6097581833600998\n",
            "Meta Train Accuracy 0.24375000596046448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "105it [00:15,  6.69it/s, epoch_progress=100%, train_loss=-1.037e+04, last_val_loss=+1.065e+05, best_epoch=5, best_loss=-5.737e+03]\n",
            "105it [00:16,  6.31it/s, epoch_progress=100%, train_loss=-1.237e+04, last_val_loss=+2.461e+05, best_epoch=5, best_loss=-6.228e+03]\n",
            "105it [00:15,  6.67it/s, epoch_progress=100%, train_loss=-1.071e+04, last_val_loss=+6.458e+04, best_epoch=5, best_loss=-5.803e+03]\n",
            "105it [00:15,  6.67it/s, epoch_progress=100%, train_loss=-1.063e+04, last_val_loss=+1.063e+05, best_epoch=5, best_loss=-6.090e+03]\n",
            "105it [00:16,  6.31it/s, epoch_progress=100%, train_loss=-1.086e+04, last_val_loss=+2.161e+05, best_epoch=5, best_loss=-6.457e+03]\n",
            "108it [00:16,  6.51it/s, epoch_progress=100%, train_loss=-9.047e+03, last_val_loss=+6.080e+04, best_epoch=8, best_loss=-5.439e+03]\n",
            "109it [00:16,  6.79it/s, epoch_progress=100%, train_loss=-1.188e+04, last_val_loss=+3.651e+05, best_epoch=9, best_loss=-6.806e+03]\n",
            "103it [00:14,  6.87it/s, epoch_progress=100%, train_loss=-1.080e+04, last_val_loss=+3.666e+05, best_epoch=3, best_loss=-7.020e+03]\n",
            " 27%|██▋       | 4/15 [21:20<58:36, 319.66s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 3\n",
            "Meta Train Error 1.630272164940834\n",
            "Meta Train Accuracy 0.1562500037252903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "107it [00:16,  6.45it/s, epoch_progress=100%, train_loss=-1.086e+04, last_val_loss=+8.685e+04, best_epoch=7, best_loss=-5.283e+03]\n",
            "105it [00:15,  6.66it/s, epoch_progress=100%, train_loss=-1.235e+04, last_val_loss=+1.861e+05, best_epoch=5, best_loss=-6.441e+03]\n",
            "106it [00:16,  6.36it/s, epoch_progress=100%, train_loss=-1.014e+04, last_val_loss=+2.059e+05, best_epoch=6, best_loss=-6.488e+03]\n",
            "105it [00:15,  6.67it/s, epoch_progress=100%, train_loss=-1.262e+04, last_val_loss=+2.851e+05, best_epoch=5, best_loss=-6.970e+03]\n",
            "105it [00:16,  6.32it/s, epoch_progress=100%, train_loss=-1.186e+04, last_val_loss=+3.597e+05, best_epoch=5, best_loss=-6.677e+03]\n",
            "104it [00:15,  6.63it/s, epoch_progress=100%, train_loss=-9.240e+03, last_val_loss=+8.110e+04, best_epoch=4, best_loss=-5.684e+03]\n",
            "105it [00:15,  6.67it/s, epoch_progress=100%, train_loss=-1.211e+04, last_val_loss=+3.384e+05, best_epoch=5, best_loss=-6.712e+03]\n",
            "105it [00:15,  6.65it/s, epoch_progress=100%, train_loss=-1.091e+04, last_val_loss=+8.782e+04, best_epoch=5, best_loss=-6.119e+03]\n",
            " 33%|███▎      | 5/15 [26:41<53:21, 320.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 4\n",
            "Meta Train Error 1.6076076179742813\n",
            "Meta Train Accuracy 0.21875000558793545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "105it [00:16,  6.32it/s, epoch_progress=100%, train_loss=-1.148e+04, last_val_loss=+1.762e+05, best_epoch=5, best_loss=-6.155e+03]\n",
            "104it [00:14,  7.24it/s, epoch_progress=100%, train_loss=-1.211e+04, last_val_loss=+1.818e+05, best_epoch=4, best_loss=-6.478e+03]\n",
            "108it [00:16,  6.52it/s, epoch_progress=100%, train_loss=-1.227e+04, last_val_loss=+2.051e+05, best_epoch=8, best_loss=-7.243e+03]\n",
            "102it [00:14,  7.21it/s, epoch_progress=100%, train_loss=-1.227e+04, last_val_loss=+9.593e+04, best_epoch=2, best_loss=-6.745e+03]\n",
            "104it [00:14,  7.02it/s, epoch_progress=100%, train_loss=-1.048e+04, last_val_loss=+1.587e+05, best_epoch=4, best_loss=-5.818e+03]\n",
            "107it [00:17,  6.14it/s, epoch_progress=100%, train_loss=-1.181e+04, last_val_loss=+2.342e+05, best_epoch=7, best_loss=-6.486e+03]\n",
            "105it [00:15,  6.96it/s, epoch_progress=100%, train_loss=-1.148e+04, last_val_loss=+1.170e+05, best_epoch=5, best_loss=-6.222e+03]\n",
            "105it [00:15,  6.66it/s, epoch_progress=100%, train_loss=-1.100e+04, last_val_loss=+1.930e+05, best_epoch=5, best_loss=-5.659e+03]\n",
            " 40%|████      | 6/15 [31:58<47:52, 319.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 5\n",
            "Meta Train Error 1.6088698208332062\n",
            "Meta Train Accuracy 0.2187500037252903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "106it [00:15,  6.78it/s, epoch_progress=100%, train_loss=-1.260e+04, last_val_loss=+5.198e+05, best_epoch=6, best_loss=-7.908e+03]\n",
            "105it [00:14,  7.06it/s, epoch_progress=100%, train_loss=-1.120e+04, last_val_loss=+2.528e+05, best_epoch=5, best_loss=-6.730e+03]\n",
            "105it [00:14,  7.00it/s, epoch_progress=100%, train_loss=-1.114e+04, last_val_loss=+5.982e+05, best_epoch=5, best_loss=-6.946e+03]\n",
            "103it [00:14,  6.96it/s, epoch_progress=100%, train_loss=-1.169e+04, last_val_loss=+2.107e+05, best_epoch=3, best_loss=-6.440e+03]\n",
            "105it [00:14,  7.03it/s, epoch_progress=100%, train_loss=-1.180e+04, last_val_loss=+2.367e+05, best_epoch=5, best_loss=-6.837e+03]\n",
            "106it [00:16,  6.39it/s, epoch_progress=100%, train_loss=-1.259e+04, last_val_loss=+2.702e+05, best_epoch=6, best_loss=-7.260e+03]\n",
            "105it [00:15,  6.69it/s, epoch_progress=100%, train_loss=-1.163e+04, last_val_loss=+2.960e+05, best_epoch=5, best_loss=-6.848e+03]\n",
            "107it [00:16,  6.44it/s, epoch_progress=100%, train_loss=-1.109e+04, last_val_loss=+1.559e+05, best_epoch=7, best_loss=-6.281e+03]\n",
            " 47%|████▋     | 7/15 [37:14<42:25, 318.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 6\n",
            "Meta Train Error 1.612065076828003\n",
            "Meta Train Accuracy 0.19687500409781933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "105it [00:16,  6.32it/s, epoch_progress=100%, train_loss=-1.200e+04, last_val_loss=+3.745e+05, best_epoch=5, best_loss=-7.066e+03]\n",
            "102it [00:14,  7.25it/s, epoch_progress=100%, train_loss=-1.160e+04, last_val_loss=+2.390e+05, best_epoch=2, best_loss=-6.190e+03]\n",
            "105it [00:14,  7.02it/s, epoch_progress=100%, train_loss=-1.116e+04, last_val_loss=+1.907e+05, best_epoch=5, best_loss=-6.159e+03]\n",
            "105it [00:15,  6.68it/s, epoch_progress=100%, train_loss=-1.099e+04, last_val_loss=+3.344e+05, best_epoch=5, best_loss=-6.621e+03]\n",
            "106it [00:16,  6.39it/s, epoch_progress=100%, train_loss=-1.086e+04, last_val_loss=+2.902e+05, best_epoch=6, best_loss=-6.508e+03]\n",
            "105it [00:14,  7.02it/s, epoch_progress=100%, train_loss=-1.241e+04, last_val_loss=+2.447e+05, best_epoch=5, best_loss=-7.094e+03]\n",
            "105it [00:16,  6.35it/s, epoch_progress=100%, train_loss=-1.095e+04, last_val_loss=+2.047e+05, best_epoch=5, best_loss=-6.440e+03]\n",
            "109it [00:16,  6.77it/s, epoch_progress=100%, train_loss=-9.996e+03, last_val_loss=+1.522e+05, best_epoch=9, best_loss=-5.522e+03]\n",
            " 53%|█████▎    | 8/15 [42:32<37:06, 318.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 7\n",
            "Meta Train Error 1.6155912578105927\n",
            "Meta Train Accuracy 0.1781250024214387\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "107it [00:16,  6.47it/s, epoch_progress=100%, train_loss=-1.059e+04, last_val_loss=+1.652e+05, best_epoch=7, best_loss=-5.783e+03]\n",
            "105it [00:16,  6.34it/s, epoch_progress=100%, train_loss=-1.261e+04, last_val_loss=+1.650e+05, best_epoch=5, best_loss=-5.586e+03]\n",
            "105it [00:15,  6.67it/s, epoch_progress=100%, train_loss=-1.081e+04, last_val_loss=+1.349e+05, best_epoch=5, best_loss=-6.176e+03]\n",
            "105it [00:15,  6.68it/s, epoch_progress=100%, train_loss=-1.096e+04, last_val_loss=+2.270e+05, best_epoch=5, best_loss=-6.968e+03]\n",
            "104it [00:14,  7.01it/s, epoch_progress=100%, train_loss=-1.130e+04, last_val_loss=+2.106e+05, best_epoch=4, best_loss=-6.332e+03]\n",
            "105it [00:14,  7.05it/s, epoch_progress=100%, train_loss=-1.092e+04, last_val_loss=+3.464e+05, best_epoch=5, best_loss=-6.992e+03]\n",
            "104it [00:14,  7.01it/s, epoch_progress=100%, train_loss=-1.130e+04, last_val_loss=+3.949e+05, best_epoch=4, best_loss=-7.054e+03]\n",
            "104it [00:15,  6.91it/s, epoch_progress=100%, train_loss=-1.234e+04, last_val_loss=+1.677e+05, best_epoch=4, best_loss=-6.708e+03]\n",
            " 60%|██████    | 9/15 [47:48<31:45, 317.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 8\n",
            "Meta Train Error 1.6293558180332184\n",
            "Meta Train Accuracy 0.14062500139698386\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "104it [00:15,  6.61it/s, epoch_progress=100%, train_loss=-1.257e+04, last_val_loss=+5.024e+05, best_epoch=4, best_loss=-7.429e+03]\n",
            "103it [00:14,  6.87it/s, epoch_progress=100%, train_loss=-1.205e+04, last_val_loss=+3.507e+05, best_epoch=3, best_loss=-6.772e+03]\n",
            "105it [00:16,  6.33it/s, epoch_progress=100%, train_loss=-1.035e+04, last_val_loss=+7.118e+04, best_epoch=5, best_loss=-5.096e+03]\n",
            "106it [00:16,  6.36it/s, epoch_progress=100%, train_loss=-1.040e+04, last_val_loss=+1.235e+05, best_epoch=6, best_loss=-5.669e+03]\n",
            "105it [00:16,  6.32it/s, epoch_progress=100%, train_loss=-1.130e+04, last_val_loss=+3.731e+05, best_epoch=5, best_loss=-6.783e+03]\n",
            "105it [00:15,  6.68it/s, epoch_progress=100%, train_loss=-1.085e+04, last_val_loss=+2.742e+05, best_epoch=5, best_loss=-6.825e+03]\n",
            "105it [00:14,  7.01it/s, epoch_progress=100%, train_loss=-1.008e+04, last_val_loss=+7.269e+04, best_epoch=5, best_loss=-5.429e+03]\n",
            "105it [00:15,  6.72it/s, epoch_progress=100%, train_loss=-1.251e+04, last_val_loss=+5.100e+05, best_epoch=5, best_loss=-7.712e+03]\n",
            " 67%|██████▋   | 10/15 [53:08<26:30, 318.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 9\n",
            "Meta Train Error 1.6092130094766617\n",
            "Meta Train Accuracy 0.19687500409781933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "105it [00:15,  6.69it/s, epoch_progress=100%, train_loss=-1.180e+04, last_val_loss=+2.583e+05, best_epoch=5, best_loss=-7.250e+03]\n",
            "105it [00:15,  6.70it/s, epoch_progress=100%, train_loss=-1.145e+04, last_val_loss=+2.299e+05, best_epoch=5, best_loss=-5.264e+03]\n",
            "105it [00:15,  6.69it/s, epoch_progress=100%, train_loss=-1.220e+04, last_val_loss=+4.624e+05, best_epoch=5, best_loss=-6.959e+03]\n",
            "102it [00:14,  7.21it/s, epoch_progress=100%, train_loss=-1.146e+04, last_val_loss=+5.169e+05, best_epoch=2, best_loss=-6.924e+03]\n",
            "106it [00:16,  6.40it/s, epoch_progress=100%, train_loss=-1.158e+04, last_val_loss=+2.489e+05, best_epoch=6, best_loss=-6.745e+03]\n",
            "104it [00:14,  6.99it/s, epoch_progress=100%, train_loss=-1.166e+04, last_val_loss=+1.657e+05, best_epoch=4, best_loss=-6.781e+03]\n",
            "106it [00:16,  6.36it/s, epoch_progress=100%, train_loss=-1.149e+04, last_val_loss=+1.418e+05, best_epoch=6, best_loss=-6.105e+03]\n",
            "105it [00:16,  6.34it/s, epoch_progress=100%, train_loss=-1.136e+04, last_val_loss=+1.941e+05, best_epoch=5, best_loss=-6.075e+03]\n",
            " 73%|███████▎  | 11/15 [58:26<21:12, 318.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 10\n",
            "Meta Train Error 1.6254547983407974\n",
            "Meta Train Accuracy 0.20937500335276127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "105it [00:15,  6.67it/s, epoch_progress=100%, train_loss=-1.115e+04, last_val_loss=+1.921e+05, best_epoch=5, best_loss=-6.793e+03]\n",
            "106it [00:15,  7.01it/s, epoch_progress=100%, train_loss=-1.251e+04, last_val_loss=+1.901e+05, best_epoch=6, best_loss=-7.051e+03]\n",
            "105it [00:15,  6.97it/s, epoch_progress=100%, train_loss=-1.111e+04, last_val_loss=+2.222e+05, best_epoch=5, best_loss=-6.414e+03]\n",
            "105it [00:15,  6.69it/s, epoch_progress=100%, train_loss=-1.165e+04, last_val_loss=+1.913e+05, best_epoch=5, best_loss=-6.491e+03]\n",
            "110it [00:18,  6.01it/s, epoch_progress=100%, train_loss=-1.030e+04, last_val_loss=+7.739e+04, best_epoch=10, best_loss=-6.157e+03]\n",
            "105it [00:15,  6.67it/s, epoch_progress=100%, train_loss=-1.127e+04, last_val_loss=+2.050e+05, best_epoch=5, best_loss=-6.394e+03]\n",
            "104it [00:15,  6.61it/s, epoch_progress=100%, train_loss=-1.106e+04, last_val_loss=+1.989e+05, best_epoch=4, best_loss=-6.129e+03]\n",
            "106it [00:16,  6.37it/s, epoch_progress=100%, train_loss=-1.219e+04, last_val_loss=+2.958e+05, best_epoch=6, best_loss=-6.831e+03]\n",
            " 80%|████████  | 12/15 [1:03:47<15:56, 318.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 11\n",
            "Meta Train Error 1.6253809332847595\n",
            "Meta Train Accuracy 0.17500000167638063\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "105it [00:16,  6.28it/s, epoch_progress=100%, train_loss=-1.186e+04, last_val_loss=+4.866e+05, best_epoch=5, best_loss=-7.415e+03]\n",
            "105it [00:15,  6.66it/s, epoch_progress=100%, train_loss=-1.210e+04, last_val_loss=+3.114e+05, best_epoch=5, best_loss=-7.420e+03]\n",
            "105it [00:16,  6.30it/s, epoch_progress=100%, train_loss=-9.833e+03, last_val_loss=+1.014e+05, best_epoch=5, best_loss=-5.599e+03]\n",
            "105it [00:16,  6.34it/s, epoch_progress=100%, train_loss=-1.204e+04, last_val_loss=+3.739e+05, best_epoch=5, best_loss=-6.891e+03]\n",
            "105it [00:16,  6.32it/s, epoch_progress=100%, train_loss=-1.232e+04, last_val_loss=+2.950e+05, best_epoch=5, best_loss=-7.175e+03]\n",
            "105it [00:15,  6.68it/s, epoch_progress=100%, train_loss=-1.119e+04, last_val_loss=+2.254e+05, best_epoch=5, best_loss=-6.452e+03]\n",
            "107it [00:15,  6.74it/s, epoch_progress=100%, train_loss=-1.059e+04, last_val_loss=+1.692e+05, best_epoch=7, best_loss=-6.028e+03]\n",
            "104it [00:15,  6.61it/s, epoch_progress=100%, train_loss=-1.009e+04, last_val_loss=+8.464e+04, best_epoch=4, best_loss=-5.540e+03]\n",
            " 87%|████████▋ | 13/15 [1:09:09<10:40, 320.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 12\n",
            "Meta Train Error 1.610784962773323\n",
            "Meta Train Accuracy 0.21250000409781933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "105it [00:15,  6.95it/s, epoch_progress=100%, train_loss=-1.130e+04, last_val_loss=+7.373e+04, best_epoch=5, best_loss=-6.591e+03]\n",
            "103it [00:14,  6.88it/s, epoch_progress=100%, train_loss=-1.309e+04, last_val_loss=+3.452e+05, best_epoch=3, best_loss=-7.502e+03]\n",
            "105it [00:15,  6.65it/s, epoch_progress=100%, train_loss=-1.134e+04, last_val_loss=+2.487e+05, best_epoch=5, best_loss=-6.862e+03]\n",
            "104it [00:15,  6.63it/s, epoch_progress=100%, train_loss=-1.079e+04, last_val_loss=+2.153e+05, best_epoch=4, best_loss=-6.597e+03]\n",
            "102it [00:14,  7.18it/s, epoch_progress=100%, train_loss=-1.114e+04, last_val_loss=+2.111e+05, best_epoch=2, best_loss=-5.955e+03]\n",
            "106it [00:16,  6.38it/s, epoch_progress=100%, train_loss=-1.107e+04, last_val_loss=+1.910e+05, best_epoch=6, best_loss=-6.812e+03]\n",
            "105it [00:15,  6.66it/s, epoch_progress=100%, train_loss=-1.126e+04, last_val_loss=+2.060e+05, best_epoch=5, best_loss=-6.572e+03]\n",
            "104it [00:15,  6.59it/s, epoch_progress=100%, train_loss=-1.269e+04, last_val_loss=+6.241e+05, best_epoch=4, best_loss=-7.435e+03]\n",
            " 93%|█████████▎| 14/15 [1:14:26<05:18, 318.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 13\n",
            "Meta Train Error 1.592513233423233\n",
            "Meta Train Accuracy 0.21875000558793545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "103it [00:14,  6.90it/s, epoch_progress=100%, train_loss=-1.304e+04, last_val_loss=+3.399e+05, best_epoch=3, best_loss=-7.629e+03]\n",
            "105it [00:15,  6.66it/s, epoch_progress=100%, train_loss=-1.208e+04, last_val_loss=+6.133e+05, best_epoch=5, best_loss=-6.916e+03]\n",
            "105it [00:15,  6.63it/s, epoch_progress=100%, train_loss=-1.214e+04, last_val_loss=+2.600e+05, best_epoch=5, best_loss=-7.211e+03]\n",
            "106it [00:15,  6.69it/s, epoch_progress=100%, train_loss=-9.933e+03, last_val_loss=+1.629e+05, best_epoch=6, best_loss=-6.697e+03]\n",
            "104it [00:14,  6.99it/s, epoch_progress=100%, train_loss=-1.120e+04, last_val_loss=+3.171e+05, best_epoch=4, best_loss=-6.939e+03]\n",
            "105it [00:15,  6.65it/s, epoch_progress=100%, train_loss=-1.270e+04, last_val_loss=+2.930e+05, best_epoch=5, best_loss=-7.124e+03]\n",
            "105it [00:15,  6.67it/s, epoch_progress=100%, train_loss=-1.322e+04, last_val_loss=+3.719e+05, best_epoch=5, best_loss=-7.621e+03]\n",
            "105it [00:16,  6.33it/s, epoch_progress=100%, train_loss=-1.276e+04, last_val_loss=+2.749e+05, best_epoch=5, best_loss=-7.658e+03]\n",
            "100%|██████████| 15/15 [1:19:44<00:00, 318.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Iteration 14\n",
            "Meta Train Error 1.620359867811203\n",
            "Meta Train Accuracy 0.22812500596046448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySCGoAzUg3fp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "c160f1fe-1c59-44b7-dc46-0cb423d8375f"
      },
      "source": [
        "#@title original code from stage 1 with 400 generated images instead of 1 shot per class\n",
        "acc_acuracy=[]\n",
        "iterations= 600\n",
        "for _ in range(iterations):\n",
        "  meta_test_error = 0.0\n",
        "  meta_test_accuracy = 0.0\n",
        "\n",
        "  for task in range(meta_batch_size):\n",
        "\n",
        "      # Compute meta-testing loss\n",
        "      learner = maml.clone()\n",
        "      batch = tasksets.test.sample()\n",
        "      evaluation_error, evaluation_accuracy = fast_adapt(batch,\n",
        "                                                          learner,\n",
        "                                                          loss,\n",
        "                                                          3,\n",
        "                                                          shots,\n",
        "                                                          ways,\n",
        "                                                          device)\n",
        "      meta_test_error += evaluation_error.item()\n",
        "      meta_test_accuracy += evaluation_accuracy.item()\n",
        "\n",
        "  # print('Meta Test Error', meta_test_error / meta_batch_size)\n",
        "  # print('Meta Test Accuracy', meta_test_accuracy / meta_batch_size)\n",
        "  acc_acuracy.append(meta_test_accuracy/meta_batch_size)\n",
        "\n",
        "\n",
        "acc_acuracy = np.array(acc_acuracy)\n",
        "means = np.mean(acc_acuracy, 0)\n",
        "stds = np.std(acc_acuracy, 0)\n",
        "ci95 = 1.96*stds/np.sqrt(iterations)\n",
        "\n",
        "print('Mean accuracy/loss, stddev, and confidence intervals')\n",
        "print((means, stds, ci95))\n",
        "print(acc_acuracy[acc_acuracy.argmin()])\n",
        "print(acc_acuracy[acc_acuracy.argmax()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean accuracy/loss, stddev, and confidence intervals\n",
            "(0.5434166772446285, 0.10080092526546676, 0.008065753861693276)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwXdGuk5hZUJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e137f77d-627d-4670-bcc0-be94b62d312b"
      },
      "source": [
        "print(acc_acuracy[acc_acuracy.argmin()])\n",
        "print(acc_acuracy[acc_acuracy.argmax()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.27500000409781933\n",
            "0.8250000067055225\n"
          ]
        }
      ]
    }
  ]
}